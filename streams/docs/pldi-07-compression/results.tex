\section{Experimental Evaluation}

To evaluate the potential benefits of computing directly on compressed
data, we focus on applications in digital video editing.  We consider
two common kinds of editing operations: 1) pixel transformations, such
as brightness, contrast, and color inversion, which adjust pixels
within a single video, and 2) video compositing, in which one video is
combined with another as an overlay or mask.

To make the performance evaluation as realistic as possible, our
current implementation takes the form of hand-coded plugins for two
popular video editing tools, MEncoder and Blender.  The plugins are
written for the Apple Animation format, and support any transformation
that either adjusts a single pixel (MEncoder) or combines two pixels
together (Blender).

The main results of our evaluation are:
\begin{itemize}

\item Operating directly on compressed data offers a speedup roughly
proportional to the compression factor in the resulting video.

\item For pixel transformations, speedups range from 3.1x to 235x,
with a median of 19x.

\item For video compositing, speedups range from 1.0x to 35x, with a
median of 7.4x.

\item {\bf [[summarize bloat using language of method section]]}

\end{itemize}
The following sections provide more details on our video workloads,
the evaluation of pixel transformations, and the evaluation of video
compositing.

\subsection{Video Workloads}

Our evaluation utilizes a suite of 12 video workloads that are
described in Table~\ref{tab:videos}.  The suite represents three
common usage scenarios for lossless video formats: Internet
screencasts, computer animation, and digital television production.
While videos in each area are often rendered to a lossy format for
final distribution, lossless codecs are preferred during the editing
process to avoid accumulating compression artifacts.  All of our
source videos are in the Apple Animation format, which is a leading
choice amongst digital video editing
professionals~\cite[p.~106]{adobe-anim} \cite[p.~284]{harrington-anim}
\cite[p.~367]{long-anim} \cite[p.~280]{pogue-anim}.  The Apple
Animation format is also popular for capturing video from the screen
or camera, as the encoder is relatively fast.

The videos are assembled from a variety of realistic and
industry-standard sources.  The first screencast is an online demo of
an authentication generator for rails~\cite{auth-demo}; the second is
a PowerPoint presentation (including animations), captured using
Camtasia Studio.  As Internet content is often watermarked with a logo
or advertisement, we include two animated logos in the ``Internet
video'' category.  These logos are taken from Digital
Juice~\cite{digital-juice}, a standard source for professional
animations, and rendered to Apple Animation format using their
software.  The animated logos are rendered full-frame (with the logo
in the corner) because compositing operations in our testbed (Blender)
are done on equal-sized videos.

The computer animation clips are derived from Elephant's Dream, a
short film with entirely open-source content~\cite{elephants-dream};
our videos are rendered from source using Blender.  Finally, the
digital television content is also taken from a Digital Juice
library~\cite{digital-juice}.  The backgrounds represent
high-resolution, rotating backdrops as might appear in the
introduction to a program.  The mattes are black-and-white animations
that can be used to synthesize a smaller overlay (such as a frame or a
``lower third'', often used for text) from a full animated background.

The videos exhibit a wide range of compression factors.  The
screencasts have very high compression ($\sim$100x-400x) because only
a small part of the screen (e.g., a mouse, menu, or powerpoint bullet)
is changing on any given frame; the Apple Animation format compresses
the inter-frame redundancy.  The compression for {\tt anim-scene1} is
also in excess of 200x because motion is limited to a small animated
character.  The animated logos are the next most compressed
($\sim$50-70x), influenced largely by the constant blank region
outside the logo.  The computer animation content ($\sim$10-30x
compression) is detailed but benefits from both inter-frame and
intra-frame redundancy, as some rendered regions have constant color.
Next are the digital video mattes ($\sim$5-10x compression), which
have fine-grained motion in some sections.  Finally, the digital video
backgrounds offer almost no compression gains under Apple Animation
(1.0-1.1x), as they have pervasive motion and detail across the entire
frame.

The Apple Animation format supports various bit depths.  All of our
source videos use 32 bits per pixel, allocating a single byte for each
of the red, green, blue, and alpha channels.

\subsection{Pixel Transformations}

The pixel transformations adjust the color of each pixel in a uniform
way.  We evaluated three transformations:
\begin{itemize}
\item Brightness adjustment, which increases each RGB value by a value
of 20 (saturating at 255).
\item Contrast adjustment, which moves each RGB value away from the
center (128) by a factor of 1.2 (saturating at 0 and 255).
\item Color inversion, which subtracts each RGB value from 255.
\end{itemize}

\subsubsection{Setup}

The pixel transformations were implemented as a plugin in MEncoder, a
popular command-line tool (bundled with MPlayer) for video decoding,
encoding, and filtering.  MEncoder relies on the FFMPEG library to
decode the Apple Animation format; as FFMPEG lacked an encoder for
this format, the authors implemented one.  Additionally, as MEncoder
lacks an interface for toggling only brightness or contrast, the
baseline configuration was implemented by the authors.

The baseline configuration performs decompression, pixel
transformations, then re-compression.  Because the main video frame is
updated incrementally by the decoder, the pixel transformations are
unable to modify the frame in place (otherwise pixels present across
frames would be transformed multiple times).  Thus, the baseline
transformations write to a separate location in memory.  The optimized
configuration performs pixel transformations directly on the
compressed data, avoiding data expansion implied by decompression and
multiple frame buffers, before copying the data to the output file.

Our evaluation platform is a dual-core Intel Xeon (2.2 GHz) with 2 GB
of RAM.  As all of our applications are single-threaded, the second
core is not utilized.  For the timing measurements, we execute each
program five times and report the median user time.

\subsubsection{Results}

Detailed results for the pixel transformations appear in
Table~\ref{tab:pixel-speedup}.  Figure~\ref{fig:pixel-speedup}
illustrates the speedups, which range from 3.1x to 235x.  As
illustrated in Figure~\ref{fig:graph-speedup-scatter}, the speedups
are closely correlated with the compression factor in the original
video.  For the highly-compressed screencasts and {\tt anim-scene1},
speedups range from 52x-235x.  For the medium-compression computer
animations (including the animated logos), speedups range from 11x to
40x.  And for the low-compression digital television content, speedups
range from 3x to 10x.

There are two distinct reasons for the speedups observed.  First, by
avoiding the decompression stage, computing on compressed data reduces
the volume of data that needs to be stored, manipulated, and
transformed.  This savings is directly related to the compression
factor and is responsible for the upwards slope of the graph in
Figure~\ref{fig:graph-speedup-scatter}.  Second, computing on
compressed data eliminates the algorithmic complexity of
re-compression.  For the Apple Animation format, the cost of
compressing a given frame does not increase with the compression
factor (if anything, it decreases as fewer pixels need a fine-grained
encoding).  Thus, the impact of re-compression can be visualized as
the intercept of the graph in Figure~\ref{fig:graph-speedup-scatter}.

The impact of re-compression is especially evident in the digital
television examples.  Despite a compression factor of 1.0 on {\tt
digvid-background2}, our technique offers a 5.5x speedup on color
inversion.  Application profiling confirms that 73\% of the baseline
runtime is spent in the encoder; as this stage is absent from the
optimized version, it accounts for $1/(1-0.73) = 3.7$x of the speedup.
The remaining speedup in this case is due to the extra frame buffer
(and associated memory operations) needed by the baseline
configuration.

Another important aspect of the results is the size of the output
files produced.  Apart from the first frame of a video\footnote{In the
Apple Animation format, the first frame is encoded as if the previous
frame was black.  Thus, adjusting the color of black pixels in the
first frame may increase the size of the file, as it removes
inter-frame redundancy.}, performing pixel transformations directly on
compressed data will never increase the size of the file.  This is
illustrated in the middle columns of Table~\ref{fig:pixel-speedup}, in
which the output sizes are mostly equal to the input sizes (to 2
decimal places).  The only exception is constrast adjustment on {\tt
anim-scene1}, in which the output is 3\% smaller than the input due to
variations in the first frame; for the same reason, some cases
experience a 0.1\% increase in size (not visisble in the table).

Though computing on compressed data has no significant effect on the
file size, there are some cases in which the pixel transformation
increases the redundancy in the video.  In such cases, an additional
re-compression stage (not present in our technique) could compress the
output even further than the original input.  This potential benefit
is illustrated in the last three columns of
Table~\ref{tab:pixel-speedup}, which tracks the output size of the
baseline configuration (including a re-compression stage) versus the
original input.  For the inverse transformation, no additional
compression is possible because inverse is a 1-to-1 transform: if two
pixels have different values in the input file, then they have
different values in the output file.  However, the brightness and
contrast transformations may map distinct input values to the same
ouput value, due to the saturating arithmetic.  In such cases, the
re-recompression stage can shrink the file to as low as 0.75x
(brightness) and 0.35x (contrast) its original size.  These are
extreme cases in which many pixels were close to the saturating point;
the median compression (across brightness and contrast) is only 10\%.

To achieve the minimal file size whenever possible, future work will
explore integrating a lightweight recompression stage into the
compressed processing technique.  Because most of the compression is
already in place, it should be possible to improve the compression
ratio without running the full encoder (e.g., run-length encoded
regions can be extended without being rediscovered).  Even running the
full encoding algorithm (in place on the compressed data) may leave us
with a significant speedup, as much of the speedup comes from
decreased data volume rather than the decreased re-compression cost.

\subsection{Video Compositing}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}[t]
\psfig{figure=table-benchmarks.eps,width=7.1in}
\caption{Video characteristics.
\protect\label{tab:videos}}
\end{table*}

\begin{table*}[t]
\psfig{figure=table-pixel-speedup.eps,width=7.1in}
\caption{Speedup on pixel transformations.
\protect\label{tab:pixel-speedup}}
\end{table*}

\begin{table*}[t]
\begin{minipage}{0.8in}
\mbox{~}
\end{minipage}
\psfig{figure=table-composite-speedup.eps,width=5.9in}
\caption{Speedup on composite transformations.
\protect\label{tab:composite-speedup}}
\end{table*}

\begin{figure}[t]
\psfig{figure=graph-speedup-pixel.eps,width=3.35in}
\caption{Speedup on pixel transformations.
\protect\label{fig:pixel-speedup}}
\end{figure}

\begin{figure}[t]
\psfig{figure=graph-speedup-scatter.eps,width=3.35in}
\caption{Speedup vs. compression factor for all transformations.
\protect\label{fig:graph-speedup-scatter}}
\end{figure}

\begin{figure}[t]
\psfig{figure=graph-speedup-composite.eps,width=3.35in}
\caption{Speedup on composite transformations.
\protect\label{fig:composite-speedup}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\scriptsize
\begin{verbatim}

\subsection{Video Compositing}

- goal: combine two source videos into a composite output
  - subtitling/logos
  - computer graphics
  - digital video editing / matte's

- do every background / foreground pair within a given application
  area, for total of 12 composites

\subsubsection{Setup}
 - implement as part of Blender (describe)
   - additional modifications needed to avoid O(n) flipping,
     O(frames^2) linked-list search, O(frames) custom-memory-mallocs,
     replace memcpy with compressed_memcpy, RGBA-BGRA on compressed
     data
 - relies on same FFMPEG codec as MEncoder

 - baseline: highly hand optimized
   - give quote from code
 - optimized: analog of a joiner
   - transcode two in parallel, keeping track of latest frames
   - if both input videos have a repeat, output a repeat; otherwise
     output new data

\subsubsection{Results}

 - point to speedups
   - again breakdown by area
   - point to same linear relationship seen previously

 - explain bloat factor, summarize by category

   - compressed data unable to get compression factor in dig
     tv. category because original videos not compressed much.  but
     output has so much black in it that they are compressed.

 - future improvement: recognize that alpha-under is not changing one
   of the source videos (perhaps with a linear analysis), then just
   copy that frame

\end{verbatim}
}

