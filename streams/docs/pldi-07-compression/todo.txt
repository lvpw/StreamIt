Before submission:
------------------

- EXAMPLES of transformations
  - add source-to-source StreamIt transformation

- abstract: 
  - also reducing volume of data operated on
  - Apple Animation not "based on" LZ77
  - check numbers

- results:
  - backwards pointer to apple animation
  - possibly describe 1x,1x case on scatter plot
  - add pictures of video frames?

- conclusions
  - first mapping of general computation into the compressed domain
- future work
  - integrating re-compression into our algorithm
  - lossy formats: linear transformations
    - preliminary experiments report over a 10x gain
    - can also support linear prediction this way
  - additional applications (conclusion):
    - cropping / padding
    - thresholding
    - reduce color depth / black/white
    - sepia toning
    - replace color
    - flip image
    - sparse matrix multiplication
    - adjust saturation
    - digital camera -- RLE in converting to Raw format

After submission:
-----------------

- if you combined intra-align and inter-align, could you get better
  compression?  Maybe intra-align expands LCM's too far

- look at more mencoder transformations
    - autolevels, IIR filters, FIR filters, etc.

- get breakdown of time spent processing vs. time spent re-compressing
  - can't really explain why encode_frame is so high (e.g., noop/inverse/screencast1)
  - delete *.so* in ffmpeg directory and rebuild blender to link
