\begin{figure}[t]
\scriptsize
\begin{verbatim}
struct rgb {
  byte r, g, b;
}
                                           --------------
rgb->rgb filter InvertColor() {            |  ReadRGB   |
  work push 1 pop 1 {                      --------------
    rgb pixel = pop();                           |
    pixel.r = 255 - pixel.r;                    \./
    pixel.g = 255 - pixel.g;               --------------
    pixel.b = 255 - pixel.b;               | InvertColor|
    push(pixel);                           --------------
  }                                              |
}                                               \./
                                           --------------
void->void pipeline Toplevel() {           |  WriteRGB  |
  add ReadRGB();                           --------------
  add InvertColor();
  add WriteRGB();
}
\end{verbatim}
\caption{StreamIt program for color inversion.
\protect\label{fig:streamit}}
\end{figure}

\section{Program Representation}

Our transformation relies on the synchronous dataflow model of
computation and the LZ77 representation of compressed data.  These are
described in the next two sections.

\subsection{Synchronous Dataflow}

In the synchronous dataflow model, a program is represented by a set
of independent {\it actors} that communicate using FIFO data
channels~\cite{LM87-i}.  Each actor has an independent program counter
and address space; all communication is done using the data channels.
Actors have an atomic execution step that executes repeatedly
throughout the lifetime of the program.  A key restriction of the
synchronous dataflow model is that, for each execution of a given
actor, the number of items produced and consumed on the data channels
is known at compile time.  This enables the compiler to perform static
scheduling of the actors and to guarantee deadlock freedom~\cite{LM87-i}.

Synchronous dataflow is a natural fit for many multimedia and signal
processing kernels, as such programs often have a regular structure
with known communication patterns.  As a programmer, one can use a
high-level language such as StreamIt~\cite{streamitcc} to express a
synchronous dataflow program.  An example StreamIt program appears in
Figure~\ref{fig:streamit}.  It consists of a sequence of three actors
(also called filters) that reads RGB data from a file, inverts the
color of each pixel, then writes the data to a file.  In the {\tt
InvertColor} actor, the {\tt work} function specifies the atomic
execution step; it declares that on each execution, it pops (inputs) 1
item from the input tape and pushes (outputs) 1 item to the output
tape.  The work function can contain general-purpose code.

\subsection{LZ77 Compression}

LZ77 is a lossless, dictionary-based compression algorithm.  Named
after its creators Lempel and Ziv, which published the algorithm in
1977~\cite{lz77}, LZ77 forms the basis for many popular compression
formats, including ZIP, GZIP and PNG.  As described in
Section~\ref{sec:formats}, LZ77 also serves as a generalization of
simpler encodings such as Apple Animation, Microsoft RLE, and Targa,
allowing our transformations to naturally extend to these formats.

\begin{figure}[t]
\scriptsize
\begin{verbatim}
stream := list-of value       stream := list-of (value | repeat)
                              repeat := <distance, count>

(a) Uncompressed domain       (b) Compressed domain (LZ77)
\end{verbatim}
\caption{Representation of data in the uncompresed and compressed
domains.  \protect\label{fig:domains}}
\end{figure}

The basic idea behind LZ77 is to utilize a sliding window of recently
decoded values as the dictionary for the compression algorithm.  In
the compressed data stream, there are two types of tokens: {\it
values} and {\it repeats} (see Figure~\ref{fig:domains}).  A value
indicates a token that should be copied directly to output of the
decoded stream.  A repeat contains two parts: a distance $d$ and a
count $c$; it indicates that the decoder should start at offset $d$
from the end of the decoded stream and copy a sequence of $c$ values
to the output.  The distances are bounded, which enables the decoder
to operate with a fixed buffer size.  It is important to note that the
count may exceed the distance, in which case some of the values
produced by a repeat operation are also copied by that operation.  For
example, a value A followed by a repeat $\langle1, 3\rangle$ results
in an output of ``A A A''.  An additional example of LZ77 compression
is given in Figure~\ref{fig:lz77}.

\begin{figure}[t]
\begin{minipage}{0.21in}
\mbox{~}
\end{minipage}
\psfig{figure=lz77-figure.eps,width=2.6in}
\caption{Example of LZ77 decompression.
\protect\label{fig:lz77}}
\end{figure}

\section{Program Transformation}

Our program transformation inputs a synchronous dataflow program and
outputs an equivalent program in which all of the data channels use a
compressed representation.  One can think of this process as mapping
from the uncompressed domain to the compressed domain (see
Figure~\ref{fig:domains}).  Rather than modifying the code within the
actors, our transformation treats actors as black boxes and wraps them
in a new execution layer.  The transformation attempts to preserve as
much compression as possible without ever performing an explicit
re-compression step.  While there exist cases in which the output data
will not be as compressed as possible, under certain conditions the
output is guaranteed to be fully compressed (relative to the
compression of the input).

We describe the transformation in three stages, first focussing on the
execution of actors themselves before detailing two helper routines.
We also discuss some optimizations and extensions to the technique.

\subsection{Execution of Actors}

\begin{figure}[t]
\scriptsize
\begin{verbatim}
                                     |             |
                             ----------------   ---------------
stream S1   stream S2        | Intra-Stream |  | Intra-Stream |
       |      |              |  Align (n1)  |  |  Align(n2)   |
       |      |              ----------------  ----------------
pop n1 |      | pop n2               |             |
     ------------              -----------------------------
     | Exec(A)  |              | Inter-Stream Align(n1, n2)|
     ------------              -----------------------------
          |push m                    |             |
          |                       ----------------------
          |                       | Compressed-Exec(A) |
       stream T                   ----------------------
                                            |

 (a) Uncompressed domain          (b) Compressed domain
\end{verbatim}
\caption{Overall execution of an actor A in the uncompressed and compressed domains.
\protect\label{fig:actor-pic}}
\end{figure}

We describe the transformation for an actor with two input streams and
one output stream.  This simplifies the presentation while capturing
all of the fundamental ideas; extension to other numbers of inputs and
outputs is only a matter of notation.  Also for the sake of
presentation, we use an operational semantics to express the execution
under the uncompressed and compressed domains.  All of the transition
rules have an efficient implementation in StreamIt, though some of
them require dynamic data rates and thus fall outside the synchronous
dataflow model.  The rules use the notations given in
Figure~\ref{fig:actor-pic}a, and have the following form:

{\scriptsize
\begin{verbatim}
S1; S2 -> T
--------------
S1'; S2' -> T'
\end{verbatim}}
This rule reads: if streams with values $S_1$ and $S_2$ are feeding
into a stream with value $T$, then after an execution step, the
streams have values $S_1'$, $S_2'$, and $T'$, respectively.  As
detailed in Figure~\ref{fig:domains}, we represent streams as lists of
tokens; inputs to the stream are added to the front of the list, while
outputs from the stream are removed from the end of the list.

Actor execution in the uncompressed domain is described by the rule in
Figure~\ref{fig:exec-rule}.  The rule expresses the simple fact that
actors input a list of $n_1$ values from the end of stream 1 and $n_2$
values from the end of stream 2; these lists are denoted by $V_1$ and
$V_2$.  The actor pushes its results, denoted by $A(V_1, V_2)$, onto
the front of the output stream.

\begin{figure}[t]
\scriptsize
\begin{verbatim}
S1 o V1; S2 o V2 -> T  |V1| = n1, |V2| = n2
--------------------------------------------- [exec-uncompressed]
S1; S2 -> A(V1, V2) o T
\end{verbatim}
\caption{Semantics of \textsc{Exec(A)}: execution of actor A in the
uncompressed domain.  $V_1$ and $V_2$ denote lists of values, $\circ$
denotes list concatenation, $A$ represents the work function of the
actor, and $n_1$, $n_2$ and $m$ are I/O rates.
\protect\label{fig:exec-rule}}
\end{figure}

\begin{figure}[t]
\scriptsize
\begin{verbatim}
S1 o V1; S2 o V2 -> T  |V1| = n1, |V2| = n2
------------------------------------------------  [exec-uncompressed]
S1; S2 -> A(V1, V2) o T

S1 o (d*n1, c*n1); S2 o (d*n2, c*n2) -> T
-----------------------------------------------   [exec-compressed]
S1; S2 -> <d*m, c*m> o T
\end{verbatim}
\caption{Semantics of \textsc{Compressed-Exec(A)}: execution of actor
$A$ in the compressed domain.  Notations are the same as in
Figure~\ref{fig:exec-rule}.  \protect\label{fig:compressed-exec-rule}}
\end{figure}

Actor execution in the compressed domain requires a sequence of
transformations (see Figure~\ref{fig:actor-pic}b).  First, each stream
is internally aligned to a granularity $n$ that matches the associated
input rate of the actor.  This alignment guarantees that every token
in the stream is either a sequence of $n$ values, or a repeat in which
both the distance and the count are multiples of $n$.  As a second
stage, the two input streams are aligned with each other.  The
inter-stream alignment guarantees that 1) if one stream is emitting a
repeat, then the other is emitting a repeat, and 2) if both streams
are emitting a repeat, then the repeat distances (and independently,
the counts) are in a ratio that matches the actor's input rates.

After the alignment stages comes the execution of the compressed
actor, which appears in Figure~\ref{fig:compressed-exec-rule}.  The
{\tt exec-uncompressed} rule deals with values on the input streams,
and is identical to that in the uncompressed execution.  The {\tt
exec-compressed} rule deals with repeats on the input streams and
encapsulates the key idea of the paper.  Because both inputs are
repeating at the correct granularity, the repeat can be copied
directly to the output of the actor without performing any new
computation.  The only change needed is to adjust the repeat distance
and count to match the actor's output rate.

The next two sections fill in the details of the intra-stream and
inter-stream alignment transformations that are utilized above.

\subsection{Intra-Stream Alignment}

The intra-stream alignment phase is needed for actors that pop more
than one item from a given stream.  Its goal is to align the execution
boundaries of the actor with the repeat boundaries of the compressed
data; this alignment is required for the compressed execution.
Following alignment, each execution of an actor will input either $n$
consecutive values, or a repeat token with a distance and count that
are evenly divisible by $n$ (where $n$ represents the pop rate of the
actor).

Both intra- and inter-stream alignment sometimes need to partially
decompress the data in the stream.  Due to the sliding-window
dictionary in LZ77, it is difficult to decode only a few items without
decompressing others.  Thus, our formulation assumes that a fully
decompressed version of the stream is available; the transition rules
access the decompressed data using the \mbox{\it decode} function,
which returns the sequence of values represented by a repeat token at
its current position in the stream.  However, as detailed in
Section~\ref{sec:opt}, there are several important cases in which
decompression can be completely avoided.

The semantics of intra-stream alignment are given in
Figure~\ref{fig:intra-stream-align}.  If the end of the input stream
contains $n$ values, then alignment is satisfied and the values are
moved to the output stream (rule {\tt pass-uncompressed}).  Likewise,
if the input contains a repeat in which the distance is a multiple of
$n$ and the count is at least $n$, then a number of aligned repeats
are peeled from the input and moved to the output (rule {\tt
pass-compressed}).  If the count is not a multiple of $n$, then part
of the repeat is leftover and remains on the input stream.

There are some cases in which a repeat cannot be moved to the output
stream, in which case the data needs to be partially decompressed
(rule {\tt expand}).  This occurs if the repeat has a count less than
$n$, if it occurs in the middle of an aligned stretch of $n$ values,
or if its distance is not a multiple of $n$ (this last condition can
sometimes be remedied by another rule, see below).  The {\tt expand}
rule decodes only one value from an unaligned repeat token, thereby
decreasing its count by one; the rest of the repeat may become aligned
later.  If the count of a repeat reaches zero, it is eliminated by the
{\tt prune} rule.

The final rule, {\tt coarsen-repeat}, preserves a specific kind of
compression in the input stream.  Consider that a filter pops two
items at a time, but encounters a long repeat with distance three and
count 100.  That is, input stream contains a regular pattern of values
with periodicity three.  Though consecutive executions of the filter
are aligned at different offsets in this pattern, every third filter
execution (spanning six values) falls at the same alignment.  In
general, a repeat with distance $d$ can be exploited by a filter with
pop rate $n$ by expanding the distance to $\mbox{LCM}(d, n)$.  In
order to perform this expansion, the count must be greater than the
distance, as otherwise the repeat references old data that may have no
periodicity.  Also, the stream needs to be padded with LCM-$d$ values
before the coarsened repeat can begin; this padding takes the form of
a shorter repeat using the original distance.  

\begin{figure}[t]
\scriptsize
\begin{verbatim}
S o V -> T            |V|=n
--------------------------- [pass-uncompressed]
S -> V o T

S o <d, c> -> T      d%n=0, c>=n
--------------------------------- [pass-compressed]
S o <d, c%n> -> <d, c-c%n> o T

                     (c<n or 1<=|V|<n or d%n>0) AND
S o <d, c> o V -> T  c<=LCM(d,n)
------------------------------------------ [expand]
S o <d, c-1> o decode(<d,1>) o V -> T

S o <d, 0> o V -> T
-------------------- [prune]
S o V -> T

                     let L=LCM(d,n)
S o <d, c> o V -> T  d%n>0,c>L
-------------------------------------- [coarsen-repeat]
S o <L, c-(L-d)> o <d, L-d> o V -> T
\end{verbatim}
\caption{Semantics of \textsc{Intra-Stream-Align}($n$): aligning data
to a granularity of $n$.  The \mbox{\it decode} function uncompresses
a repeat token into a list of values; other notations are given in
Figure~\ref{fig:exec-rule}. \protect\label{fig:intra-stream-align}}
\end{figure}

\begin{figure}[t]
\scriptsize
\begin{verbatim}
S1 o V1; S2 o V2 -> T1; T2   |V1| = n1, |V2| = n2
--------------------------------------------------- [pass-uncompressed]
S1; S2 -> V1 o T1; V2 o T2 

S1 o <d1*n1, c1*n1>; 
S2 o <d2*n2, c2*n2> -> T1, T2   d1=d2,c1>=c2
---------------------------------------- [pass-compressed]
S1 o <d1*n1, (c1-c2)*n1>; 
S2 -> <d1*n1, c2*n1> o T1; <d2*n2, c2*n2> o T2

S1 o <d1*n1, c1*n1>;                 (|V2|>0 or d1!=d2) AND
S2 o <d2*n2, c2*n2> o V2 -> T1, T2   (c1<=LCM(d1,d2) or c2<=LCM(d1,d2))
-------------------------------------------------------------- [expand]
S1 o <d1*n1, (c1-1)*n1> o decode(<d1*n1, n1>) o V1;
S2 o <d2*n2, c2*n2> o V2 -> T1, T2

S1 o <d, 0> o V; S2 -> T1, T2
------------------------- [prune]
S1 o V; S2 -> T1; T2

                                     V1,V2 may be empty
S1 o <d1*n1, c1*n1> o V1;            let L = LCM(d1,d2)
S2 o <d2*n2, c2*n2> o V2 -> T1, T2   d1<d2,c1>L,c2>L
------------------------------------------------------ [coarsen-repeat]
S1 o <L*n1, (c1-(L-d1))*n1> o <d1*n1, (L-d1)*n1> o V1
S2 o <d2*n2, c2*n2> o V2 -> T1, T2;
\end{verbatim}
\caption{Semantics of \textsc{Inter-Stream-Align}($n_1$, $n_2$):
aligning two streams with granularities $n_1$ and $n_2$.  Notations
are the same as in Figure~\ref{fig:inter-stream-align}.
\protect\label{fig:inter-stream-align}}
\end{figure}

\subsection{Inter-Stream Alignment}

For actors that read from multiple input streams, an additional
alignment step is needed to align repeats between the streams.  While
intra-stream alignment guarantees that each repeat distance and count
is some multiple of the pop rate, the inter-stream alignment
guarantees that both streams use the same multiple at a given point in
time.  When this constraint is satisfied, the compressed execution
(Figure~\ref{fig:compressed-exec-rule}) can simply copy repeats from
the input to the output, as both inputs correspond to the same
executions of the actor during a previous time step.

The transition rules for inter-stream alignment appear in
Figure~\ref{fig:inter-stream-align}.  The rules have a close parallel
with the intra-stream case, except that repeat distances and counts
are being reconciled between the two streams rather than being
reconciled with the pop rate.  To reduce the number of rules required,
the subscripts should be interpreted without loss of generality; that
is, on every application of a rule, $S_1$ may refer to either one of
the input streams while $S_2$ refers to the other.

The first two rules specify conditions under which tokens may move to
the output streams.  If each input ends with a sequence of values that
is as long as the corresponding pop rate, then the values are moved to
the output streams (rule {\tt pass-uncompressed}).  Alternately, if
both inputs contain repeats and the distances correspond to the same
number of actor executions, then the shorter repeat is moved to the
output tape and the longer repeat is shortened (rule {\tt
pass-compressed}).

There are two conditions under which data needs to be decompressed
during inter-stream alignment.  They are: 1) one stream contains a
sequence of values where the other contains a repeat, and 2) both
streams contain repeats but the distances correspond to a different
number of actor executions (and cannot be corrected by coarsening, see
below).  In these cases, the {\tt expand} rule decodes one of the
repeats for the equivalent of one actor execution.  If the repeat
count reaches zero, then the token is subsequently removed by the {\tt
prune} rule.

The {\tt coarsen-repeat} rule has the same effect as in intra-stream
alignment: if two repeat distances correspond to a different number of
actor executions, and the repeat counts are longer than the distances,
then the distances can be coarsened to the LCM of their original
values.  For this to be profitable, the repeat counts must also exceed
the LCM value, as otherwise there would be no repetition following the
coarsening.  The rule coarsens one stream at a time; it needs to be
applied twice if neither repeat distance is equal to the LCM.

\subsection{Optimizations}
\label{sec:opt}

Though the transformation to the compressed domain was formulated in
fully general terms, the process can be streamlined considerably for
common classes of inputs:
\begin{itemize}
\item If an actor has only one input stream, then no inter-stream
alignment is needed.
\item If an actor has a pop rate of one ($n=1$) on a given stream,
then no intra-stream alignment is needed.
\item If the repeat distance is equal to the LZ77 window size, then no
decompression is needed because it would simply overwrite the same
values in the buffer.  This property holds for inter-frame repeats in
the Apple Animation format (see Section~\ref{sec:formats}).
\end{itemize}
A consequence of the first two bullets is that an actor with a single
input stream and a pop rate of one (such as the InvertColor actor in
Figure~\ref{fig:streamit}) requires no alignment stages; it is wrapped
only in the compressed execution driver.  Without the alignment
stages, there is no decompression involved, thus guaranteeing that the
compressed output will be the same size as the compressed input.

\subsection{Extensions}
\label{sec:extensions}

The transformation can be extended to support a broader class of
actors.  Some straightforward extensions are as follows:
\begin{itemize}

\item {\it Actors with state.}  If an actor retains mutable state from
one execution to the next, a repeat token can be copied across the
actor if the current state values are the same as they were at the
beginning of the repeated segment.  One could maintain a lookup table
that tracks the state values for the sake of this comparison.
Further, state updates that are associative (e.g., counting pixels for
a histogram) could be detected and applied even if the current state
is different than the original.

\item {\it Dynamic input and output rates.}  The current formulation
relies on an actor's fixed I/O rates to calculate repeat distances and
counts for the output tape from the repeat tokens on the input tapes.
However, a lookup table could be used to track the actual I/O rates on
each execution.  In the event of a repeat, the recorded I/O rates from
the previous execution could be used to calculate the repeat
parameters on the output tape.

\item {\it Sliding window computations.}  We currently assume that an
actor consumes all of the items it inspects on a given execution step.
However, some actors (e.g., a gaussian blur filter) inspect a window
of values in addition to the one that is popped from the input.  Such
{\it peeking} filters can be supported by shortening the output

\end{itemize}