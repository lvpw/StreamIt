\section{Results}
\label{chpt:results}

We have implemented the phased single appearance and minimum latency
scheduling algorithms as part of the StreamIt compiler, and we
evaluate them in this section.  Section \ref{sec:results:apps}
presents the applications used for evaluation, while Section
\ref{sec:results:results} presents the results and analysis.

\subsection{Benchmarks}
\label{sec:results:apps}

Our benchmark suite contains 17 applications. Out of these
applications, 15 represent meaningful computations taken from
real-life applications, while two were chosen to highlight the
effectiveness of phased scheduling.

SJPeek1024 and SJPeek31 are synthetic benchmarks, designed to
highlight the strengths of phased schedules~\cite{karczma-thesis}.
SJPeek1024 requires an initialization schedule which benefits from the
finer granularity of minimum latency scheduling. SJPeek31 contains a
push/pop mismatch which causes a combinatorial blow-up using single
appearance scheduling.

Nine test applications (BitonicSort, FFT, FilterBank, FIR, Radio, GSM,
3GPP, Radar and Vocoder) are also used in \cite{Gordo02}. BitonicSort
performs a 32 element bitonic sort; FFT performs a 64-element FFT;
FilterBank is an 8 channel filter bank; FIR is a 64-tap fine-grained
FIR filter; Radio is an FM radio decoder with an equalizer; 3GPP is a
3GPP Radio Access Protocol application; Radar is a radar array
front-end application with beamforming; Vocoder is a 28 channel
Vocoder.

Two test applications (CD-DAT and QMF) are borrowed from
\cite{murt2000x2}. We model only the communication properties of the
graphs; the code inside of the {\filters} has not been implemented.
CD-DAT performs sample rate conversion and is exactly the same as that
described in \cite{murt2000x2}.  QMF is a filter bank application
which uses a 1/2-1/2 split for the spectrum up to a depth of 3
(qmf12\_3d in~\cite{murt2000x2}).  It was slightly modified to use
{\StreamIt}'s pre-defined {\splitter} and {\joiner} constructs.  The
high-pass and low-pass filtering in multiple-output blocks has been
converted to a splitter followed by filters on each of the output
channels. The low and high pass filters have also been given a peek
amount of 16 so they can perform their function in the way intended by
{\StreamIt}.

The remaining 4 applications were chosen from our sample applications
used for testing the StreamIt compiler. HDTV performs a HDTV signal
decoding/encoding. CFAR implements PCA Constant False Alarm Rate
detection. Block Matrix Mult performs a blocked matrix multiplication
- it multiplies a 12x12 matrix by a 9x12 matrix in blocks of 3x3
sub-matrices. Trellis performs trellis encoding/decoding.

\begin{comment}

\subsection{Methodology}
\label{sec:results:methodology}

The following data has been collected: number of nodes, number of
node executions per steady state, schedule size and buffer size
for pseudo single appearance and minimal latency schedules.

\subsubsection{Schedule Compression}

\end{comment}

\subsection{Results}
\label{sec:results:results}

\begin{figure}[t]
\vspace{6pt}
\psfig{figure=buffer-graph.eps,width=3.35in}
\caption{\small Buffer size required by a phased minimum latency schedule,
normalized to buffer size of a hierarchical single appearance
schedule.\protect\label{fig:buffergraph}}
\vspace{-6pt}
\end{figure}

Table \ref{tbl:results} presents the buffer and schedule sizes
required by our hierarchical single appearance and minimum latency
scheduling algorithms for our benchmark suite.  Note that the GSM
application cannot be scheduled using a single appearance schedule,
because it has a tightly constrained feedback loop (see
Figure~\ref{fig:gsm}).  Thus, we omit GSM in
Figures~\ref{fig:buffergraph} to~\ref{fig:sumgraph}.

Several applications show a very large improvement in buffer size
necessary for execution (see Figure~\ref{fig:buffergraph}).  These
improvements are usually coupled with an increase in code size
(Figure~\ref{fig:codegraph}).  However, as shown in
Figure~\ref{fig:sumgraph}, minimum latency scheduling never increases
the sum of code size and data size for any application.  In computing
this sum, note that we give equal weight to the code size and data
size only for the sake of illustration; in an actual system, the
relative cost of each kind of storage would greatly depend on resource
constraints and the implementation strategy.

The CD-DAT benchmark exhibits a decrease in buffer size from 1021 to
72, a 93\% improvement. \cite{murt2000x2} reports a buffer size of 226
after applying buffer merging techniques. Our improvement is due to
reducing the combinatorial growth of the buffers using phased
scheduling.

\begin{figure}[t]
\vspace{6pt}
\centering
\psfig{figure=code-graph.eps,width=3.28in}
\caption{\small Code size required by a phased minimum latency schedule,
normalized to code size of a hierarchical single appearance
schedule.\protect\label{fig:codegraph}}
\end{figure}

\begin{figure}[t]
\psfig{figure=total-size-graph.eps,width=3.35in}
\caption{\small Sum of buffer and code size required by a phased
minimum latency schedule, normalized to that of a hierarchical single
appearance schedule.  We give equal weight to the code and buffer size
only for illustration; in an actual system, the relative weights are
complex and depend upon resource
constraints. \protect\label{fig:sumgraph}}
\vspace{-4pt}
\end{figure}

\begin{table*} \centering \small
\vspace{-4pt}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline {\parbox{0.8in}{ \vspace{3pt} {\bf Benchmark}}} & \parbox{0.8in}{\centering \vspace{8pt}{\bf Number of Nodes}} & \parbox{0.8in}{\centering \vspace{16pt} {\bf Number of Node Executions}} & \multicolumn{2}{c|}{{\bf Single Appearance}} & \multicolumn{2}{c|}{{\bf Minimal Latency}} \\
\cline{4-7} & & & \parbox{0.8in}{\centering ~ \\ \vspace{6pt} {\bf Schedule Size} ~ \\ } & \parbox{0.8in}{\centering ~ \\ \vspace{-3.3pt} {\bf Buffer Size} ~ \\ } & \parbox{0.8in}{\centering ~ \\ \vspace{6pt} {\bf Schedule Size} ~ \\ } & \parbox{0.8in}{\centering ~ \\ \vspace{-3.3pt} {\bf Buffer Size} ~ \\ } \\
\hline SJPeek31 & 6 & 12063 & 8 & 19964 & 24 & 874 \\
\hline HDTV & 170 & 390038 & 230 & 550692 & 1190 & 28300 \\
\hline CD-DAT & 6 & 612 & 6 & 1021 & 64 & 72 \\
\hline CFAR & 4 & 193 & 7 & 193 & 9 & 129 \\
\hline SJPeek1024 & 6 & 3081 & 8 & 7168 & 13 & 4864 \\
\hline Block Matrix Mult & 43 & 1956 & 48 & 4212 & 56 & 3132 \\
\hline Vocoder & 117 & 415 & 156 & 1285 & 205 & 1094 \\
\hline Radar & 68 & 161 & 68 & 332 & 68 & 332 \\
\hline BitonicSort & 370 & 468 & 370 & 2112 & 370 & 2112 \\
\hline 3GPP & 94 & 356 & 104 & 986 & 108 & 970 \\
\hline Trellis & 14 & 301 & 14 & 538 & 17 & 499 \\
\hline FIRfine & 132 & 152 & 132 & 1560 & 132 & 1560 \\
\hline FilterBank & 53 & 312 & 95 & 2063 & 116 & 1991 \\
\hline QMF & 65 & 184 & 85 & 1225 & 85 & 1225 \\
\hline Radio & 30 & 43 & 35 & 1351 & 35 & 1351 \\
\hline FFT & 26 & 448 & 26 & 3584 & 26 & 3584 \\
\hline GSM & 47 & 3356 & - & - & 64 & 3900 \\
\hline
\end{tabular}
\caption{\small Results of running single appearance and minimal
latency scheduling algorithms on various applications.}
\label{tbl:results}
\vspace{-4pt}
\end{table*}

For our synthetic benchmarks SJPeek31 and SJPeek1024, buffer sizes
decrease by 95\% and 32\%, respectively. In the case of SJPeek1024,
the improvement is due to creating fine grained phases which allow the
initialization schedule to transfer smaller amounts of data and allow
the children of a {\splitjoin} to drain their data before the
{\splitter} provides them with more. This improvement is only evident
in the presence of peeking. In the case of SJPeek31, the improvement
reflects reduced combinatorial growth in addition to the fine-grained
benefit with peeking.

It is important to note that the schedules we consider in our
evaluation have the elements of a hierarchical phase sorted as
described in Section~\ref{chpt:phased}: all of the phases of a given
child stream are executed before advancing to the next child.  For
both single-appearance and minimum latency scheduling, this represents
only one possible execution order for child phases; in particular, a
more fine-grained interleaving of children could reduce buffer
requirements.  While we do not explore the range of possible
interleavings within a hierarchical node, note that the hierarchy of
the stream graph provides a set granularity at which the leaf nodes of
the graph can be interleaved---for example, in a hierarchical
single-appearance schedule, two consecutive executions of a pipeline
construct would execute all of its nodes once before executing all of
the nodes again.  We are exploring other interleaving strategies for
the nodes within a given phase.
