\section{StreamIt Scheduling Concepts}
\label{chpt:sched-basic}

This section introduces the general concepts used for scheduling
{\StreamIt} programs.  Concepts presented here are common with other
systems \cite{ptolemyoverview}.  Section \ref{sec:exec-model} presents
the {\StreamIt} execution model. Section \ref{sec:steady-state}
introduces the concept of a steady state and shows how to calculate
it. Section \ref{sec:init-peeking} explains the need for
initialization of {\StreamIt} program.
% these languages don't have static scheduling
% \cite{esterel92} \cite{lustre}.

\subsection{{\StreamIt} Execution Model}
\label{sec:exec-model}

A {\StreamIt} program is represented by a hierarchical graph, where
the leaf nodes are filters, splitters, and joiners, and the composite
nodes are pipelines, splitjoins, and feedbackloops.  Edges in the
graph represent data channels, which operate as FIFO queues.

In order for a {\filter} $f$ to execute, it must have at least
$\mt{peek}_f$ items on its input channel.  Execution will decrease the
amount of data on its input channel by $\mt{pop}_f$ and increase the
amount of data on its output channel by $\mt{push}_f$. Similarly, a
{\splitter} $s$ will consume $\mt{pop}_s$ data from its {\Input}
{\Channel} and push $\mt{push}_{s,i}$ data onto its $i$th output
channel, while a joiner $j$ will consume $\mt{pop}_{j,i}$ items from
its $i$th input channel and push $\mt{push}_j$ onto its {\Output}
{\Channel}.

Each filter, splitter, and joiner in the graph has two epochs of
execution: one for initialization, and one for the steady state.
Within each epoch, a given filter can have any number of phases, each
of which is an atomic execution step with its own input and output
rates.  At the start of the program, each node starts in phase $0$ of
the initial epoch.  It then advances through its initialization
phases, executing each a single time before transitioning to phase $0$
of the steady state epoch.  Within the steady state, a filter executes
its steady state phases cyclically.
% (just as in a cyclo-static dataflow graph~\cite{BELP96}).

\subsection{Steady State Schedule}
\label{sec:steady-state}

One of the most important concepts in scheduling streaming
applications is the steady state schedule.  A steady state schedule is
a schedule that the program can repeatedly execute forever.  It has
the property that the amount of data buffered up between any two nodes
does not change from before to after its execution.

A ``steady state'' of a program is a collection of number of times
that every node in the program needs to execute in a steady state
schedule.  It does not impose an order of execution on the nodes in
the program.
\begin{comment}
Not every {\StreamIt} program has a steady state schedule.  It is
possible for a program to have unbalanced production and
consumption of data in {\splitjoins} and {\feedbackloops}. The
amount of data buffered continually increases, and cannot be
reduced, thus making it impossible to create a steady state
schedule for them.  It is also possible that a {\feedbackloop}
does not have enough data buffered up internally in order to
complete execution of a full steady state, and thus deadlocks.
Programs without a valid steady state schedule are not considered
valid {\StreamIt} programs. In other words, all valid {\StreamIt}
programs have a steady state schedule.
\end{comment}

\subsubsection{Minimal Steady State}

We now summarize some of the key properties of steady states, which
are presented in~\cite{lee87static}.  Detailed proofs of these
properties in the context of StreamIt can be found in
\cite{karczma-thesis}.

%% The size of a steady state is defined as the sum of all executions
%% of all the nodes in the program per iteration of the steady state.

%% \begin{definition}
%% A steady state of a stream operator $s$ is represented by vector
%% $m$ of non-negative integers. Each of the elements in $m$
%% represents the number of times a corresponding node in $s$ must be
%% executed in the steady state.
%% \end{definition}

%% Note that $m$ does not impose an order of execution of nodes. Size
%% of a steady state is the total number of executions of all the
%% nodes in the steady state.

The first property concerns the size of a steady state.  The size is
defined to be the sum of the repetitions of all nodes in the schedule.

\begin{theorem}[Minimal Steady State Uniqueness]
A {\StreamIt} program that has a valid steady state, has a unique
minimal steady state.
\end{theorem}

This means that for every valid {\StreamIt} program, there is a unique
set of steady state multiplicities that fires as few nodes as
possible.  Our scheduler will produce schedules that execute exactly
the minimal steady state of a program.

\begin{comment}
\begin{proof}[Minimal Steady State Uniqueness]
Assume that there are two different minimal steady states with
same size.  Let $m$ and $q$ denote vectors representing the two
steady states. Let $\sum_i m_i$ denote size of schedule $m$ and
$\sum_i q_i$ denote size of schedule $q$. Note that since both $m$
and $q$ are minimal steady states, $\sum_i m_i = \sum_i q_i$.
Since the schedules are different, there must be some $j$ for
which $m_j \ne q_j$. Assume without loss of generality that $m_j <
q_j$. Since a steady state does not change the amount of data
buffered between nodes, the node producing data for node $i$ must
also execute less times than corresponding node in $q$. Similarly,
the node consuming data produced by node $j$ also must execute
less times than the corresponding node in schedule $q$. Since a
{\StreamIt} program describes a connected graph, it follows that
$\forall i, m_i < q_i$.  Thus $\sum_i m_i \ne \sum_i q_i$, which
is a contradiction. Thus there cannot be two different minimal
steady state.
\end{proof}

\begin{corollary}[Minimal Steady State Uniqueness]
\label{corollary:minimal-state}
The additional property we have from the above proof is that if
$m$ represents a minimal steady and $q$ any other steady state,
then $\forall i, m_i < q_i$.
\end{corollary}

\begin{lemma}[Composition of Steady Schedules]
\label{lemma:composition}
If $m$ and $q$ are two steady states for a {\StreamIt} program, then
$m + q$ is also a steady state.
\end{lemma}

The above lemma is true because neither $m$ nor $q$ change the
amount of data buffered in the {\Channels}.  Thus a composition of
the steady states does not change the amount of data buffered in
the {\Channels}, which makes the composition also a steady schedule.

\begin{corollary}[Composition of Steady Schedules]
\label{corollary:composition}
If $m$ and $q$ are two steady states, and $\forall i, m_i > q_i$,
then $w = m - q$ is also a steady state.
\end{corollary}

If $q$ is a steady state and $m = w + q$ is a steady state, then
$w$ must not change the amount of data buffered in {\Channels}. Thus
$w$ must be a steady state.
\end{comment}

\begin{theorem}[Multiplicity of Steady States] If a
{\StreamIt} program has a valid steady state, then all its steady
states are strict multiples of its minimal steady state.
\label{thm:multiplicity}
\end{theorem}

\begin{comment}
\begin{proof}[Multiplicity of Minimal Steady State]
Assume that there exists a steady state that is not a multiple of
the minimal steady state.  Let $m$ denote the minimal steady
state. Let $q$ denote the other steady state.  Note that $w = q -
m$ is still a steady state, as long as all elements of $w$ remain
non-negative (by Corollary \ref{corollary:composition}).  Repeat
subtracting $m$ from $q$ until no more subtractions can be
performed without generating at least one negative element in
vector $w$.  Since $q$ is not a multiple of $m$, $w \ne 0$. But
since we cannot subtract $m$ from $w$ any further, $\exists i, m_i
> w_i$.  Since $m$ is a minimal steady state and $w$ is a steady
state, this is impossible due to Corollary
\ref{corollary:minimal-state}. Thus there are no steady states
that are not multiples of the minimal steady schedule.
\end{proof}
\end{comment}

This property means that in order to find a minimal steady state
schedule of a stream operator, we can find any of its steady states
and divide it by the $gcd$ of executions of all nodes in the operator
to find the minimal steady state schedule.

\subsubsection{Calculating Minimal Steady States}
\label{sec:calc-min-steady}

For a general stream graph, the minimal steady state can be calculated
in a linear algebra framework by formulating a set of balance
equations~\cite{lee87static}.  However, with StreamIt we leverage the
structure of the stream graph to calculate steady states in a
hierarchical manner.  That is, a minimal steady state is calculated
for all child operators of a {\pipeline}, {\splitjoin} and
{\feedbackloop}, and then the schedule is computed for the actual
parent operator using these minimal states as atomic executions.  This
approach is useful in the context of separate compilation, where the
entire graph might not be available at compile time; additionally, the
steady state multiplicity of a given node in relation to its parent is
useful for our scheduling algorithms.

For brevity, we omit the equations for finding the minimal steady
states.  The steady states are calculated hierarchically; filters with
multiple phases are represented by a single, coarser phase for the
sake of the steady-state schedule.  Details can be found
in~\cite{karczma-thesis}.  For example, the minimal steady states of
the stream graphs in Figure~\ref{fig:steady-state} are as follows:
\[
\begin{tabular}{ll}
\mbox{Sample Pipeline}: & \mt{steady}(A) = 4 \\
~ & \mt{steady}(B) = 6 \\
~ & \mt{steady}(C) = 9 \\
~ & \mt{steady}(D) = 3 \\
~ & ~ \\
\mbox{Sample SplitJoin}: & \mt{steady}(splitter) = 2 \\
~ & \mt{steady}(A) = 2 \\
~ & \mt{steady}(B) = 1 \\
~ & \mt{steady}(joiner) = 2 \\
~ & ~ \\
\mbox{Sample FeedbackLoop}: & \mt{steady}(joiner) = 6 \\
~ & \mt{steady}(B) = 15 \\
~ & \mt{steady}(splitter) = 5 \\
~ & \mt{steady}(L) = 3 \\
\end{tabular}
\]
Note that these numbers represent the multiplicity of each node in one
steady state execution of its parent.  In Section~\ref{chpt:phased},
we consider how to order these executions to form a valid schedule.

%% Executing a full steady state of an operator is referred to as
%% ``executing an operator". The notation for $peek$, $pop$ and $push$ is
%% is extended to mean entire operators in their minimal steady state
%% execution.  That is, a {\pipeline} $p$ will consume $o_p$ data,
%% produce $u_p$ data and peek $e_p$ data on every execution of its
%% steady state.  Again, in the hierarchical view of {\StreamIt}
%% programs, a child operator of a {\pipeline} will execute its steady
%% state atomically.

%% A steady state of a stream operator $s$ is represented by an
%% ordered set $S_s$ of elements, $S_s = \{m, N, c, v\}$. The set
%% includes a vector $m$, which describes how many times each
%% {\StreamIt} node of the operator will be executed in the steady
%% state, a corresponding ordered set $N$ which stores all the nodes
%% of the operator, a vector $c$, which holds values $[e_s, o_s,
%% u_s]$ for stream operator $s$, and a vector $v$ which holds number
%% of steady state executions of all direct children of $s$. $m$ and
%% $v$ are not the same vector, because $m$ refers to nodes in the
%% subgraph, while $v$ refers only to the direct children, which may
%% be {\filters}, {\pipelines}, {\splitters} and {\feedbackloops}.
%% For a stream operator $s$, set $S$ is denoted as $S_s$ and the
%% elements of $S_s$ are denoted as $S_{s,m}$, $S_{s,N}$, $S_{s,c}$
%% and $S_{s,v}$.

%% Note, that a steady state does not say anything about the ordering
%% of the execution of nodes, only how many times each node needs to
%% be executed to preserve amount of data buffered by the operator.

%% We omit the equations for calculating the minimal steady states
%% for brevity. Details can be found in Appendix \ref{apx:eqs}. As an
%% example, the {\splitjoin} from Figure \ref{fig:steady-state}(b) has
%% the following steady state:

%% \begin{displaymath}
%% S_{sj} = \left\{
%% \begin{array}{c}
%% 2 * S_{sj_0, m} \circ 1 * S_{sj_1, m} \circ [2\ 2], \\
%% S_{sj_0, N} \circ S_{sj_1, N} \circ \{sj_s, sj_j\}, \\
%% \left[
%% \begin{array}{c}
%% 2 * 3 \\ 2 * 3 \\ 2 * 4
%% \end{array}
%% \right], \left[
%% \begin{array}{c}
%% 2 \\ 1 \\ 2 \\ 2
%% \end{array}\right]
%% \end{array} \right\}
%% \end{displaymath}

\subsection{Initialization Schedule}
\label{sec:init-peeking}

Unlike traditional SDF graphs, StreamIt programs may require a
separate schedule for initialization.  This is for two reasons.
First, each filter might contain an initialization stage, where the
input and output rates are different than in the steady state.  But
even without the initialization epoch, an initialization schedule is
necessary if any filter makes use of StreamIt's $peek$ construct, in
which input items can be examined without being consumed.

To understand the impact of peeking on scheduling, consider a filter
$f$, with $\mt{peek}_f = 2$ and a $\mt{pop}_f = 1$. When a {\StreamIt}
program is first run, there is no data present on any of the
{\Channels} (ignoring the case of a feedbackloop delay).  This means
that for the first execution, {\filter} $f$ requires that two data
items be pushed onto its {\Input} {\Channel}.  After the first
execution of $f$, it will have consumed one data item, and left at
least one data item on its {\Input} {\Channel}.  Thus in order to
execute $f$ for the second time, only one extra data item needs to be
pushed onto $f$'s {\Input} {\Channel}.  The same situation persists
for all subsequent executions of $f$ -- only one additional data item
is required on $f$'s {\Input} {\Channel} in order to execute $f$.

This example illustrates that the first execution of a {\filter} may
require special treatment.  Namely, some nodes will need to push extra
items at the start of execution so that downstream filters can fire
for the first time.  Due to this condition, a {\StreamIt} node may
need to be initialized before it can enter steady state execution.

%% \subsection{Schedules}
%% \label{sec:general:schedules}

%% Once a program has been initialized, it is ready to execute its
%% steady state. In order to do this, a steady state schedule needs
%% to be computed. The steady states computed above do not indicate
%% the ordering of execution of the nodes, only how many times the
%% nodes need to be executed.

%% A schedule is an ordering of nodes in a {\StreamIt} operator. In
%% order to execute the schedule, we iterate through all of its nodes
%% in order of appearance and execute them one by one.  For example
%% in order to execute schedule $\{ABBCCBBBCC\}$ we would execute
%% node A once, node B twice, node C two times, node B three times
%% and node C twice again, in that order. In order to shorten the
%% above schedule we can run-length encode it.  The schedule becomes
%% $\{A \{2B\}\{2C\}\{3B\}\{2C\}\}$.
