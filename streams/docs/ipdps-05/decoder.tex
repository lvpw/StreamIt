\Section{MPEG Decoder in StreamIt}

% TODO: recalculate lines of code using statement count (num of ;)
We implemented an MPEG-2 decoder in StreamIt. It is a fully portable
implementation in that the application is not architecture
dependent. The implementation was carried out by one student
programmer with no prior understanding of MPEG. The development
spanned eight weeks from specification~\cite{MPEG2} to the first fully
functional MPEG decoder. The StreamIt code is nearly 4,921 lines of
code with 48 static streams. The MPEG stream parser is the largest
single filter, consisting of 1,924 lines of code.  The 48 static
streams are compiled to 2,150 filters for a picture resolution of
352x240. In contrast, the reference C
implementation~\cite{reference-mpeg-c} is nearly 9,832 lines of code,
although it provides several features such as interlacing and
multi-layer streams that are not yet implemented in the StreamIt
decoder.

% What follows is the added section with a detailed description
% of our implementation. - Matt, 1/25/06

\begin{figure}[htbp]
% Width and spacing is probably all wrong now
% Also, we probably want to get rid of dec_block later on in favor
% of this. This is also just a draft of the detailed block diagram right
% now with changes and improvements to be made.
\centerline{\epsfig{file=dec_block_detailed.eps,width=5in}}
\caption{Block diagram of MPEG-2 decode.}
\label{fig:dec_block_detailed}
\end{figure}

The MPEG decoder implementation, shown in Figure 
\ref{fig:dec_block_detailed} is a pipeline, with most of the work
contained within three subsections. It accepts a compressed bitstream as input, and 
produces the decoded video as output. 

The first subsection is a filter responsible for
parsing the MPEG-2 bitstream and performing Huffman and variable
run-length decoding (VLD). This process results in a set of
quantized, frequency-domain macroblocks and corresponding motion
vectors. 

The second subsection is a splitjoin which processes the macroblocks
and motion vectors in parallel. The macroblocks are reordered, 
inversely quantized, and inversely DCT transformed to the spatial 
domain. The motion vectors, coded with respect to their associated
macroblock position and the value of previously decoded vectors,
are converted to absolute addresses.

The third section is responsible for motion compensation in the case of
predictively coded macroblocks (e.g., P and B pictures). Because the
color channels can be decoded independently from each other, a
splitjoin processes the motion compensation for each channel in
parallel. The motion compensation filter uses the motion vectors to find
a corresponding macroblock in a previously decoded, stored 
reference picture. This reference macroblock is added to the current
macroblock to recover the original picture data. If the current macroblock
is part of an I or P picture, then the decoder stores it for future
reference. In addition to the motion compensation, the chrominance
channels require upsampling.

In addition to these three decoder subsections, two additional filters handle
reordering the decoded pictures temporally and transforming them into the
RGB color space.

The decoder uses messaging to send metadata associated with macroblocks
from the parser to downstream filters. For instance, the parser generates
a message whenever the picture or macroblock type changes. The motion
compensation filter uses this information to determine how to process
the blocks and determine whether it needs to store them for future
reference. The picture reordering step uses the picture type to 
determine the correct temporal order, and the math behind the inverse
quantization depends on the encoding type of the macroblock. Because
the macroblock type and picture type information changes infrequently
and irregularly compared to the regular flow of data, messaging is an
intuitive mechanism for propogating these updates.

While each of the described components decomposes into its own 
subgraph, this high level description is enough to show the advantages
of a stream based implementation. For instance, the pipeline 
parallelism is exposed for both the steps involved in block decoding 
and the chrominance color channel processing. The splitjoin in the lower
part of the graph explicitly exposes the data parallelism present because
the color channels can be decoded independently. 

% done with addition

% I think the information in the very first paragraph on the decoder 
% about line counts and C comparison should get moved here and
% incorporated into the following paragraph - Matt 1/25/06

A noteworthy aspect of the StreamIt implementation is its
malleability. We illustrate this using two specific examples.  In the
first example, we focus on the video sampling rates. MPEG-2 streams
are encoded using a 4:2:0 sampling rate, which achieves a 50\%
reduction in the number of bits required to represent a video, with
little noticeable loss of color information. However, better quality
is possible with higher sampling rates since more color information is
retained from the original picture. In this paper, we describe how our
decoder implementation, originally designed to deal with a 4:2:0
sampling rate is modified for a 4:2:2 sampling rate.

In the second example, we describe a straight forward language-level
transformation that exposes the data-parallelism across macroblocks in
a picture. This is done in the context of the decoder pipeline which
consists of the inverse quantization, inverse DCT, and motion
compensator. We show that parallelism can be exposed at various levels
in the decoding process, from macroblock to block granularities, and
that the migration path is trivial.

\input{chroma}

\SubSection{Motion Compensation}

% Commented out this section since this information is incorporated into
% the decoder implementation section. - Matt 1/25/06
% An MPEG decoder accepts a bitstream as input and performs Huffman and
% variable run-length decoding (VLD).  This process results in a set of
% quantized, frequency-domain macroblocks and corresponding motion
% vectors.  The decoder inversely quantizes (IQ) the macroblocks and then
% performs an inverse DCT (IDCT) to convert the macroblocks to the
% spatial domain.  For predictively coded macroblocks (e.g., P and B
% pictures), the decoder performs motion compensation (MC) using the
% input motion vectors to find a corresponding macroblock in a
% previously decoded, stored reference picture. This reference
% macroblock is added to the current macroblock to recover the original
% picture data. If the current macroblock is part of an I or P picture,
% then the decoder stores it for future reference.
% Figure~\ref{fig:dec_block} illustrates the decode sequence.

%\begin{figure}[htbp]
%\centerline{\epsfig{file=dec_block.eps,width=5in}}
%\caption{Block diagram of MPEG-2 decode.}
%\label{fig:dec_block}
%\end{figure}

A simple strategy for parallelizing the MPEG-2 decoding can exploit
the data parallelism among macroblocks. Using this scheme, the Huffman
and run-length decoding is inherently serial, as macroblock boundaries
can only be discovered by performing the decode operation.  Once this
decode is complete, a parallel implementation can distribute
macroblocks to independent streams (using a splitjoin). Each stream
performs the inverse quantization, inverse discrete cosine transform,
and motion compensation. Furthermore, each stream locally stores
reference macroblocks for future motion compensation. Using this
strategy, the streams can execute independently with one exception.

% TODO: This is the figure showing the macroblock parallelism
% I'm not sure where it goes. - Matt
\begin{figure*}[t]
\vspace{-12pt}
%\epsfig{file=decoder_macroblock_parallelism.eps, width=3in}
%\epsfig{file=decoder-parallel.eps, width=\textwidth}
\epsfig{file=decoderpipeline.eps, width=\textwidth}
% TODO: Change Matt's 2 am caption.
\caption{MPEG-2 decoder exploiting macroblock-level parallelism.}
\label{decoder_macroblock_parallelism}
\vspace{-6pt}
\end{figure*}

This exception occurs when a stream is performing motion compensation
and the corresponding motion vector indicates a reference macroblock
stored in some other stream. In this case, inter-stream communication
is required to send the reference data to the requesting stream. This
situation is not uncommon, and is more prevalent for higher resolution
pictures. A simple scheme for handling this situation is for every
stream to broadcast its decoded macroblocks to all other streams. This
solution has the benefit of being conceptually easy to understand and
implement. StreamIt allows programmers to naturally expose such
parallelism. A StreamIt pipeline that operates at macroblock
granularity is shown in Figure~\ref{decoder_macroblock_parallelism}. It is
worthy to note that there is a high correlation between the stream
graph, and the StreamIt syntax describing the pipeline.

The implementation can be made more fine grained by exposing the
intra-macroblock parallelism. For example, the IQ-IDCT pipeline can
operate at a block level, rather than at a macroblock
granularity. This is easily achieved by encapsulating the IQ-DCT pipeline
within a splitjoin to scatter the blocks, operate, and gather the
results to recover the parent macroblock.

There are many implementation strategies for the decoder, each with
varying degrees of exposed parallelism. Of the greatest advantage of
the StreamIt implementation is its malleability. The stream graph is
easily reconfigured to operate at picture-level granularity (exposing
parallelism between chroma channels), macroblock level (exposing even
more data-level parallelism), or even at block level (exposing the
greatest amount of data-level parallelism). The modularity of the
language also affords the ability to cleanly define stream interfaces,
and reuse existing components. As an example, the zig-zag descrambler,
inverse quantizer, and inverse DCT components were all reused for our
JPEG codec implementation. The modularity also reduces the complexity
of the debugging process, as stream components can be functionally
verified independently, leading to greater programmer productivity.

%% TODO: add figure showing decoder pipeline at macroblock granularity
%% and streamit text ala Bill's beamformer/fmradio examples


