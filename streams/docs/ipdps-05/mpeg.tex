\Section{MPEG-2 Video Coding and Decoding}

MPEG-2~\cite{MPEG2} is a popular coding and decoding standard standard
for digital video data. The scheme is a subset of both the
DVD-Video~\cite{DVDVideo} standard for storing movies, and the Digital
Video Broadcasting specifications for transmitting HDTV and
SDTV~\cite{DVB}. The scheme is used by a wide variety of multimedia
applications and appliances such as the Tivo Digital Video
Recorder~\cite{tivo}, and the DirecTV satellite broadcast
service~\cite{directv}.

MPEG-2 encoding uses both {\it lossy} compression and {\it lossless}
compression. Lossy compression permanently eliminates information from
a video based on a human perception model. Humans are much better at
discerning changes in color intensity (luminance information) than
changes in color (chrominance information). Humans are also much more
sensitive to low frequency image components, such as a blue sky, than
to high frequency image components, such as a plaid shirt. Details
which humans are likely to miss can be thrown away without affecting
the perceived video quality.

Lossless compression eliminates redundant information while allowing
for its later reconstruction. Similarities between adjacent video
pictures are encoded using motion prediction, and all data is Huffman
compressed\cite{Huffman52}. The amount of lossy and lossless
compression depends on the video data. Common compression ratios range
from 10:1 to 100:1. For example, HDTV with a resolution of 1280x720
pixels and a streaming rate of 59.94 frames per second, has an
uncompressed data rate of 1.33 Gigabits per second. It is usually
compressed at a rate of 66:1, reducing the required streaming rate to
20 Megabits per second~\cite{imagevidstandards, Page 3}.

\SubSection{Encoding}
Encoded pictures are made up of pixels. Each 8x8 array of pixels is
known as a block. A 2x2 array of blocks is termed a
macroblock. Compression is achieved using
motion estimation, 2-dimensional discrete cosine transform (DCT) performed
on 8x8 blocks of pixels, quantization of DCT coefficients, and Huffman
and run/level coding. Pictures called I pictures are encoded without
prediction. Pictures termed P pictures may be encoded with prediction
from previous pictures. B pictures may be encoded using prediction
from both previous and subsequent pictures. A simplified MPEG-2
encoder is shown in Figure~\ref{fig:encoder-simple}.

The motion estimator calculates a
motion vector which represents the horizontal and vertical
displacement from the macroblock being encoded to the matching
macroblock-sized area in the reference picture.

The motion estimator then substract the matching block from the
current picture, on a pixel by pixel basis, from
the new macroblock entering the encoder. This forms a
residual signal that represents the difference between the
predicted macroblock and the actual macroblock being encoded. This
residual is often very small.

The residual is transformed from the spatial domain by a 2-dimensional
DCT.  The two dimensional DCT consists of separable vertical and
horizontal one-dimensional DCTs. The DCT coefficients of the residual
are then quantized in a process that reduces the number of bits needed
to represent each coefficient. Usually many coefficients are
effectively quantized to 0.

The quantized DCT coefficients are Huffman run/level coded which
further reduces the average number of bits per coefficient. This is
combined with motion vector data and other side information (including
an indication of I, P or B picture) and sent to the decoder.

{\bf need to introduce zig-zag ordering since i use it in the language
  section}

\SubSection{Decoding}

The decoding process is conceptually the reverse of the encoding
process. The input stream is is Huffman/run-level decoded. Motion vectors
are parsed from the data stream and fed to the motion
compensator. Quantized DCT coefficients are fed to the inverse
quantizer and then to an IDCT circuit that transforms them back to the
spatial domain. For P and B pictures, motion vector data is translated
to a memory address  by the motion compensator to read a particular
macroblock (predicted macroblock) out of a previously stored reference
picture. The adder adds this prediction  to the residual to form
reconstructed picture data. For I pictures, there are no motion
vectors and no reference picture, so the prediction is forced to
zero. For I and P pictures, the adder output it is fed back to be
stored as a reference picture for future predictions.

The highest level of organization within an MPEG-2 stream is a Group
of Pictures (GOP) which contains all the information needed to
reconstruct a video over some time span. A GOP contains three kinds of
pictures: Pictures which are coded independently of other pictures and
can be reconstructed without additional information are
{\it Intra-coded (I) pictures}. {\it Predictive-coded (P) pictures} must
be reconstructed using motion estimates from the immediately
preceeding I or P picture. {\it Bidirectionally predictive-coded (B)
  pictures} must be constructed using motion estimates from both the
previous and subsequent I and P pictures. I pictures are intended to
assist scene cuts, random access, fast forward, or fast reverse
playback\cite{MPEG2, Page 14 6.1.1.7}, B pictures provide the best
compression, and P pictures are a compromise between the two. A
typical I:P:B frame ratio in a GOP is 1:3:8.~\footnote{A typical
  picture sequence pattern is the indefinite repetition within a GOP
  of the subpattern "I B B P B B P B B P B B".} Pictures are not
ordered temporally within an MPEG-2 stream, but instead ordered such
that if a decoder encounters a P picture, the P picture's motion
prediction is with respect to the previously decoded I or P picture,
and if the decoder encounters a B picture, the B picture's motion
prediction is with respect the previously two decoded I or P pictures.

Pictures break up into 16x16 pixel {\it macroblocks}, themselves
composed of 8x8 pixel {\it blocks}. Macroblocks specify colors using a
{\it luminance} channel to represent saturation (color intensity), and
two {\it chrominance} channels to represent hue. MPEG-2 streams specify
a "chroma format" which allows the chrominance data to be sampled at a
lower rate - many applications use the "4:2:0 chroma format" which
represents a macroblock using four blocks for the luminance channel
and one block for each of the two chrominance channels. For P and B
pictures, blocks may be encoded independently, as a set of vectors
representing a motion estimate, or the combination of a set of motion
estimate vectors and a block representing the error between the motion
prediction and the desired reconstruction. Additionally, blocks in B
pictures may be motion predicted from either the previous reference
frame, the subsequent reference frame, or a linear combination of both
predictions.

For blocks that are independently coded or incorporate an error block,
each block is stored in the frequency domain using a Discrete Cosine
Transform (DCT). Before the frequency coefficients are stored, they
are quantized by dividing the block's coefficients by a quantization
matrix and throwing away the non-integer remainder. The values in the
matrix are based on the human ability to perceive different horizontal
and vertical frequencies.

All of the data in the various MPEG stream structures is entropy
encoded using Huffman tables to minimize stream size.

