Firstly, we would like to thank the reviewers for their careful
reviews and thoughtful suggestions to improve our paper.

We used the space-multiplexing and time-multiplexing analogy to help
the reader understand our research.  However, our work is not simply a
new point on a continuum. The SpaceTime model differs substantially
from traditional parallel execution models.  Traditionally,
time-multiplexed portions of a parallel program are mapped to a single
compute node and these portions are space-multiplexed across a
parallel target.  The SpaceTime model forms space-multiplexed slices,
which can occupy multiple compute nodes, and time-multiplexes them.
SpaceTime scheduling can balance latency and load-balancing concerns.
Due to the time-multiplexed outer loop, we can employ scheduling
techniques (in this case software pipelining) previously reserved for
scheduling instructions in a loop.

Our research is applicable to any multicore architecture but
especially for architectures with a fast on-chip communication network
(CELL, Merrimac, TRIPS, etc.).  For these architectures, forming
slices leverages the on-chip network necessary for scaling while
benefiting from flexible load-balancing and scheduling.  This is
unlike previous approaches that cannot make both claims (for example
Cilk's shared memory model). We use RAW to prove the validity of our
research, as a demonstration.  In the final paper, we will more
clearly present our general contributions and findings.

Reviewer 1 is concerned about the benchmarking baseline and asks how
it compares to a uniprocessor.  In previous work [Taylor et al., ISCA
04], it has been shown that a space multiplexing compiler for StreamIt
targeting RAW is 4.9x - 15.4x faster in terms of cycle count and 3.5x
- 10.9x faster in terms of time than a Pentium III across a benchmark
suite similar to the suite employed in this research. In this work we
show that we are on average 38% better than a space-multiplexing
approach.

Reviewer 3 asks why we did not compare to time-multiplexing only. If
we limit slices to one filter, we come close to approximating a
time-multiplexing baseline. However, even with one filter per slice,
there are many novelties in our system including software-pipelining
of slices across a parallel target. In the final paper, we will
rigorously investigate the effect of slice size by varying the
work threshold parameter (addressing Reviewer 1's comments regarding
this parameter).  We will show that the space-multiplexing component
of our SpaceTime model is essential because it reduces off-chip memory
traffic by utilizing on-chip communication resources.  This aspect
will become more pronounced as multicores scale up and the memory
bottleneck remains.

We agree with Reviewer 2, the organization and quality of the writing
needs to be improved, but Reviewer 2 is critical only of the
presentation.  

Dynamic input and output rates can be naturally and efficiently
supported by SpaceTime multiplexing.  This is one major benefits of
our SpaceTime model over space multiplexing.  It is straightforward to
limit dynamic i/o rates to the slice boundaries, allowing for load
balancing within a slice and off-chip buffering between dynamic rate
slices.

Reviewer 4 questions the generality of the system because we chose not
to support for feedbackloops at this time.  We chose not support
feedbackloops because they occur very infrequently in practice.  There
does not exist a fundamental limitation in our system that prevents us
from supporting them.  Feedbackloops are akin to loop-carried
dependencies which traditional software pipeliners respect.  The
presence of a feedbackloop would place a limit on the realizable
throughput of the stream graph.

The final version of the paper will include a more detailed
explanation of the results and the 3 outlier cases in which
space-multiplexing has higher performance than SpaceTime. Note that
with fine-tuning of our parameters these 3 benchmarks cease to be
outliers.

In response to Reviewer 2, the utilization metric includes stalls due
to cache accesses and pipeline hazards for each tile.  Each RAW tile
is a single-issue, inorder processor.  Pipeline stalls are frequent
and thus depress the utilization metric.  

Utilization should not be compared because space multiplexing adds
compute instructions necessary to implement filter fusion (the data
buffering and redistribution of filters mapped to a single node). In
SpaceTime this is achieved using the communication networks.  A
throughput comparison makes more sense.

We did not enable code optimizations (unrolling, constant propagation,
and scalar replacement) for space-multiplexing because we did not have
these optimizations implemented in the SpaceTime compiler.  Thus,
the comparison would be unfair.  It is unclear which approach will
benefit more from these optimizations. 

