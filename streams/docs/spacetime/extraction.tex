\section{Slice Extraction}
\label{sec:extract}
Slice extraction refers to the process of assigning each joiner,
filter, and splitter of the stream graph to a slice.  As stated
previously, a slice is a contiguous section of the stream graph that
is scheduled for execution as a group. Each slice occupies a portion
of the chip as it executes and is ``swapped out'' when it completes
execution, not to execute again until the next steady-state.  Each
filter in the stream graph is a member of exactly one slice.

An informal English description of our slice extraction algorithm
should suffice.  We traverse the stream graph in depth-first order.
Each time we visit a node, we must decide if the node should be added
to the slice we are currently constructing.  Due to the restrictions
of the current implementation, as we traverse the stream graph, we end
the current a slice {\it before} a joiner node and we end the current
slice {\it after} a splitter node, thus restricting the slices to
pipelines of filters.  Also, as we are adding filters to the slice, we
must introduce a slice boundary if the size of the slice is equal to
the number of tiles in the Raw configuration.

Additionally, we try to coax the generation of load-balanced slices.
For each filter, we calculate a static work estimation of the filter
based on an analysis of the {\tt work} function
\cite{streamit-asplos}.  Because of the static I/O (push, pop, and
peek) rates in this version of StreamIt, most loop bounds within {\tt
work} can be resolved, allowing a close approximation of the actual
cycle count.  This estimate is multiplied by the number of times the
filter executes in the steady-state.

As we are adding filters to the slice, we compare the work estimation
of the current filter we are examining to the work estimation for the
filter of the slice that performs the most work (the current {\it
bottleneck} of the slice).  If the ratio of the work of the current
filter to the work of the bottleneck is within a predefined
threshold, termed the {\it work threshold}, then we proceed to add the
filter to the slice.  Otherwise, begin a new slice with the current
filter as the first filter in this new slice. In the case where a
slice will end in a filter, we will insert a dummy splitter at the end
of the just-completed slice.  Conversely, if needed, we will insert a
dummy joiner at the beginning of a newly created slice if the slice
begins with a filter.

Any data-flow arcs that existed from splitters and to joiners will
persist as arcs to nodes of other slices.  The arcs of the introduced
splitters and joiners assume the connections of their insertion point.

\todo{What value of work threshold do we use or do we experiment?}
