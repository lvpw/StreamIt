// can be followed by a clusterer to further detect similarities
// BETWEEN segments

For an example
--------------

- looking at beamformer
- looking at complex sort
	- sort by real, grouping by complex conjugate
	- sort first by magnitude, then by phase angle
	- but this isn't going to be perfect because of data-dependent control flow

- getting trace of matrix - only sum along diagonal

- cumulative product - there's an interesting loop-carried dependence
that gets reset each time; but output the elements along diagonal.
Same with cumsum.

- adjacent differencing - difference all elements of an array, but not
across elements.  still this could keep a counter instead to tell
where end of matrix is, but you'd have to detect the cycle period of
the difference.

- convolutions also have the property that the k'th element output is
dependent on 1..k of both inputs

- problem with loop thing: if we do dependence tracking around a loop,
then would have to enumerate all loop iterations before knowing which
ones we could really execute?  lose the parameterization... e.g. how
do you do the decimation propagation backwards 

- cosine distance:  (1-x_r x_s') / ( (x_r x_r')^.5 (x_s x_s')^0.5


---

 - execution on Raw - basically do filter fission using the SARE and
then schedule the resulting graph; this could be part of the combined
load balancing paper (maybe round 2)

- execution on any other kind of target?

- minimal makespan of the schedule (but what was previous minimum?
executing each in parallel?)

- think about the fission thing for the sake of eliminating
synchronization.

Low Priority
------------

x I don't like the $m_n$, etc. notation.  Can we just leave them
unbounded?  Or make the nodes something other than "n"'s so that these
can be "n"'s.

x Would it be clearer if push/pop/peek were an aspect of a node?  I think maybe.

****************************************************************************

Theoretical problems:
---------------------

What if you're passing a structure or array over the tape?  Any way to
resolve the dependences then?

NOTES
-----

First let's do SDF with peeking -- in this case, it's just a
computation graph:

operation O_k associated with each node n_k

for every branch d_p from n_i to n_j

initially have A_p items on the branch
node n_k (dest) pops W_p items
node n_k (dest) peeks T_p items
node n_i (src)  pushes U_p items

----------------

so if there's static control flow in a node, then you can convert all
nodes to a canonical form like this, for nodes k

--

for all p s.t. there exists d_p : n_j -> n_k:
  for i = 1 to T_p
    in_p[i] = peek(i)
  for i = 1 to W_p
    pop()

// use <in>'s, write to <out>'s

for all p s.t. there exists d_p : n_k -> n_j:
  for i = 1 to U
    push( out_p[i] )

--

assume that there are no name conflicts between the bodies of
different filters.

then you can convert this to as follows.  first, there is an initial
configuration of each channel in the program:

----
for all p
  for i = 1 to A_p
    chan_p[i] = initial-value(p, i)
----

then, there is the code for each node:

----
for all p s.t. there exists d_p : n_j -> n_k:
  last_p = A_p

for m = 1 to steady_k

  for all p s.t. there exists d_p : n_j -> n_k:
    for i = 1 to T_p
      in_p[i] = chan_p[(m-1)*W_p + i]

  // use <in>'s, write to <out>'s

  for all p s.t. there exists d_p : n_k -> n_j:
    for i = 1 to U_p
      chan_p[(m-1)*U_p + i] = out_p[i]
----

can solve balance equations to get steady_k: how many times node k
executes in the steady state

---

new realizations:

- even with a single affine schedule, you can do initialization with
different start times

- could do zero-one programming with different loop structures to see
a single-appearance schedule?  (is there a way to guarantee
single-appearance in what's generated from an affine schedule?  this
would be useful for the affine scheduling community, too.)
