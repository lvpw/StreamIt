Stream programming offers an attractive way to exploit coarse-grained
parallelism, as the filters that comprise an application are
independent, and communication between filters is regular and
repeating. Data-parallelization of appropriate filters has the
potential for computational scalability, but the global communication
and synchronization requirements of such techniques must be carefully
considered.  It is important that the language exposes as many
opportunities for data-parallelization as possible. For instance, the
peek idiom found in many streaming languages allows the compiler to
data-parallelize sliding-window computations that would otherwise have
loop-carried dependencies.  However, doing so is difficult because of
the complex communication and synchronization patterns that are
required.

In this paper we present a new technique for data-parallelizing a
filter that performs a sliding-window computation. Traditionally,
input data remaining in the sliding window between iterations cause a
loop-carried dependence, preventing automatic
data-parallelization. Our technique intelligently converts this
loop-carried state into inter-core communication of duplicated input
data to parallelized constituent filters.  We evaluate the technique
in the context of our stream compiler which targets Tilera's 64-core
Tile64 architecture.  We show that our new technique offers
significant performance improvement when compared to a previously
published approach that also duplicates input data.  Furthermore, we
demonstrate that our compiler achieves near-linear scalability across
our benchmark suite as we increase the number of cores.


