\section{Introduction}

The trend of processors with multiple cores on a chip is continuing
and all processor roadmaps are toward processors with more and more
cores on a chip. As the number of cores increases, so will the
decoupling between cores such that shared storage occurs further away
from the cores. A commercial example of such an architecture that is
available today is the Cell~\cite{cell} processor with 8 cores each
with its own local storage and a DMA engine to manage data movement in
and out of its local store. Another commercial decoupled multicore
processor is the Tile64~\cite{tilera} chip with 64 cores.

Multicores require partitioning of the application code so that there
is an adequate number of code fragments that can occupy the available
cores, increasing utilization and ultimately improving application throughput.
Each code fragment requires its own data chunk to compute on, and
produces its own chunk which may be shared with other code fragments.
Scheduling involves assigning code and data onto a core as well as
managing the communication between cores.

Decoupled multicore architectures require careful scheduling:
partitioning and assignment of the application code and data working
sets so that code and data are collocated onto the same core for
efficiency. There are two extreme scheduling paradigms. A
static scheduler orchestrates execution offline. It partitions a given application and
orchestrates a static plan that assigns code chunks to a core, fixes the
order of code firings and also manages the flow of data between
cores. In contrast, a dynamic scheduler makes all of its decisions at
runtime. It decides on the mapping, the ordering, and dataflow.

Static scheduling works well for applications with lots of explicit
parallelism and exposed communication patterns that can be easily
profiled so that a static scheduler can make informed decisions
relating to load balancing, and hiding communication latency.
Static scheduling is considered a good option when there are
reasonable guarantees that there is little variance in terms of the
static assumptions that are made. We will show however in this paper
that variance can be easily mitigated in a static scheduling regime.

Dynamic scheduling in contrast side steps the issue variance by virtue
of running alongside the application. A basic conceptual view of a
dynamic scheduler is that it maintains a pool of work, and it
dispatches that work as processing cores become available. There is a
large body of work covering dynamic scheduling, and the concept
continues to command considerable attention since there are some
fundamental drawbacks to a dynamic scheduling approach. Two
disadvantages in particular are noteworthy. Arguably, a dynamic
scheduler is relatively easy to implement if it can maintain a
centralized internal representation of resources, computation, and
data locations in storage. These are necessary to track because a
scheduler will eventually have to check if some chunk of work can be
fired based on its set of data and control dependences, and available
resources which can include available storage to buffer output date.
However maintaining a centralized data structure can severaly limit
the scalability of the approach. To decentralize the scheduler
requires parallelizing the implementation and this can be a
substantial endeavor. There is prior work on decentralized and
distributed scheduling models, and they may prove successful.
Another potential drawback is that a dynamic scheduler can result in
very large memory footprints because it may have to keep a buffer
around for a long period of time until the consumer of that buffer
runs. This effect can have substantial impact in setting where the
memory is limited, such as in embedded systems.

\subsection{contributions}

\begin{itemize}

\item developed a framework for mapping applications to decoupled
  multicores that admits both static schedules or constructs dynamic schedules

emphasis on stream computing

why stream computing is a good 

\item evaluation of some scheduling strategies: stream graph patterns
  to faciliate static scheduling

\item work estimation and variance analysis

\item evaluation of static vs dynamic scheduling for different stream
  graph patterns

\end{itemize}

