\section{Tolerating Variance With Static Schedules}

A particular challenge that a static scheduler faces is posed by the
work estimation $W_X$ required for an actor $X$. An efficient static
schedules requires an effective work estimation methodology. Previous
work in feedback directed optimizations has shown that profiling is a
practical approach to characterizing applications. There are numerous
examples of profiling used for various compiler optimizations such as
inlining, unrolling, data prefetching, trace formation, etc. And prior
related work on scheduling of stream graphs has shown that good static
estimation of work is
feasible~\cite{mgordon-asplos04,mgordon-asplos06}.

In the case of the patterns shown in the previous section, variance in
the expected work duration of an actor can lower utilization and
throughput when actors communicate across processor
boundaries. Inter-processor communication requires a shared buffer
where data is stored by the producing actors. If the buffer is full
and the producing actors get ahead of the consumers, they cannot write
to the buffer and hence they will block; similarly if the producers
are slow and the comsumers are fast because of work firing variance.

However, it possible to compensate for the variance by simply creating
extra {\it slack} between the two processors. Slack is essentially
allowing the shared buffer to be larger than the size mandated by the
schedule. As the slack increases, or in other words, the maximum
allowed buffer size is increased, the static schedule becomes more
resillient to variance and can maintain high utilization and sustain
throughput.

\begin{figure}[t]
\begin{center}
\psfig{figure=variance.eps,height=3.5in}
\caption{{\small Simulated utilization for the schedule of Pattern 6 on 
a 2-core processor.  Each actor has an average work of 10 units. The
runtime work of the producer (stateful) actor is varied by a given
distribution: (1) 50\% 5 units, 50\% 15 units;
(2) 99\% 0 units, 1\% 1000 units; (3) Normal distribution with $\sigma$ =
1; and (4) Normal distribution with $\sigma$ = 10.
\protect\label{fig:variance-chart}}}
\end{center}
\end{figure}

We emperically tested and observed this phenomena using both
simulations of the patterns and through actual implementations and
measurements on a Cell processor.  In Figure \ref{fig:variance-chart}
we show the results of our simulations on Pattern 6.  In this
simulation, each of the actors in the pattern have equal average work,
but we vary the work of the producer (stateful) actor by a
distribution centered around the average.  The rates of the actors are
matched with the producer producing 1 item and the consumer consuming
1 item per execution.  From the figure, we can see that for three of
distributions, introducing small amounts buffering allows the schedule
to achieve near 100\% utilization.  The remaining distribution has
very high variance, but if we allow enough buffering (256 elements),
we can achieve over 95\% utilization.
