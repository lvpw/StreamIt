\subsection{Preliminary Results}
\label{sec:results}

\begin{figure*}[!t]
\centering
\begin{minipage}{3.0in}
\centering
\psfig{figure=speedup-graph.eps,width=2.95in}
\caption{\protect\small StreamIt throughput on a 16-tile Raw machine,
normalized to throughput of hand-written C running on a single Raw
tile.  \protect\label{fig:compare-raw}}
\end{minipage}
~
\hspace{0.1in}
\begin{minipage}{3.0in}
\centering
\psfig{figure=throughput-graph.eps,width=2.95in}
\caption{Throughput of StreamIt code running on 16 tiles and C code
running on a single tile, normalized to throughput of C code on a
Pentium IV. \protect\label{fig:compare-pentium}}
\end{minipage}
\end{figure*}

We evaluate the StreamIt compiler for the set of applications shown in
Table~\ref{tab:benchmarks}; our results appear in
Table~\ref{tab:performance}.

%  For each benchmark, we show the number of
%lines of StreamIt code, the occurrence of each stream construct, and
%the number of nodes required to execute the expanded graph on Raw.
For each application, we compare the throughput of StreamIt with a
hand-written C program, running the latter on either a single tile of
Raw or on a Pentium IV.  For Radio, GSM, and Vocoder, the C source
code was obtained from a third party; in other cases, we wrote a C
implementation following a reference algorithm.  For each benchmark,
we show MFLOPS (which is N/A for integer applications), processor
utilization (the percentage of time that an {\it occupied tile} is not
blocked on a send or receive), and throughput.  We also show the
performance of the C code, which is not available for C programs that
did not fit onto a single Raw tile (Radar, GSM, and Vocoder).
Figures~\ref{fig:compare-raw} and~\ref{fig:compare-pentium} illustrate
the speedups obtained by StreamIt compared to the C
implementations\footnote{FFT and Filterbank perform better on a Raw
tile than on the Pentium 4.  This could be because Raw's single-issue
processor has a larger data cache and a shorter processor pipeline.}.

The results are encouraging.  In many cases, the StreamIt compiler
obtains good processor utilization--over 60\% for four benchmarks and
over 40\% for two additional ones.  For GSM, parallelism is limited by
a feedbackloop that sequentializes much of the application.  Vocoder
is hindered by our work estimation phase, which has yet to accurately
model the cost of library calls such as {\tt sin} and {\tt tan}; this
impacts the partitioning algorithm and thus the load balancing.  3GPP
also has difficulties with load balancing, in part because our current
implementation fuses all the children of a stream construct at once.

StreamIt performs respectably compared to the C implementations,
although there is room for improvement.  The aim of StreamIt is to
provide a higher level of abstraction than C without sacrificing
performance.  Our current implementation has taken a large step
towards this goal.  For instance, the synchronization removal
optimization improves the throughput of 3GPP by a factor of 1.8 on 16
tiles (and by a factor of 2.5 on 64 tiles.)  Also, our partitioner can
be very effective--as illustrated in Figure~\ref{fig:beam-blood},
partitioning the Radar application improves performance by a factor
of 2.3 even though it executes on less than one third of the tiles.


The StreamIt optimization framework is far from complete, and the
numbers presented here represent a first step rather than an upper
bound on our performance.  We are actively implementing aggressive
inter-node optimizations and more sophisticated partitioning
strategies that will bring us closer to achieving linear speedups for
programs with abundant parallelism.

