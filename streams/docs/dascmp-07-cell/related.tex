\section{Related Work}\label{ch:bg}

Streaming languages provide an attractive alternative to sequential
languages for many applications. In a streaming language, the
programmer defines actors that operate on data streams and composes
programs by connecting actors. Many common high-performance
applications, especially those involving signal, audio, image, and
video processing, have explicit block diagram structure and are most
easily conceptualized in that manner, making streaming languages a
natural choice for these applications.
Because programs written in streaming languages are explicitly
structured as communicating actors, they typically expose a high
degree of parallelism. This allows streaming language compilers to
easily analyze stream programs and efficiently parallelize
them. Compared to sequential languages, streaming languages free
programmers from the burden of having to explicitly write parallelized
code for specific architectures, allowing them to focus on expressing
the high-level semantics of the algorithm in a natural way.
Recent developments in streaming languages include Brook~\cite{brook},
Cg~\cite{cg}, StreamC/KernelC~\cite{streamc}, and StreamIt~\cite{streamitweb}.
The MSL is not tied to any particular language choice and simply
relies on the expression of computation as a dataflow graph.
 
MPI and OpenMP are arguably the most well-known and widely used
parallelization frameworks for computing clusters and traditional SMP
architectures. These two programming APIs represent opposite ends of a
spectrum: MPI defines a language-independent, low-level network
communication API, while OpenMP defines a set of  high-level
annotations that programs can use to direct compatible compilers to
generate multi-threaded code.  The multicore streaming layer and
library are intended to provide the same kind of low-level
functionality as MPI, with two major differences: \emph{i}) they are
more naturally suited for multicores rather that clusters, and
\emph{ii}) they are specific to streaming applications and hence provides
more targeted control functionality.

The work presented here also complements parallelization frameworks
that have been designed specifically for multicores or Cell; see
\cite{cell:pf} for a review. RapidMind~\cite{rapidmind} and MPI
Microtask~\cite{mpimicrotask} follow a ``task-based'' approach by
providing runtime systems that help schedule program-defined tasks, or
kernels. Mercury's MultiCore Framework~\cite{mcf} adopts a similar
approach. However, it is primarily designed for exploiting data
parallelism in large matrix computations instead of streaming.
CellSs~\cite{cellss} attempts to automatically generate tasks from
annotations to linear code. Sequoia~\cite{sequoia} is a language that
exposes an abstract hierarchical memory model and allows the
programmer to define communication and local computation; its compiler
and runtime system can efficiently execute Sequoia programs on
Cell. The MSL allows for the exploration of various scheduling
methodologies for executing programs on multicores.

The Stream Virtual Machine (SVM) also aims to simplify compilation to
diverse multicore architectures~\cite{svm:specs,svm}.  As a specification,
the SVM is more general than the MSL, encompassing a broader class of
architectures and applications while potentially incurring higher
runtime overhead.  The SVM supports a rich parameterized machine model
encompassing FIFO interconnects, specialized DMA processors, and
hierarchical control processors, while the MSL targets regular
distributed-memory machines with a single control processor and
implicit DMA between processors.  A complete implementation of the SVM
must support automatic flow control, end-of-stream markers, and
suspension/termination of filters; the MSL elides these functions
because they complicate the interface and are difficult to implement
efficiently.  The MSL API simplifies the tracking of filter
dependences by assigning a unique identifier to each {\it command}
instance, rather than tracking the underlying filters and sometimes
depending on the state of those filters (as in the SVM).  Finally, the
MSL was designed from the beginning to be implemented as a standalone
library; while a library implementation is also possible with the SVM,
the specification was influenced by an intention to employ a
special-purpose ``low-level compiler'' to process the client code.

Gummaraju and Rosenblum map a stream execution model based on the SVM
to a general purpose processor~\cite{streamgpp}. The mapping 
is similar to a ``low-level compiler'' that interfaces between the SVM
and the target architecture. It abstracts out processors and memories, 
and in particular supports hyper-threaded processors with multiple
hardware contexts. However, because the goal is to map stream
programs to general purpose processors, many mapping techniques are specific to
such single-core commodity CPUs.


%%XXX TODO: add SVM and MERCURY 
