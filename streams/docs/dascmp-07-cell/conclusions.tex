\section{Conclusions \& Future Work}\label{ch:conc}

Streaming languages provide an excellent way to
target new multicore architectures while placing minimal
parallelization burden on the programmer. Multicore architecture such
as Cell that are designed to offer high peak performance are well
suited for streaming applications. This paper described a runtime
framework for streaming applications on multicores consisting of
\emph{i}) a common Multicore Streaming Layer (MSL) that provides
high-level primitives for schedulers, \emph{ii}) an implementation
of the MSL for an existing processor, namely Cell, \emph{iii}) a
lightweight dynamic scheduler for stream graphs, and \emph{iv}) a
static scheduler for stream graphs. The framework greatly
simplifies the task of a streaming language compiler or scheduler.

The real benefit provided by the framework, in particular the MSL
runtime library, is that it allows a scheduler to think directly in
terms of filters and how they are scheduled instead of lower-level
architecture-specific details. It requires far less code to implement
scheduling patterns on top of the library than directly on Cell
hardware for example, and the MSL library also allows far more complex
patterns to be implemented than directly at a lower level.
 The library running the data-parallel
fused FFT benchmark produces a reasonably small amount of overhead
(1.2\%), and the dynamic scheduler running the pipelined version of
the benchmark produces an acceptable amount of overhead (8.6\%).

The MSL library currently provides two orthogonal branches that can be
further developed. First, it is important to reduce the 9\% overhead
observed in the pipelined FFT tests involving the dynamic
scheduler. This overhead is entirely due to the cost of the run list
when many commands are active, and it can probably be significantly
reduced by optimizing library code, although it is also likely that
doing so would make the SPE library implementation, especially the run
list, much more specialized.

In addition, the implementation currently lacks real support for
filters with dynamic rates -- the library simply leaves the
responsibility of tracking rates to the scheduler entirely. Feedback
from the library on how much data filters have produced and consumed
would be very useful for schedulers; ultimately, the library should
have some way of running filters with unbounded dynamic rates. The
latter would require a general mechanism to suspend dynamic rate
filters in the middle of executing their work functions.

The dynamic scheduler can be extended in many directions. The simplest
additions involve adjusting the metric used for selecting filters to
test and improve the performance of the dynamic scheduler as work
becomes more and more imbalanced between filters. In addition, an
important advantage of dynamic scheduling in general is the ability to
react to dynamic rate filters and the runtime distribution of work in
the stream graph; implementing robust support for dynamic rate filters
in the stream graph would drastically increase its usefulness.
