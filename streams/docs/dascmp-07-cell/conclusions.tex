\section{Conclusions and Future Work}\label{ch:conc}

Streaming languages provide an excellent way to
target new multicore architectures while placing minimal
parallelization burden on the programmer. Multicore architectures such
as Cell that are designed to offer high peak performance are well
suited for streaming applications. This paper described a runtime
framework for streaming applications on multicores consisting of
\emph{i}) a common Multicore Streaming Layer (MSL) that provides
high-level primitives for schedulers, \emph{ii}) an implementation
of the MSL for an existing processor, namely Cell, \emph{iii}) a
lightweight dynamic scheduler for stream graphs, and \emph{iv}) a
static scheduler for stream graphs. The framework offers automatic
management and optimization of communication, and greatly
simplifies the task of a streaming language compiler or scheduler.

The real benefit provided by the framework, in particular the MSL
runtime library, is that it allows a scheduler to think directly in
terms of filters and how they are scheduled instead of lower-level
architecture-specific details. We found that it required
far less code to implement scheduling patterns on top of the library
than at a lower level on Cell. The MSL library also
allows for far more complex patterns to be implemented than is
directly feasible at a lower level. The library running the
data-parallel fused FFT benchmark produces a reasonably small amount
of overhead (1.4\%), and the dynamic scheduler running the pipelined
version of the benchmark produces an acceptable amount of overhead
(11.2\%).

The MSL library currently provides two orthogonal branches that can be
further developed. First, it is important to reduce the 12\% overhead
observed in the pipelined FFT tests involving the dynamic
scheduler. This overhead is entirely due to the cost of switching
between commands when many are active, and it can probably be significantly
reduced by optimizing library code.

In addition, the implementation currently lacks real support for
filters with dynamic rates (i.e., I/O rates that change over time and
across executions). The library simply leaves the responsibility of
tracking rates to the scheduler entirely. Feedback from the library on
the amount of data produced and consumed by individual filters
would be very useful for schedulers; ultimately, the library should
have some way of running filters with unbounded dynamic rates. The
latter requires a general mechanism to suspend dynamic rate filters in
the middle of executing their work functions.

The dynamic scheduler can be extended in many directions. The simplest
additions involve adjusting the metric used for selecting filters to
test and improve the performance of the dynamic scheduler as work
becomes more and more imbalanced between filters. In addition, an
important advantage of dynamic scheduling in general is the ability to
react to dynamic rate filters and the runtime distribution of work in
the stream graph; implementing robust support for dynamic rate filters
in the stream graph would drastically increase its usefulness.
