\section{Optimization}
\label{sec:optimization}

We now turn our attention to the problem of optimizing a stream program.
Unlike other program domains, where the principle aim of compiler
optimization is to shorten the total execution time, there are many
distinct optimization metrics for streaming applications, including
throughput, latency, data size, and code size.  The latter two of these
are especially important in embedded domains, where memory is in short
supply; latency can be critical for real-time applications, and
throughput is always of interest.

% here's a more verbose version...
%
%These include: 1) {\bf Throughput}, the number of items passing
%through the stream per unit time, 2) {\bf Latency}, the amount of
%elapsed time (or consumed data) before the effects of an input item
%are seen at the output, 3) {\bf Data size}, the buffer space required
%to hold live items, and 4) {\bf Code size}, the space consumed by
%instructions.

In this section we present some transformations that improve a stream
program by one or more of these metrics.  However, there is often a
tradeoff between throughput and latency, or code size and data size,
such that the optimality of a stream program depends on the metric of
interest.

\subsection{Fusion Transformations}

A primary stream optimization is the fusion of multiple filters and
streams into a single atomic unit.  This can be beneficial for
throughput, latency, and data size, as data buffers are eliminated in
favor of local variables with short live ranges.  Fusion is also
important for adapting a fine-grained stream program to a
coarse-grained target; the programmer benefits from dividing the
program into many modular components without losing the performance of
a single, integrated procedure.

An algorithm for fusing a pipeline of two filters that contain only {\tt
push} and {\tt pop} statements is given in \cite{pro96}.  However, in a
stream program, it pays to consider not only vertical fusion of pipeline
constructs, but also horizontal fusion of parallel streams in a
SplitJoin.  Here we present a transformation on the abstract syntax of
Section \ref{sec:intalgebra} that collapses a SplitJoin construct
containing $n$ parallel filters $s1 \dots sn$ into a single filter $sc$.
Let us denote the weights of the joiner $J$ by $w_1 \dots w_n$ with $W =
\sum_{i=1}^{n}{w_i}$: \\ \vspace{-6pt}
\begin{align*}
Merge[(S~s1~\dots&~sn~J)] \\ = (\mbox{in~Filter}&~push_{sc}~pop_{sc}~peek_{sc}~work_{sc}) \\ \vspace{-12pt} \\ 
where: {\bf push_{sc}} &= totalRounds * W \\
       {\bf pop_{sc}} &= totalPop ~~~~~~~~~if~S~=~RoundRobin \\
                &= totalPop / n ~~~~~if~S~=~Duplicate \\
       {\bf peek_{sc}} &= MAX_{j \in [1,push_{sc}]}(shift_j(peek_{sj})) \\
       {\bf work_{sc}} &= h_{sc, 1} \dots h_{sc, push_{sc}} \\
       totalRounds &= lcm(lcm(push_{s1}, w_1), \dots, lcm(push_{sn},
       w_n)) \\
       totalPop &= \sum_{i=1}^{n}(totalRounds * w_i * pop_{si} / push_{si}) \\
       shift_j(x) &= \mi{I_S}{I_{sj}}(x + \\ &~~~~~(\mi{I_{sj}}{O_{sj}} \circ \mi{O_{sj}}{O_J})(j)-peek_{sj}) \\
       h_{sc, j} &= \la~g~.~h_{s,p(j)}(\la~i_{local}~.~shift_j(g(i_{local})))
\end{align*} \vspace{-6pt} \\ 
We have proven that this transformation preserves the meaning of the
program with respect to our transform algebra for the case when $n = 2$,
$w_1 = w_2 = 1$, and $S$ is a duplicate splitter.  The proof involves
only straightforward algebra, but we omit it due to space constraints.

This transformation is very powerful--it allows us to fuse any set of
parallel filters in a SplitJoin construct into a single filter,
regardless of the splitter/joiner types and the push/pop/peek
requirements.  We have implemented this transformation in the StreamIt
compiler for cases with a duplicate splitter and filters with output
rates matching the joiner's weights; performance improves significantly
(see Section \ref{sec:results}) due to decreased channel operations.

In the sections that follow, we give an overview of other optimizations
that we are implementing in the StreamIt compiler.  Due to space
limitations, we cannot describe them at the above level of detail.

% We've implemented:  collapse $n$ filters, if:
%
% The splitter is a duplicate and the joiner is some form of
% round robin.  Each child stream pops 1, and pushes the same
% number as the round robin ratio.  I think we also require
% the child streams to be filters.

\subsection{Fission Transformations}

When the machine target is more fine-grained than the stream graph, it
is advantageous to break filters up into smaller pieces so that more
hardware resources can be utilized.  We propose three fission
transformations:
\begin{enumerate}
\item {\bf Parallelizing stateless filters.}  If a filter has no state,
  then we can gain data parallelism by duplicating the filter $n$ times
  and embedding it in an $n$-way SplitJoin with a round robin splitter
  and joiner.
\item {\bf Parallelizing stateless feedback loops.}  If the body of a
  feedback loop is stateless and its input/output rates evenly divide
  the delay of the loop, then the entire loop can be replicated and
  parallelized as in (1), with the quantity and delay of the new loops
  being (approximately) equal to the quotient of the old delay and the
  body stream's I/O rates.  This exploits the fact that for certain
  feedback loops there are interleaved subsequences of the input stream
  that are transformed completely independently by the loop.

\item {\bf Splitting stateful filters.}  If a filter has persistent
  state, we can still gain pipeline parallelism by breaking the the
  filter into an $n$-stage pipeline in which the state is communicated
  through the data channels.
\end{enumerate}

\subsection{Steady-State Invariant Code Motion}

In the streaming domain, the analog of loop-invariant code motion is the
motion of code from the steady-state {\tt work} function to the {\tt
init} function if it does not depend on any quantity that is changing
during the steady-state execution of a filter.  Quantities that the
compiler detects to be constant during the execution of {\tt work} can
be assigned to fields in the {\tt init} function and then referenced
from {\tt work}.

\subsection{Induction Variable Detection}

The {\tt work} function can also be analyzed as would the body of a loop
to see if there are induction variables from one steady-state execution
to the next.  This analysis is useful both for strength reduction, which
{\it adds} a dependence between invocations by converting an expensive
operation to a cheaper, incremental one, as well as for data
parallelization, which {\it removes} a dependence from one invocation to
the next by changing incremental operations on filter state to
equivalent operations on privatized variables.

\subsection{Decimation Propagation}

Decimation refers to the regular discarding of a fraction of a filter's
input items, perhaps to reduce the sampling rate in a stream.  In the
streaming domain, the analog of dead code elimination is the propagation
of this decimation up through the stream graph, thereby eliminating the
computations that produce the unused items.

\subsection{Synchronization Removal}

In a StreamIt graph, the SplitJoin construct provides a way to define
independent units of parallel computation.  However, when two SplitJoins
$s_1$ and $s_2$ are connected in a pipeline, there is a joiner/splitter
pair that serializes all of the items passing from $s_1$ to $s_2$.  If
the joiner of $s_1$ and the splitter of $s_2$ are both round robins with
equal weights, then this node can be eliminated in favor of a single
SplitJoin $s_c$ with the $i$'th parallel stream in $s_c$ being a
pipeline of the corresponding streams in $s_1$ and $s_2$.

