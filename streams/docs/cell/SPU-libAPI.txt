StreamIt-Cell SPU Library API (working draft - do not distribute)
David Zhang, Rodric Rabbah, Bill Thies


Contents:

1. Overview
   1.1. API summary
2. Objects
   2.1. Filters
   2.2. Buffers
3. SPU management
   3.1. SPU commands
   3.2. Scheduler interface
   3.3. SPU event loop
   3.4. SPU local store
4. SPU command/library function API
   4.1. Special library functions
   4.2. Filter management
   4.3. Buffer management
   4.4. Querying status
   4.5. Work functions
5. Examples


1. OVERVIEW
-----------

The goal of the SPU library is to provide an interface that "automates" much of
the work involved in running filters on SPUs and transferring data between
them.

The interface is intended to be general enough that any type of scheduler can
be implemented: from a fully static schedule with the scheduler controlling all
data transfer, to a fully dynamic schedule with the SPUs automatically
time-multiplexing multiple filters and transferring data between themselves.

In addition to filters running on SPUs, some filters may be more suited for
execution on the PPU (e.g., any filter that does I/O or splitters/joiners with
very many outputs/inputs). A similar interface can be implemented for managing
PPU filters. This document only focuses on issues regarding SPU filters.


1.1. API summary
----------------

load_code
  Loads filter code/parameters onto an SPU
filter_load
  Loads a filter onto an SPU
filter_unload
  Unloads a filter from an SPU
filter_attach_buffer
  Attaches/detaches a filter tape to a buffer
filter_run
  Runs a filter's work function
buffer_alloc
  Allocates a buffer on an SPU
buffer_dealloc
  Deallocates a buffer on an SPU
data_transfer/data_transfer_in/data_transfer_out
  Transfers data between buffers

Miscellaneous:

spu_set_update_rate
  Sets the rate at which SPUs update status information
(filter_query)
  Set of functions to query filter performance counters
(buffer_query)
  Set of functiosn to query buffer status information


2. OBJECTS
----------

The library manages 2 types of objects: FILTERS and BUFFERS. Both are exposed
to the scheduler in varying ways.

Filters are self-explanatory. Filter objects are created when the stream graph
is initialized, and exist for the lifetime of the program.

Buffers store data items. Unlike filter objects, buffer objects are transient:
they are allocated and deallocated by the scheduler as the program executes.
Conceptually, at any time a buffer is either an INPUT, OUTPUT, or SHARED
buffer. An input buffers is a buffer intended to be attached to an input tape
of a filter; an output buffer is intended to be attached to an output tape of a
filter; and a shared buffer is intended to be attached to the output tape of
one filter and the input tape of another. Input and output buffers are only
allocated in an SPU's local store; shared buffers can be allocated in SPU local
store or memory (in the latter case, the buffer is called a MEMORY buffer).
Note, however, that for each buffer that is allocated the library keeps a data
structure in memory.


2.1. Filters
------------

n->m filters are supported: the filter reads from n input "tapes" and writes to
m output tapes. 

At any time, an SPU filter may be loaded on at most one SPU. A filter must be
loaded before its work function can be run. Allowing filters to be loaded
separately from running them allows a scheduler to efficiently time-multiplex
filters, as long as their code and buffers do not occupy too much local store.
Before a loaded filter can be run, its tapes must be attached to buffers.


2.2. Buffers
------------

Buffers have a fixed size specified at allocation and act as circular queues of
data items. The use of the terms input, output, shared, and memory to classify
buffers is purely descriptive.

A filter running on an SPU can read data items from its input buffer(s) and
write data items to its output buffer(s). In a producer-consumer pair running
on different SPUs, data must be transferred from the producer's output buffer
to the consumer's input buffer. In addition, data can be be transferred from
either buffer to a separate memory buffer (when both buffers need to be
deallocated but contain data items, or when the producer produces items faster
than the consumer can consume). Except when data is being transferred, a data
item that is produced resides in exactly one buffer until it is consumed.


3. SPU MANAGEMENT
-----------------

Each SPU maintains a list of filters loaded and buffers allocated on it.


3.1. SPU commands
-----------------

Library code on the PPU controls the SPUs by issuing commands. Each command is
assigned an ID by the scheduler, and can depend on the completion of other
commands (that have been issued to the same SPU); an SPU does not start
processing a commands until its dependencies have completed. Each SPU runs an
event loop that listens for new commands from the PPU and DMA completions, and
runs commands. Multiple commands that all have their dependencies met appear to
be run concurrently.

Commands are handled asynchronously by both the PPU and SPU. A command is
issued by sending a mailbox message with the address and size of the memory
location containing command parameters (this memory location will eventually
be overwritten by the command's return value). The SPU receives the message in
its event loop, DMAs the parameters to its local store, and inserts the command
into its dependency graph. When the command eventually completes, the SPU DMAs
a return value and notifies the PPU via mailbox (a single outbound mailbox
message can indicate completion of multiple commands). After issuing a command,
the PPU can execute other code, periodically polling the mailbox to detect
completions.

A command's dependencies must first be issued to the SPU before the command can
be issued. When the SPU receives a command with a dependency ID that it does
not know about, it assumes the dependency has completed. As a result, the SPU
does not need to store information about completed commands.

There will generally be multiple outstanding commands to each SPU at any time.
Only the PPU can issue SPU commands; thus, the library can ensure it does not
overflow an SPU mailbox (by issuing too many commands before the SPU event loop
can drain it). Because many commands are small and often issued together with
other commands, commands are allowed to be batched: the parameters for multiple
commands can be grouped into a single message. When the SPU receives this
message, it treats the commands in the batch as having been issued in the order
in the message. However, the commands can complete in any order and completion
notifications are sent separately. This is intended to reduce the PPU-SPU
communication overhead resulting from a large number of small messages.

The library maintains the state of all filter and buffer objects on the PPU,
and updates it before issuing SPU commands and after commands complete. The PPU
provides a single point where commands to different SPUs can be synchronized.
In general, SPUs do not need to communicate with each other. The exception is
data transfer between buffers; however, in order for this to be efficient, a
separate protocol not exposed to the scheduler will be used.


3.2. Scheduler interface
------------------------

The interface exposed to the scheduler is a set of library functions, most of
which wrap one or more SPU commands. When a library function is called, the
library first does some processing on the PPU before possibly issuing
command(s) to SPU(s). The function then returns immediately with a sequence
number (or error code). The scheduler calls a library function with this
sequence number to check for completion; it can execute other code (run PPU
filters or call other library functions) in the meantime. The scheduler must
periodically call a library function that checks for command completion
notifications from SPUs; upon receiving a notification, the library may do
additional processing on the PPU before setting the state of the original
library function call as completed.


3.3. SPU event loop
-------------------

When a command's dependencies have all completed, the command is placed in a
runnable state. While the event loop no has PPU messages or DMA completions to
service, it cycles through all runnable commands. (This can be done in simple
round-robin fashion, or alternatively the SPU program can be compiled with a
more complex "scheduler".) For each runnable command, the SPU dispatches to
functions that process part of the command. These functions will generally
return before the command completes; for example, a filter's work function will
be run for only a few iterations before control is returned to the event loop.
This prevents long-running commands from starving the event loop or other
commands.

In general, code running on the SPU is not context-switched. For static-rate
filters (what is really meant here is "the function that processes the command
to run a static-rate filter for a specified number of iterations"), control is
returned to the event loop if there is insufficient input/output buffer to run
an iteration of the work function.  Dynamic-rate filters with unbounded rates
or in feedback loops present a problem. For such filters, it may not be
possible to ensure enough buffer without calling the work function; as a
result, peeks and pushes may block on data. When blocked on data, peeks/pushes
run a modified event loop until data is available. This event loop is the same
as the main event loop, with the exception that it does not attempt to run
unbounded dynamic-rate filters (if it did, and the new filter blocked, control
could not be returned to the original filter until the new filter finished an
iteration of its work function). 

A limitation of this is that (for the most part) at any time only one unbounded
dynamic-rate filter can be running concurrently. We plan to implement SPU
context switching at a later time to address this problem. However, context
switching is likely to be slow and should still only be used by the scheduler
as a last resort.


3.4. SPU local store
--------------------

SPU local store (LS) is completely managed by the scheduler on the PPU. At
compile/startup, the SPU program reserves all remaining local store (except for
a small amount used for tracking command dependencies and loaded filters and
buffers) and reports this information to the PPU. An SPU will only need to
allocate local store in response to a command from the PPU; thus all LS
allocations needed by a command can be reported to the SPU as additional
command parameters. Similarly, deallocations can be handled by the PPU in
response to command completion notifications.

The scheduler is free to implement LS allocation however it wants. A simple
implementation can just duplicate malloc. A complex scheduler can generate a
schedule of allocations based on its schedule of filter executions to reduce
fragmentation.


4. SPU COMMAND/LIBRARY FUNCTION API
-----------------------------------

The following sections describe SPU commands. In general, each command
corresponds to a single library function. Parameters to the command versus the
function are somewhat conflated; which parameters apply to each should be clear
from the context. Unless otherwise stated, all commands/functions also take an
ID and dependencies as parameters.

The conditions that are stated for each command must hold when the command is
executed, and not necessarily when it is issued. The scheduler must ensure
this; the library will perform checks but it is not always able to. In most
cases, this can be done by specifying dependencies.


4.1. Special library functions
------------------------------

SPU command batching is controlled with two library functions:

[spu_start_batch] -------------------------------------------------------------

Causes all future SPU commands issued to the specified SPU to be delayed until
an spu_end_batch. Successive spu_start_batch calls nest; commands are delayed
until the spu_end_batch call corresponding to the outermost spu_start_batch.

Parameters:
- SPU number

[spu_end_batch] ---------------------------------------------------------------

If this call corresponds to the outermost previous spu_start_batch call for the
specified SPU, issues all delayed SPU commands to the SPU in a single batch.
Otherwise, does nothing.

Parameters:
- SPU number

-------------------------------------------------------------------------------

All SPU commands issued to an SPU that are not contained within a
spu_start_batch/spu_end_batch pair (for that SPU) are sent immediately,
unbatched. Batching does not affect how the library checks for function
completion.

The library function for checking for completion of other library function
calls is not described.


4.2. Filter management
----------------------

These commands control filter loading, unloading, and execution.

[load_code] -------------------------------------------------------------------

Copies constant data to an SPU's local store. This is used to load filter code
and parameters onto an SPU.

The PPU allocates space in the local store to hold the data and sends the LS
address to the SPU. Completes after DMA operations have completed.

Note that there is no corresponding [unload_code] command. Because local store
is managed by the scheduler, the scheduler simply marks the LS region as
deallocated after all commands that use the constant data have completed.

Parameters:
- LS address
- Memory address/size of data

[filter_load] -----------------------------------------------------------------

Loads a filter's state onto an SPU and prepares it to be run. A control area is
allocated to store information about the filter (its rates, buffers, etc.) and
the filter's state is copied to local store. Completes after DMA operations
have completed.

The filter must not be already loaded on any SPU. Before the filter can be run,
the following conditions need to be met:

- load_code commands to load the filter's code/parameters must have completed
  (this can be indicated via dependencies of the first filter_run).
- Its tapes must be attached to input/output buffers (via filter_attach_buffer
  commands).

Parameters:
- LS address of control area
- LS addresses of code/parameters
- LS address of state
- Memory address/size of filter properties
- Memory address/size of state

[filter_unload] ---------------------------------------------------------------

Unloads a filter from an SPU. The filter's state is copied back to memory.
Completes after DMA operations have completed.

There must be no outstanding filter_attach_buffer or filter_run commands. This
command contains implicit filter_attach_buffer commands to detach all tapes.

Parameters:
(none)

[filter_attach_buffer] --------------------------------------------------------

Attaches a tape of a loaded filter to an allocated buffer, or detaches a tape.

No filter_run command on the same filter can be in a runnable state at the
same time. When attaching an input/output tape, the buffer cannot already be
attached to an input/output tape of another filter (note that a buffer can be
attached to an input tape and an output tape; this is a shared SPU buffer).

Parameters:
- Buffer index

[filter_run] ------------------------------------------------------------------

Runs a loaded filter's work function until one of the following occurs:

- It has run for the specified number of iterations.
- (optional) It has consumed (including peeks) a specified number of data
  items.
- (optional) It has produced a specified number of data items.

The data item limitations are intended to provide an additional way of
controlling the execution of dynamic-rate filters. Completes afterwards.

The filter's tapes must all be attached to buffers. No other filter_run
commands on the same filter can be in a runnable state at the same time.

Parameters:
- Number of iterations
- (optional) Input and output data items


4.3. Buffer management
----------------------

These commands operate on buffer objects.

[buffer_alloc] ----------------------------------------------------------------

Allocates a new buffer on an SPU.

Parameters:
- LS address/size of buffer

[buffer_dealloc] --------------------------------------------------------------

Deallocates a buffer on an SPU.

The buffer must contain no data items (this can be done by a previous
data_transfer_out command). There must be no outstanding data_transfer_*
commands involving this buffer on any SPU. If filter(s) are attached to the
buffer, this command contains an implicit filter_attach_buffer command to
detach them.

Parameters:
(none)

[data_transfer]     -----------------------------------------------------------
[data_transfer_in]
[data_transfer_out]

(data_transfer is a library function that wraps the other two SPU commands.)

data_transfer_in allows the transfer of the specified amount data from a
specified buffer to this buffer. data_transfer_out allows the transfer of data
from this buffer to another buffer. The buffer does not need to contain the
specified amount of space/data at the time these commands become runnable. The
actual way data is transferred is unspecified. Completes when the specified
amount of data has been transferred in/out.

No other data_transfer_* command on the same buffer can be in a runnable state
at the same time. For a data_transfer_in command, if the buffer is attached to
an output tape of a filter, no filter_run commands on that filter can be
runnable at the same time. For a data_transfer_out command, if the buffer is
attached to an input tape of a filter, no filter_run commands on that filter
can be runnable at the same time.

In general, data_transfer_in will be called on input buffers and
data_transfer_out will be called on output buffers. However, data_transfer_out
to a memory buffer may need to be called on any SPU buffer before it is
deallocated, and data_transfer_in may need to be called on a shared SPU buffer
after it is allocated.

Because SPU-SPU data transfer will often involve a pair of data_transfer_in/
data_transfer_out commands to two buffers, data_transfer is provided; it simply
issues two matching data_transfer_in/data_transfer_out commands.

data_transfer_in/data_transfer_out parameters:
- Source/destination buffer index/SPU
- Number of data items to transfer

data_transfer parameters:
- Source buffer index/SPU
- Destination buffer index/SPU
- Number of data items to transfer


4.4. Querying status
--------------------

Filter and buffer data structures in memory contain status fields that SPUs may
periodically update (this is a compile-time flag; it can be disabled if a
scheduler does not need it). These commands can be used to obtain more up-to-
date information.

These commands are unlike standard SPU commands in that they do not have any
dependencies; the SPU completely processes the command in its event loop as
soon as it receives it. The actual specification for these commands (what types
information need to be provided, etc.) will be determined later.

[spu_set_update_rate] ---------------------------------------------------------

Sets the rate at which an SPU updates status fields in memory.

Parameters:
- Update rate

(filter_query) ----------------------------------------------------------------

This is a set of commands that return various status flags/performance counters
for a filter (whether it is blocked on input/output, number of iterations run,
cumulative work function runtime, etc.)

Parameters:
(none)

(buffer_query) ----------------------------------------------------------------

This is a set of commands that return various status information about a
buffer (number of data items contained, percentage of time it is empty/full,
etc.)

Parameters:
(none)


4.5. Work functions
-------------------

Filter work functions access their input/output tapes with [peek(n)] and [push]
functions. These functions return pointers to the address where the specified
data item can be read from/should be written to; C code can then perform casts
to the filter's data type. Separate [advance_input(n)] and [advance_output]
functions are used to advance the input/output tape position.

A pop operation would be represented by a macro/inline function (compiled with
the filter's work function, not the library) such as:

TYPE item = (TYPE*)peek(0);
advance_input(1);
return item;

A push operation would be represented by the macro:

(TYPE*)push() = item;
advance_output();

Different implementations of these functions can be provided for static-/
bounded-dynamic- versus unbounded-dynamic-rate filters. The former would not
need to block on data.

An additional function that we may provide in a future implementation is a
[poke(n)] function to write a data item to an arbitrary future position on the
output tape.


5. EXAMPLES
-----------

Transferring data from one buffer to another requires the following commands
(in any order; it is assumed that all prevous data_transfer_* commands
involving the buffers have completed):

  buffer 1: data_transfer_in n items from buffer 2
  buffer 2: data_transfer_out n items to buffer 1

Normally, the scheduler will only need to call the data_transfer library
function (which generates the commands above):

  data_transfer n items from buffer 1 to buffer 2

However, having separate data_transfer_in and data_transfer_out commands allows
other commands to depend on data transfers completing:

  data_transfer_out all items to memory buffer, then buffer_dealloc

Double-buffering for a static-rate filter can be implemented "manually" by the
scheduler by specifying the following commands (commands on a line depend on
all commands on the preceding line):

                  data_transfer_in(peek_rate + (n - 1) * pop_rate)
  filter_run(n)   data_transfer_in(n * pop_rate)
  filter_run(n)   data_transfer_in(n * pop_rate)
               ...

Alternatively, double-buffering can be implemented "automatically" by
specifying the following commands (N is a very large number):

  filter_run(N)   data_transfer_in(peek_rate + (N - 1) * pop_rate)
