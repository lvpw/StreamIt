\section{Translation to Frequency}
\label{sec:freq}

In this section, we demonstrate how we can leverage our linear
representation to automatically perform a common domain-specific
optimization: translation to the frequency domain.  First, we show
that a linear node is equivalent to a set of convolution sums, which
can benefit from algorithmic gains if performed in frequency rather
than time.  We then present an optimized code generation strategy for
transforming linear nodes to frequency.

\subsection{Basic Frequency Implementation}

In order to derive a frequency implementation of a linear node, let us
start by formulating the computation that the node performs.  To
simplify the derivation, assume that we are given a node $\lambda$
with ${\vec b = 0}$ and $\mt{push}=\mt{pop}=1$ (we will relax these
restrictions below).  As usual, let $e$ denote the peek rate for
$\lambda$; also let ${\vec x}_0$ denote the input items and $y_0$
denote the output item.  Then, by Definition 1, we have the following:
\[
y_0 = {\vec x} A + {\vec b} = \sum_{k=0}^{e-1} A[k] \mbox{\tt peek}(e-k-1)
\]
Note that in this case, $y_0$ is a scalar since $\mt{push}=1$.  Now
let us consider the values that appear on the output tape over time,
which we denote by ${\vec y}$.  On the $n$'th iteration, the
computation is exactly as above, except that the input and output
tapes are offset by $n$:
\[
\label{fig:linconv}
{\vec y}[n] = \sum_{k=0}^{e-1} A[k] \mbox{\tt peek}(n+e-1-k) 
\]
At this point, our equation is in the same form as a convolution sum
from digital signal processing: given two vectors ${\vec h}$ and
${\vec x}$, the convolution is defined as:
\[
{\vec x} * {\vec h} = \sum_{k=-\infty}^{\infty} {\vec x}[k] {\vec h}[n-k]
\]
The calculation of a convolution sum is much more efficient in the
frequency domain, due to the Fast Fourier Transform (FFT).  To compute
the convolution, an N-point FFT of ${\vec x}$ and ${\vec h}$ is
performed to obtain ${\vec X}$ and ${\vec H}$, each of which are
complex-valued vectors of length $N$.  Element-wise multiplication of
${\vec X}$ and ${\vec H}$ yields a vector ${\vec Y}$, on which we can
perform an inverse FFT (IFFT) to obtain the result ${\vec y}$.
Convolution in the frequency domain requires $O(N \lg(N))$ operations,
as each FFT and IFFT has a cost of $O(N \lg (N))$ and the vector
multiplication is $O(N)$.  By contrast, the complexity is $O(N^2)$ in
the time domain, as each of the $N$ output values requires $O(N)$
operations.  For more details, refer to~\cite{oppenheim-discrete}.

We can use the exact procedure described above to implement
Equation~\ref{fig:linconv} in the frequency domain.  The only
modification to the procedure is due to the offset of $e-1$ in the
peek argument.  Because of this offset, the complete convolution will
yield values of ${\vec y}[i]$ for $i \in [-(e-1), n]$, even though the
values at negative indices are not directly meaningful.  In the naive
implementation, we simply disregard these values; however, in the next
section, we give an optimized implementation that takes advantage of
them.

The only task remaining for the implementation is to choose $N$, which
for performance reasons should be a power of two, and as large as
possible.  The value of $N$ also determines how many input items we
can process per iteration, as too many items will cause frequency
aliasing.  According to Fourier's theorem, an $N$-point FFT can
exactly represent any discrete sequence of $N$
numbers~\cite{oppenheim-discrete}.  The numbers we need to represent
are the results ${\vec y}$, of which there are $n+e-1$ (where $n$
represents the number of input items per iteration).  Thus, we can
choose $N$ as we please and use $n = N-e+1$.  In our implementation,
we set $N$ to the first power of two that is larger than $2e$, which
strikes a reasonable compromise between storage space and performance
for our uniprocessor benchmarking platform.  Under a different set of
resource constraints, the choice of $N$ should be adjusted.

The transformation below gives a naive translation of a linear node to
the frequency domain.  In addition, it relaxes all of the assumptions
that we made above.  The algorithm allows for a non-zero value of
${\vec b}$ by simply adding ${\vec b}$ after returning from the
frequency domain.  To accommodate a push rate greater than one, the
algorithm cycles between alternate columns of the $A$ matrix, pushing
values from each one in turn.  Finally, to accommodate a pop rate
greater than one, the algorithm performs extra computations and
proceeds as if the pop rate was one; then, the node is followed by a
decimator that eliminates the spurious output.  Though this introduces
some inefficiency, it still leaves room for large performance
improvements, as the frequency transformation improves performance by
an average factor of 50 (in the case where $\mt{pop}=1$.)

\begin{transformation} (Naive frequency implementation)
Given a linear node $\lambda = \{A, {\vec b}, e, o, u\}$, the
following stream is a naive implementation of $\lambda$ in the
frequency domain: \\
\begin{equation} \nonumber
  \begin{array}{ll}

    {\tt float \rightarrow float}~{\tt pipeline~naiveFreq~}(A, {\vec b}, e, o, u){\tt ~\{} & \hspace{40pt}\\
    ~~{\tt add~float->float~filter~\{}\\
    ~~~~N \leftarrow 2^{\lceil \lg(2e) \rceil} \\
    ~~~~n \leftarrow N-e-1 \\
    \\
    ~~~~{\tt init}~{\tt \{} \\
    ~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~\vec{H}[j] \leftarrow \mathbf{FFT}(N,A[*,u-1-j]) \\
    ~~~~{\tt \}} \\
    \\
    ~~~~{\tt work}~{\tt peek}~u*n~{\tt pop}~u*n~{\tt push}~u*n~{\tt \{} \\
    ~~~~~~\vec{x} \leftarrow {\tt pop}(0 \dots n - 1) \\
    ~~~~~~\vec{X} \leftarrow \mathbf{FFT} (N, \vec{x}) \\
    ~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~\vec{Y}[j] \leftarrow \vec{X} .* \vec{H}[j] \\
    ~~~~~~~~\vec{y}[j] \leftarrow \mathbf{IFFT}(N, \vec{Y}[j]) \\
    ~~~~~~{\tt \}} \\
    ~~~~~~{\tt for~i~=~0~to~}n-1\\
    ~~~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~~~{\tt push}(\vec{y}[j][i+e-1] + {\vec b}[j])\\
    ~~~~{\tt \}} \\
    ~~{\tt \}} \\
    ~~{\tt add~Decimator(o)} \\
    {\tt \}} \\
  \end{array}
\end{equation}
\label{trans:freq1}
\end{transformation}

\subsection{Optimized Frequency Implementation}

\begin{transformation} (Optimized frequency implementation)
Given a linear node $\lambda = \{A, {\vec b}, e, o, u\}$, the
following stream is an optimized implementation of $\lambda$ in the
frequency domain: \\
\begin{equation} \nonumber
  \begin{array}{ll}

    {\tt float \rightarrow float}~{\tt pipeline~optimizedFreq~}(A, {\vec b}, e, o, u){\tt ~\{} & \hspace{40pt}\\
    ~~{\tt add~float->float~filter~\{}\\
    ~~~~N \leftarrow 2^{\lceil \lg(2e) \rceil} \\
    ~~~~n \leftarrow N-e-1 \\
    ~~~~\vec{partials} \leftarrow {\tt new~float}[u][e] \\
    \\
    ~~~~{\tt init}~{\tt \{} \\
    ~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~\vec{H}[j] \leftarrow \mathbf{FFT}(N,A[*,u-1-j]) \\
    ~~~~{\tt \}} \\
    \\
    ~~~~{\tt prework}~{\tt peek}~u*n~{\tt pop}~u*n~{\tt push}~u*(n-(e-1))~{\tt \{}\\
    ~~~~~~\vec{x} \leftarrow {\tt pop}(0 \dots n-1) \\
    ~~~~~~\vec{X} \leftarrow \mathbf{FFT} (N, \vec{x}) \\
    ~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~\vec{Y}[j] \leftarrow \vec{X} .* \vec{H} \\
    ~~~~~~~~\vec{y}[j] \leftarrow \mathbf{IFFT}(N, \vec{Y}[j]) \\
    ~~~~~~~~\vec{partials}[j] \leftarrow \vec{y}[j][n \dots (N-1)]\\
    ~~~~~~{\tt \}} \\
    ~~~~~~{\tt for~i~=~0~to~}n-(e-1)\\
    ~~~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~~~{\tt push}(\vec{y}[j][i+e-1] + b[j]) \\
    ~~~~{\tt \}} \\
    \\
    ~~~~{\tt work}~{\tt peek}~u*n~{\tt pop}~u*n~{\tt push}~u*n~{\tt \{} \\
    ~~~~~~{\tt for~i~=~0~to~}e-1\\
    ~~~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~~~{\tt push}(\vec{y}[j][i] + {\vec partials}[j][i])\\
    ~~~~~~\vec{x} \leftarrow {\tt pop}(0 \dots n - 1) \\
    ~~~~~~\vec{X} \leftarrow \mathbf{FFT} (N, \vec{x}) \\
    ~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~\vec{Y}[j] \leftarrow \vec{X} .* \vec{H}[j] \\
    ~~~~~~~~\vec{y}[j] \leftarrow \mathbf{IFFT}(N, \vec{Y}[j]) \\
    ~~~~~~~~{\vec partials}[j] \leftarrow \vec{y}[j][n \dots (N-1)]\\
    ~~~~~~{\tt \}} \\
    ~~~~~~{\tt for~i~=~0~to~}n-(e-1)\\
    ~~~~~~~~{\tt for~j~=~0~to~}u-1\\
    ~~~~~~~~~~{\tt push}(\vec{y}[j][i+e-1] + {\vec b}[j])\\
    ~~~~{\tt \}} \\
    ~~{\tt \}} \\
    ~~{\tt add~Decimator}(o) \\
    {\tt \}} \\
  \end{array}
\end{equation}
\label{trans:freq1}
\end{transformation}

\subsection{Applications of Frequency Transformation}

The transformation to the frequency domain is straightforward in
theory and very common in practice. However, the detailed record
keeping, transform size selection, and state management make an actual
implementation quite involved.  Further, as the complexity of DSP
programs continue to grow, manually determining the disparate regions
across which to apply this optimization is an ever more daunting task.
For example, several filters individually may not perform sufficiently
large convolutions to merit a frequency transformation, but after a
linear combination of multiple filters the transformation could be
beneficial.  Differing levels of architectural support for various
convolution and frequency operations further complicates the task of
manually choosing the optimal transform.  Our compiler automatically
determines all the necessary information and transforms the
computation into the frequency domain.

%% Then consider that we push u values.  Then n indicates the firing
%% number of the work function.
%%
%%   For all j in [0,u-1]:
%%
%%     y[n*u+j] = sum_i (x[n-i]*A[e-1+i,j])
%%
%% Consider instead that we pop o items.  Then have:
%%
%%   y[n] = sum_i (x[o*n-i]*A[e-1+i])
