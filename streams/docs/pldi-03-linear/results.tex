\section{Results}
\label{sec:results}

Our compiler currently has two linear analysis optimizations. The
first, {\it linear replacement}, transforms linear streams (either
filter, splitjoin or pipeline) by replacement with a filter that
directly computes the calculation of the corresponding linear node.
The second optimization, {\it frequency replacement}, applies the
transformation described in Section \ref{sec:freq}.  The
transformation takes advantage of the machine tuned FFT package
FFTW~\cite{frigo99fast}, to perform the necessary basis conversions.
The partitioner automatically determines to which subsections of the
overall program to apply each of the transformations. Below we
describe experiments and results that demonstrate substantial
performance improvements due to our methods.

\subsection{Measurement Methodology}
%We chose to measure the strength of our optimizations in terms of 
%floating point instruction reduction. The StreamIt compiler currently
%has two code generation backends. The uniprocessor backend generates sequential C code
%that can be compiled and linked against a supporting library. 
%There is also a backend that generates code for the RAW microprocessor
%\cite{waingold97baring, raw-micro}, which features
%a grid of processors interconnected via various communication facilities. 
%Mapping a StreamIt program on to the RAW architecture is complicated
%by issues of communication, load balancing and partitioning\cite{streamit-asplos}. 
%Therefore, the effects of our linear analysis optimizations can not
%be easily differentiated from differences in placement, routing and fusion that result
%from modifying the program's stream graph (as is the case for linear replacement). 
%Therefore we chose to use the uniprocessor backend for our measurements.

%As always, the appropriate metric to measure performance is not totally clear. 
%Running time is complicated by the multitasking environment offered by 
%modern operating systems. Also, given that the uniprocessor backend for
%the StreamIt compiler is meant for prototyping, the supporting 
%library is anything but optimized. Therefore, measuring running time is
%probably not an appropriate metric.

\begin{figure}[t]
%\vspace{-6pt}
\center
\epsfxsize=3.2in
\epsfbox{images/multiplications-remaining.eps}
\vspace{-6pt}
\caption{Percent of multiplication operations remaining after performing linear replacement, frequency replacement, and both.}
\label{fig:linear-freq-both}
\vspace{-12pt}
\end{figure}

%Floating point multiplication instructions 
%in the IA-32 instruction set are defined to be any of ({\tt fmul fmulp fimulp fdiv fdivp fidivp fdivr fdivrp fidivr}).
%We measure execution time normalized to the number of program outputs generated. 

Our measurement platform is a Dual Intel 2.2 GHz P4 Xenon processor system 
with 2GB of memory running GNU/Linux. We compile our benchmarks using StreamIt's uniprocessor backend
and generate executables from the resulting C files using {\tt gcc -O2}.
To measure the number of runtime multiplications we use an instruction counting 
DynamoRIO\cite{dynamo99} client.
There are no standard benchmarks written yet for StreamIt, so we use
a set of representative programs\footnote{Stream graphs appear in Appendix A XXXXXXXXXXXXXXXXXXXXXX.}
which perform computations that are commonly found in streaming applications:
1) {\bf FIR}, a single 256 point low pass FIR filter; 
2) {\bf RateConvert}, an audio down sampler that converts the 
sampling rate by a non-integral factor ($\frac{2}{3}$); 
3) {\bf TargetDetect}, four matched filters in parallel with threshold target detection; 
4) {\bf FMRadio}, an FM software radio with equalizer;
5) {\bf Radar}, the core functionality in modern radar signal processors, based on a system from the Polymorphic Computing Architecture (PCA);
6) {\bf FilterBank}, a multi-rate signal decomposition 
processing block common in communications and image processing;
7) {\bf Vocoder}, a channel voice coder, commonly used for speech analysis and compression;
8) {\bf Oversample}, a $16x$ oversampler, a function found in many CD players,
9) {\bf DToA}, an audio post-processing stage prior to a 1-bit D/A converter 
with oversampler and first order noise shaper.

\subsection{Performance}
To determine the effects of our linear replacement and frequency
replacement optimizations, we compiled each benchmark program with
linear replacement, with frequency replacement, with a back to back application of
frequency replacement and linear replacement and with the partitioner.
Figure~\ref{fig:linear-freq-both} shows the reduction in the number
of multiplications that our optimizations achieve.
For each benchmark, our optimizations reduce the number of multiplications
considerably. For FIR and TargetDetect, the reduction comes from 
frequency replacement, but in other benchmarks linear replacement
reduces the multiplications as well. For TargetDetect, Radar and Vocoder,
combining both optimizations using the partitioner decreases mulitplications
more than either alone. Linear replacement increases the number of multiplications
required because it ``unfactors'' some of the computation that the original
programmer had expressed in the program's structure. With the partitioner,
only beneficial combinations are performed which reduces the number of 
multiplications required.
% AAL-is there anything else interesting that we would like to point out?

\begin{figure}[t]
\center
\epsfxsize=3.2in
\epsfbox{images/execution-speedup.eps}
\vspace{-6pt}
\caption{Execution speedup for each of the benchmarks with 
  frequency replacement, linear replacement, both and partitioning.}
\label{fig:execution-speedup}
\vspace{-6pt}
\end{figure}

In general, reducing computation does not necessarily translate into a
faster program, but it is often a useful indication.  As
Figure~\ref{fig:execution-speedup} demonstrates, our benchmarks
speedup on average by a factor of {\bf XXXXX} and by a factor of
$XXXXXXX$ in the best case.  Our performance improvements are due only
in part to to the efficiency of FFTW.  Multiplications are decreased
and execution is sped up in RateConvert, FM, FilterBank and Vocoder
with only linear replacement. Linear replacement improvements are due
to removing redundant computations -- in essence we do algebraic
simplification across filer boundaries.

With the exception of FilterBank and Vocoder, execution speed
increases when multiplications are decreased. For Vocoder, the
difference between the back to back application of the individual
optimizations and the partitioned application is that the partitioner
refactors and combines a linear splitjoin where the back to back
application did not. As Figure~\ref{fig:linear-freq-both} shows, this
collapsing has no effect on the number of multiplications required but
it does change the execution scheduling.  The difference in execution
speed is due to a difference in the runtime overhead of this different
structure. FilterBank is the same -- the partitioner determines a
clever refactoring that reduces the number of multiplications compared
to the back to back application, but the additional overhead of more
filters actually causes the execution time to increase. A more
accurate cost model that takes into account costs other than
multiplications could help the partitioner make a better choice
between possible partitions.

\begin{table*}[t]
\vspace{-6pt}
\centering
\small
\begin{tabular}{|l|c|c|c||c||c|c|c|} 
\hline
& \multicolumn{3}{|c||}{Originally}  &             & \multicolumn{3}{|c|}{After Optimizations} \\
\hline
Benchmark  & Filters & Pipelines& SplitJoins & Average     & Filters      & Pipelines         & SplitJoins \\
           & (linear)& (linear) & (linear)   & vector size &              &                   &            \\
\hline
FIR        & 3 (1)   & 1(0)     & 0 (0)      & 256         & 3            & 1                 & 0 \\
\hline
RateConvert& 5 (3)   & 2 (1)    & 0 (0)      & 102         & 4            & 1                 & 0 \\
\hline
TargetDetect& 10 (4) & 6 (0)    & 1 (0)      & 300         & 7            & 2                 & 1 \\
\hline
FMRadio    & 26 (22) & 11 (9)   & 2 (2)      & 40          & 5            & 1                 & 0 \\
\hline
Radar      & 76 (60) & 17 (0)   & 2 (0)      & 4412        & 21           & 1                 & 2 \\
\hline
FilterBank & 27 (24) & 17 (9)   & 4 (4)      & 52          & 10           & 1                 & 2 \\
\hline
Vocoder    & 17 (13) & 10 (8)   & 2 (1)      & 60          & 7            & 2                 & 1 \\
\hline
Oversampler& 10 (8) & 1 (1)     & 0 (0)      & 33          & 3            & 1                 & 0 \\
\hline
DToA       & 14 (10) & 3 (1)    & 0 (0)      & 52          & 6            & 2                 & 0 \\
\hline

\end{tabular}
\vspace{-3pt}
\caption{Statistics for benchmarks before and after optimizations.
\protect\label{fig:benchmark-statistics}}
\vspace{-4pt}
\end{table*}
