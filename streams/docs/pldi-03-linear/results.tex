\begin{figure}[t]
\vspace{-16pt}
\psfig{figure=images/flops-removed.eps,width=3.4in}
\vspace{-16pt}
\caption{Elimination of floating point operations by linear replacement, frequency replacement, and automatic optimization selection.}
\label{fig:flops}
\vspace{-12pt}
\makeline
\vspace{-12pt}
\end{figure}

\begin{table*}[t]
\vspace{-16pt}
\centering
\small
\begin{tabular}{|l|c|c|c||c||c|c|c|} 
\hline
& \multicolumn{3}{|c||}{Originally}  &             & \multicolumn{3}{|c|}{After Optimizations (using Automatic Selection)} \\
\hline
Benchmark  & Filters & Pipelines& SplitJoins & Average     & Filters      & Pipelines         & SplitJoins \\
           & (linear)& (linear) & (linear)   & vector size &              &                   &            \\
\hline
FIR        & 3 (1)   & 1(0)     & 0 (0)      & 256         & 3            & 1                 & 0 \\
\hline
RateConvert& 5 (3)   & 2 (1)    & 0 (0)      & 102         & 4            & 1                 & 0 \\
\hline
TargetDetect& 10 (4) & 6 (0)    & 1 (0)      & 300         & 7            & 1                 & 1 \\
\hline
FMRadio    & 26 (22) & 11 (9)   & 2 (2)      & 40          & 5            & 1                 & 0 \\
\hline
Radar      & 76 (60) & 17 (0)   & 2 (0)      & 4412        & 38           & 17                & 2 \\
\hline
FilterBank & 27 (24) & 17 (9)   & 4 (4)      & 52          & 3            & 1                 & 0 \\
\hline
Vocoder    & 17 (13) & 10 (8)   & 2 (1)      & 60          & 6            & 2                 & 1 \\
\hline
Oversampler& 10 (8) & 1 (1)     & 0 (0)      & 33          & 3            & 1                 & 0 \\
\hline
DToA       & 14 (10) & 3 (1)    & 0 (0)      & 52          & 7            & 2                 & 0 \\
\hline
\end{tabular}
\vspace{-3pt}
\caption{Statistics for benchmarks before and after optimizations.
\protect\label{fig:benchmark-statistics}}
\makeline
\vspace{-8pt}
\end{table*}

\section{Results}
\label{sec:results}

We have completed a fully automatic implementation of the linear
combination, frequency replacement, and optimization selection
algorithms described in the previous sections.  The implementation is
part of the StreamIt compiler, and works for both the uniprocessor and
Raw~\cite{raw-micro} backends.  In this section, we evaluate three
configurations of linear optimizations for the uniprocessor backend:
\begin{itemize}

\item {\it Linear replacement}, which transforms maximal linear
sections of the stream graph into a single linear node, which we
implement as a matrix multiply.  For small nodes (less than 256
operations), this takes the form of an unrolled arithmetic expression,
whereas for large nodes we implement an indexed matrix multiply that
avoids zero entries at the top and bottom of each column.

\begin{figure}[t]
\vspace{-16pt}
\psfig{figure=images/execution-speedup.eps,width=3.4in}
\vspace{-16pt}
\caption{Execution speedup for linear replacement, frequency replacement, and automatic optimization selection.}
\label{fig:execution-speedup}
\vspace{-12pt}
\makeline
\vspace{-12pt}
\end{figure}

\item {\it Frequency replacement}, which transforms maximal linear
sections of the stream graph into a single node in the frequency
domain.  To implement the necessary basis conversions, we use
FFTW~\cite{frigo99fast}, which is an adaptive and high-performance FFT
library.

\item {\it Automatic selection}, which employs both of the previous
transformations judiciously in order to obtain the maximal benefit.
This works according to the algorithm in
Section~\ref{sec:partitioning}.
\end{itemize}
Below we describe experiments and results that demonstrate substantial
performance improvements due to our methods.  For full results, stream
graphs, and source code, please visit {\tt
http://cag.lcs.mit.edu/linear/}.

\subsection{Measurement Methodology}
%We chose to measure the strength of our optimizations in terms of 
%floating point instruction reduction. The StreamIt compiler currently
%has two code generation backends. The uniprocessor backend generates sequential C code
%that can be compiled and linked against a supporting library. 
%There is also a backend that generates code for the RAW microprocessor
%\cite{waingold97baring, raw-micro}, which features
%a grid of processors interconnected via various communication facilities. 
%Mapping a StreamIt program on to the RAW architecture is complicated
%by issues of communication, load balancing and partitioning\cite{streamit-asplos}. 
%Therefore, the effects of our linear analysis optimizations can not
%be easily differentiated from differences in placement, routing and fusion that result
%from modifying the program's stream graph (as is the case for linear replacement). 
%Therefore we chose to use the uniprocessor backend for our measurements.

%As always, the appropriate metric to measure performance is not totally clear. 
%Running time is complicated by the multitasking environment offered by 
%modern operating systems. Also, given that the uniprocessor backend for
%the StreamIt compiler is meant for prototyping, the supporting 
%library is anything but optimized. Therefore, measuring running time is
%probably not an appropriate metric.

%Floating point multiplication instructions 
%in the IA-32 instruction set are defined to be any of ({\tt fmul fmulp fimulp fdiv fdivp fidivp fdivr fdivrp fidivr}).
%We measure execution time normalized to the number of program outputs generated. 

%Our measurement platform is a Dual Intel 2.2 GHz P4 Xeon processor
%system with 2GB of memory running GNU/Linux. 
Our measurement platform is a Dual Intel P4 Xeon system with 2GB of
memory running GNU/Linux.  We compile our benchmarks using StreamIt's
uniprocessor backend and generate executables from the resulting C
files using {\tt gcc -O2}.  To measure the number of floating point
operations, we use an instruction counting DynamoRIO\cite{dynamo99}
client.

Since StreamIt is a new language, there are no external sources of
benchmarks.  Thus, we have assembled the following set of
representative streaming components and have rewritten them in
StreamIt: 1) {\bf FIR}, a single 256 point low pass FIR filter; 2)
{\bf RateConvert}, an audio down sampler that converts the sampling
rate by a non-integral factor ($\frac{2}{3}$); 3) {\bf TargetDetect},
four matched filters in parallel with threshold target detection; 4)
{\bf FMRadio}, an FM software radio with equalizer; 5) {\bf Radar},
the core functionality in modern radar signal processors, based on a
system from the Polymorphic Computing Architecture~\cite{pca}; 6) {\bf
FilterBank}, a multi-rate signal decomposition processing block common
in communications and image processing; 7) {\bf Vocoder}, a channel
voice coder, commonly used for speech analysis and compression; 8)
{\bf Oversampler}, a $16x$ oversampler, a function found in many CD
players, 9) {\bf DToA}, an audio post-processing stage prior to a
1-bit D/A converter with an oversampler and a first order noise
shaper.

\subsection{Performance}

One interesting aspect of our optimizations is that they eliminate
floating point operations (FLOPS) from the program, as shown in Figure
Figure~\ref{fig:flops}.  The removal of FLOPS represents fundamental
computation savings that is independent of the streaming runtime
system and other (FLOPS-preserving) optimizations in the compiler.  As
shown in the figure, all of our benchmarks illustrate pronounced
reduction in the number of FLOPS.  For FIR and TargetDetect, the
reduction comes only from frequency replacement, but in other
benchmarks linear replacement reduces the count as well.  

The automatic selection option eliminates more FLOPS than either of
the other options for TargetDetect, FMRadio, Radar, and Vocoder.  The
effect is especially pronounced in Radar, where linear and frequency
replacement increase the number of FLOPS, but automatic selection
decreases FLOPS; the selection algorithm chose to combine only some of
the filters in Radar, transforming none to the frequency domain.
Automatic selection always performs at least as well as the other two
options, which implies that our cost functions have some level of
accuracy.

Execution speedups are shown in Figure~\ref{fig:execution-speedup}.
With automatic selection, our benchmarks speed up by an average factor
of 450\% and by a factor of 800\% in the best case.  While the graph
suggests that frequency replacement almost always performs better than
linear replacement, this is not strictly the case; in FMRadio, Radar,
and Vocoder, the automatic selection algorithm obtains its speedup by
using linear replacement instead of frequency replacement for part of
the stream graph.  However, linear replacement does reduce performance
for FIR, TargetDetect, and DToA despite reducing the number of FLOPS.
We believe that this is due to inefficiencies in our implementation of
the matrix multiplication routine, as well as auxillary effects on the
runtime overhead in the StreamIt library.  If we use the machine-tuned
ATLAS library for the matrix multiply~\cite{whaley01automated},
performance for the linear replacement optimization varies widely:
linear replacement with ATLAS performs anywhere from -36\% (on
FMRadio) to 58\% (on Oversampler) better than with our own matrix
multiply routine, with an average of -4.3\% improvement.  Note that
these numbers reflect our overhead in calling ATLAS in addition to
ATLAS itself.  In the future, we plan to explore how best to perform
the matrix multiply.

Perhaps the most interesting benchmark is Radar\footnote{\small This
is the same Radar application as in~\cite{streamit-asplos}, with some
filters adjusted to work at a coarser level of granularity.  This
eliminates persistent state in exchange for increased I/O rates.
Also, frequency replacement caused an internal error in gcc for this
program, so we used egcs 2.91 instead.}.  Maximal linear and frequency
replacement lead to abysmal performance on Radar, due to a
vector-vector multiply called Beamform at the top of a pipeline
construct.  The Beamform filter pushes 2 items, but pops and peeks 24;
thus, when the replacement algorithms combine it with a downstream FIR
filter, much of its work is duplicated.  Moreover, the frequency
replacement option suffers from the large pop rates in the application
(as high as 128 for some filters), thereby increasing FLOPS and
execution time by more than a factor of 30.  The automatic selection
algorithm is essential in this case; it averts the
performance-degrading combination and benefits from linear
combinations elsewhere in the program, resulting in a significant
reduction in FLOPS and a 5\% performance gain.

%% There are two cases in which the multiplication reduction is not a
%% good predictor of execution speedup.  For Vocoder, the optimization
%% selection algorithm achieves the same number of multiplications as
%% applying both linear and frequency replacement; however, the speedup
%% is higher with automatic selection because the selection algorithm
%% refactors and combines a linear splitjoin where the plain
%% optimizations do not. The refactoring has no effect on the number of
%% multiplications required, but it increases the execution time because
%% it increases the runtime overhead in the execution of the stream
%% graph.  FilterBank illustrates similar behavior --- the selection
%% algorithm determines a clever refactoring that reduces the number of
%% multiplications compared to applying both linear and frequency
%% replacement, but the additional overhead required actually causes the
%% execution time to increase. A more accurate cost model that takes into
%% account costs other than multiplications could help the selection
%% algorithm improve its choice of stream graph arrangements.
