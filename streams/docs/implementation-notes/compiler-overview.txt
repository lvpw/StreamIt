This document provides an overview of the organization of the StreamIt
compiler.  The compiler is build on top of version 1 of the Kopi Java
compiler, which is an open-source Java compiler that is written in
Java.  It is available from:

http://www.dms.at/kopi/


Compiler Flow
-------------

Here's the general flow of the compiler as it stands now:

0. The StreamIt frontend reads in a source file, and converts it to
   "old syntax" Java code; the main entry point is
   src/streamit/frontend/ToJava.java.

1. The Kopi scanner/parser reads in a source file (see
   src/at/dms/kjc/Main.java)

2. The Kopi system type-checks the code and resolves object references
   to point to actual objects instead of just symbolic names. (see
   src/at/dms/kjc/Main.java)

3. We translate the Kopi IR into a StreamIt high ir (SIR) consisting
   of a stream graph of filters, pipelines, splitjoins, and
   feedbackloops.  The class that does this translation is
   kjc/Kopi2SIR; the toplevel streamit stuff is in kjc/StreaMITMain.

  SIR is located at src/at/dms/kjc/sir.  It is a hierarchical IR with
  direct representations for pipelines, feedbackloops, and
  splitjoins. Variable rates are supported in the SIR.  The SIR also
  includes a custom cloning implementation used to clone sections of (or
  the complete) graph.  If you are adding fields to an SIR class, you
  must run a pass that auto-generates the cloning code (see
  at/dms/kjc/CloneGenerator.java).

4. We have some passes that operate on the sir code, such as:

   Constant Propagation / Loop Unrolling    kjc/sir/lowering/ConstantProp.java
   Field Propagation			    kjc/sir/lowering/FieldProp
   
   The constant prop. and loop unrolling is used to expand the
   parameterized structure of the IR into a static graph.

   There are also a set of graph transformations that can re-arrange
   filters in the graph, convert to and from different canonical
   forms, and adjust the granularity by fusing many filters into one
   or fissing one filter into many:
     kjc/sir/lowering/partition/RefactorSplitJoin.java
     kjc/sir/lowering/partition/RefactorPipeline.java
     kjc/sir/lowering/fusion/Lifter.java
     kjc/sir/lowering/fission/StatelessDuplicate.java
     kjc/sir/lowering/fission/VerticalFission.java

   These phases are used for partitioning and optimization, discussed below.

-----

Backends
--------------------------------------

Currently, by default the "Cluster" backend runs.  This backend
follows a space-multiplexed pipeline parallelism approach.  It has
support for dynamic rates and teleport messaging.  It support multiple
threads per processor, and also multiple machines connected over a LAN
(cluster).  We are in the process of deprecating this backend, so it
will not be covered further. 

SMP Backend:

The smp backend was developed using the tilera backend as a base.  It
is enabled via the -smp X option, where X is the number of cores the
user desires to target.  The backend is located at at/dms/kjc/smp.
The driver of the backend is SMPBackend.java, called by
StreaMITMain.java.  

The SMP backend uses our shared backend infrastructure that seeks to
ease development of new backends.  This infrastructure is located in
at/dms/kjc/backendsuppport.  The process for adding a backend is
documented at: docs/implementation-notes/adding-a-backend.html.  See
at/dms/kjc/backendSupport/package.html for more information on the
structure of our extensible backend infrastructure.

Upon entry to SMPBackend, a suite of passes common across backends is
run.  See at/dms/kjc/CommonPasses.  The most important task
accomplished here is the lowering of the SIR to a lower IR called
Slice IR or Slice graph (see at/dms/kjc/slicegraph).  Slicegraph is a
flat IR with nodes that support multiple input and output.  The
conversion from SIR to slicegraph folds splitters and joiners into
their upstream and downstream fliters, respectively.  The slicegraph
also includes more power splitting operations where a node can
duplication and round-robin distribute output items.    The slice can
be thought of as a wrapper for SIRFilter(s).  The slicegraph
was originally designed to facilitate an experimental combination of
pipeline parallelism, so a slice is defined as a pipeline of filters.
However, this experiment was abandoned, so a slice is now mostly
standarded to include exactly one filter. 

Parallelization is performed in CommonPasses, and depending on the
method, is performed on either the SIR or the slicegraph.  The
streamit compiler is a research compiler, so it includes many
experimental parallelization passes that are enabled by options, one
important task to complete before a release is to standardize a
parallelization flow.

The SMP backend relies on time-multiplexed data and task parallelism
as defined by our ASPLOS 06 paper (though this is not enable by
default).  The backend currently does not support dynamic rates.  The
backend currently supports a limited implementation of dynamic
workload balancing enabled with --loadbalance (see Tan Masters
Thesis).   

Tilera Backend:

Similar to SMP backend, but generates communication code for the
remote store programming paradigm of the Tilera chip.  See Gordon PhD
thesis for more information on the implementation.

The Directory Structure
-----------------------

At this point an explanation of our directory structure is long
overdue.  From under streams/src, it looks like this:

|-- streamit            Code that is specific to the StreamIt compiler
|   |-- frontend        StreamIt-to-Java converter
|   |-- library         StreamIt Java runtime library
|   |-- misc            Support classes for the scheduler
|   |-- scheduler1      Old scheduler (unused)
|   `-- scheduler2      Current stream scheduler
|
`-- at/dms              Parts from Kopi:
    |-- kjc		This is the compiler section of Kopi, that
    |   |               we're using.
    |   |-- iterator	Stream iterators, used primarily for interfacing 
    |   |               with the scheduler.
    |   |-- linprog	Interface to a linear programming package,
    |   |               currently unused.
    |   |-- lir		The LIR is the low-ir for the uniprocessor
    |   |               backend discussed above.
    |   |-- raw		This is where all the Raw backend stuff lives.
    |   `-- sir		This holds our representation of the high IR.
    |       `-- lowering  Originally intended for lowering SIR to LIR,
    |	        |       this generally contains anything related to
    |	        |       preparing the SIR for a backend stage.
    |           |-- linear - domain-specific optimization of linear filters.
    |           |-- fission - Contains fission transformations on SIR nodes.
    |           |-- reordering - Different re-arrangements of stream graph.
    |           |-- fusion - Contains fusion transformations on SIR nodes.
    |           |-- stats - Stub for statistics gathering package.
    |           `-- partition - Contains partitioners for load balancing.
    |               |-- dynamicprog - dynamic programming partitioner.
    |               `-- linear - automatic selection for linear opt.
    |
    `-- util - Miscellaneous utilities for use in different packages.

The top-level directory structure is as follows:

`-- streams
    |-- 3rdparty        Extra parts needed to run Kopi; taken directly
    |                   from the Kopi distribution.
    |-- apps            StreamIt benchmarks and applications
    |-- docs            Documentation for the language and compiler
    |-- include         Parts included by other parts of the
    |                   distribution, including Raw bc devices and
    |                   LaTeX macros
    |-- library         Uniprocessor C runtime library
    |-- misc            Scripts and helpers used by various things
    |-- regtest         Automated test infrastructure
    `-- src             Java sources for compiler and runtime library


The Scheduler
-------------

The component above that we haven't touched upon is the scheduler.
The role of the scheduler is to calculate/choose an execution ordering
for the filters in some graph or sub-graph, given all of their I/O
rates.  Right now our scheduler is a simple hierarchical scheduler
that schedules each stream container independent of its neighbors, but
we are working on a "phased scheduler" that is more fine-grained and
results in smaller buffer sizes between filters.

The scheduler can be used in several contexts.  It is used by the
fusion algorithm to statically schedule the components of a pipeline
or splitjoin. It is used by the Raw backend to simulate the execution
of the stream graph so that the routing instructions can be generated
for the switches on Raw.  It is used by the uniprocessor path to build
the work functions of stream containers when the SIR is being lowered
to the LIR.  And it is used for the work estimation phase of the
automatic partitioner, to determine how many times a given stream
segment executes in a steady-state execution of the graph.

The Front-End
-------------

All of the above assumes code written in legal Java, where StreamIt
objects are Java classes derived from the classes in the
streamit.library package ("old syntax").  A front-end package reads in
files written in the StreamIt language ("new syntax"), does some
processing, and spits out an old-syntax file that the compiler can
process.  This includes processing to change between syntaxes for
language features such as filter I/O rates, and eliminating language
features not present in Java (most notably, complex numbers).

The main entry point to the front-end is the streamit.frontend.ToJava
class.  This reads in the input file using an ANTLR grammar, and
creates a parse tree using the classes in the streamit.frontend.nodes
package.  This IR is immutable; visitor classes, generally derived
from streamit.frontend.nodes.FEReplacer, rewrite the IR tree.  Some
generic passes live in the streamit.frontend.passes package, and are
used to perform limited semantic checking and would otherwise be
useful outside of the context of conversion to Java.

Currently, the major task of the front-end is to produce Java code to
feed to Kopi.  This is done in the streamit.frontend.tojava package.
A couple of special IR nodes are introduced here to handle concepts
not otherwise present in the front-end, such as Java constructors for
the Channel object to "declare" an input or output type.
streamit.frontend.tojava.NodesToJava is the final class, which takes
the tattered remnants of the IR tree and spits out the desired Java
file.

The front-end can also be invoked to produce code for the StreamIt
Java library.  This is generally identical to what's produced for the
compiler, but differs on details for things like phased filters.
There are also plans to change the calling convention for init
functions for the library path only to avoid needing a valid
constructor for every possible set of parameters.  The output of the
front-end in this case would be directly compiled with javac,
and run with java.

FAQ: docs/implementation-notes/developer-FAQ.html
