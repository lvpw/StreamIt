\section{Streaming Virtual Machine API}

The Streaming Virtual Machine API is a set of data types and functions used to express the streaming portion of an application mapped to a specific VM by the high-level compiler. It includes streams and blocks which specify how data is mapped to memory, kernels which specify how computation and data-movement functions are mapped to processors, and control functions which are used by threaded code to control kernel execution.

The Streaming Virtual Machine API is a strict C subset, and can be compiled by a standard C compiler with 
a simple library for debugging and testing purposes.

We describe the API for streams and blocks in Section~\ref{sec:memory}, the API for kernels in Section~\ref{sec:kernel}, and the API for control in Section~\ref{sec:control}.

\subsection{Memory}
\label{sec:memory}

The SVM API specifies how data is mapped to memory using stream and block declarations in the control code.  Streams are used for sequential production and consumption of elements, while blocks provide random access to a fixed set of elements.  Streams are mapped to random-access memory or hardware FIFOs. Blocks are only mapped to random-access memory. We describe streams in Section~\ref{sec:streams} and blocks in Section~\ref{sec:blocks}.

\subsubsection{Streams}
\label{sec:streams}

A {\it stream} is a data type that represents a sequence of elements of a given type. 
The elements must have a fixed size. Variable sized elements can be supported at the language-level and compiled into the fixed size scheme using a data encoding. The stream type and supporting enumerations and functions are declared as follows:

{\small
\begin{verbatim}
  typedef struct {
    // not exposed
  } Stream;

  // aliases used by high-level compiler to indicate how a kernel uses a stream
  // to the low-level compiler
  typedef Stream IStream;
  typedef Stream OStream;

  //
  // stream initialization functions:
  //
  
  // make a stream mapped to random access memory <ramLocation>, 
  // allocated at <address> that can hold at most <capacity> elements
  // of size <elementSize>
  void streamInitRAM(Stream* s, VM_NODE_MEM ramLocation, int address, 
                     int capacity, int elementSize, int flags);

  // as above with <initLength> elements already in place and
  // EOS set if <initSetEOS>
  void streamInitWithDataRAM(Stream* s, VM_NODE_MEM ramLocation, int address, 
                             int capacity, int elementSize, int initLength, 
                             int initSetEOS, int flags);

  // make a stream mapped to hardware FIFO <fifoLocation> that contains
  // elements of size <elementSize>
  void streamInitFIFO(Stream* s, VM_NODE_MEM fifoLocation, int elementSize,
                      int flags);

  // flags used by high level-compiler to pass 
  // performance hints to the low-level compiler
  typedef enum /* STREAM_FLAGS */ {
    // True if FIFO semantics may be relaxed such that popping does not return   
    // elements in the same order that the elements were pushed. Peek cannot be
    // used if this flag is set.
    STREAM_UNORDERED = 0x1,

    // True if other streams/blocks not aliased with this stream and stream 
    // can have arbitrary layout in memory
    STREAM_UNALIASED_RAM = 0x2,
    
    // True if more than capacity elements will never be pushed
    STREAM_NEVER_WRAPS = 0x4
  } STREAM_FLAGS;  

  //
  // stream io functions, described in more detail below:
  //
  
  // pushes element onto stream, stalls if full
  void streamPush(Stream* s, void* element);
  
  // pushes element onto streams, stalls if any is full
  void streamPushMulticast(void* element, Stream* s0, Stream* s1, ...);
  
  // pops element off of stream, stalls if empty
  void streamPop(Stream* s, void* element);
  
  // peeks element n from the front of the stream
  // stalls if less than n+1 elements are available
  void streamPeek(Stream* s, int n, void* element);

  // sets the end of stream for the stream,
  // indicating that no more elements will be pushed  
  void streamSetEOS(Stream* s);

  // returns false if at least n+1 elements are available;
  // returns true if streamSetEOS has been called and
  // less than n+1 elements are available;
  // otherwise stalls until one of the above is true
  int streamGetEOS(Stream* s, int n);
\end{verbatim}}

\ssss{initialization functions} The stream initialization functions declare the location and size of the stream, and specify flags which give performance hints to the low level compiler. The {\tt streamInitRAMWithData} initialization function is used to initialize a stream which aliases RAM that already contains data.

Each stream mapped to random access memory for which the STREAM\_UNALIASED\_RAM flag is not set makes an important guarantee on its data layout: 
it is implemented as a circular buffer of length {\tt
capacity} that starts at the specified {\tt address} and wraps around to the beginning when more than {\tt capacity} elements have been pushed.  This guarantee is important for allowing reuse of memory space between streams, as well as for transferring data between threaded code and streaming code.  However, there is no contract on data layout at any time if the STREAM\_UNALIASED\_RAM flag is set. This gives 
the low-level compiler the freedom to implement streams with an 
architecture-specific representation if their contents are never aliased.

The initialization function's {\tt initLength} parameter indicates how many elements are already in place at {\tt address} that should be pushed onto the stream initially. It requires the STREAM\_UNALIASED\_RAM flag not be set.

\sss{Stream IO Functions}

We now turn our attention to the other stream functions, which are used by kernels to write and read the stream.

\ssss{streamPush} For output streams, the {\tt streamPush} function enqueues a value onto the end of the stream.  If the stream cannot hold any more elements 
then streamPush stalls until there is space available. 

\ssss{streamPushMulticast} The streamPushMulticast function pushes 
the same data onto multiple streams, and is equivalent to a series of streamPush 
operations with the same argument but provides an opportunity for optimization by the low-level compiler.

\ssss{streamPop} For input streams, the {\tt streamPop} function dequeues a value from the front of the stream.  If there are no elements in the stream, then streamPop stalls until an element is available.

\ssss{streamPeek} For ordered input streams, the {\tt streamPeek} function returns the element at position {\it index}, where {\it index} is zero-indexed (such that {\tt streamPeek(0)} gives the same value as {\tt streamPop()}).  If there are fewer than $\mt{index}+1$ elements in the stream, then streamPeek stalls until $\mt{index}+1$ elements are available. If $\mt{index}+1$ exceeds the capacity of the stream, then the 
return value is undefined.

\ssss{streamSetEOS and streamGetEOS} In some cases the number of elements which can 
be popped from a stream is variable and determined by the producing kernel. 
The producing kernel can encode this information directly in the data stream, 
but doing so often ignores hardware support and incurs overhead for each element. For this reason, the Stream API provides the {\tt streamSetEOS} and {\tt streamGetEOS} 
functions. After pushing the last element onto a stream, the producing kernel can call 
{\tt streamSetEOS} to indicate that no more elements will be pushed. The 
consuming kernel can call {\tt streamGetEOS} at any time. {\tt streamGetEOS} with argument  
{\it index} stalls until either index + 1 elements are available or {\tt streamSetEOS} is called. It then returns false if index + 1 elements are available, true otherwise. 

\subsubsection{Blocks}
\label{sec:blocks}

For kernels that require random access to a fixed set of elements, the API provides the {\it block} abstraction.  A block is simply a region of memory that can be read and written to.  The block type and 
supporting functions are declared as follows:

{\small
\begin{verbatim}
  typedef struct {
    // not exposed
  } Block;

  // aliases used by high-level compiler to indicate how a kernel uses a block
  // to the low-level compiler
  typedef Block IBlock;
  typedef Block OBlock;

  // make a block mapped to memory node <ramLocation>, 
  // allocated at <address> that can hold at most <capacity> elements
  // of size <elementSize>
  void blockInit(Block* b, VM_NODE_MEM ramLocation, int address, 
                 int capacity, int elementSize);

  //
  // block io functions, described in more detail below:
  //

  // writes element to block
  void blockWrite(Block* b, int index, void* element);

  // reads element from block
  void blockRead(Block* b, int index, void* element); \end{verbatim}}

\ssss{initialization functions} The block initialization function declares the location and size of the block.

\sss{Block IO Functions}

\ssss{blockWrite} For output blocks, the {\tt write} function stores an element into memory.  It requires that the {\tt index} written to is less than the block's {\tt capacity}.  

\ssss{blockRead} For input blocks, the {\tt read} function reads a location in memory.  It requires that the {\tt index} read is less than the block's {\tt capacity}.

\subsection{Kernels}
\label{sec:kernel}

Kernels are used to map computation to processors. 
The API has support for three kinds of kernels. Section~\ref{sec:kernelhlc} describes general user-defined kernels whose behavior is explicitly described by the high-level compiler; Section~\ref{sec:kernelsvm} describes pre-defined kernels that are built into the SVM and must be supported on every architecture; and Section~\ref{sec:kernelllc} describes library kernels that appear as a black box to the high-level compiler. 

All three types of kernels share a base data type that 
specifies where the kernel is executed and is passed to functions that control kernel execution, and a common execution model.

Kernels have the following components:

\begin{enumerate}

\item An initialization function, which receives the following: 
\begin{itemize}
\item The processor resource where the kernel will execute. 
\item (Optional) A block of memory for spilling local variables. 
\item The input and output streams and blocks for the kernel. 
\item Any other kernel-specific initialization data. 
\end{itemize}

\item A {\it work} function that defines the execution of the kernel.

\item (Optional) A data type which represents kernel data that is accessible to the control thread before, after, and at certain times during kernel execution.

\item A {\it status} that reflects the current state of the kernel.

\item Control functions used to execute the kernel.

\end{enumerate}

\sss{Kernel Base Data Type}

All kernels share a base data type which is extended to 
create specific kernels. The kernel type and 
supporting functions are declared as follows:

{\small
\begin{verbatim}

  typedef struct {
    // not exposed
  } Kernel;

  // function pointer to work function
  typedef void (*ExtKernelWork) (void* extKernelData);

  // makes a kernel that executes on processor <procLocation>,
  // spills to memory <scratch> and is extended with the encompassing
  // data type <extKernelData> of size <extKernelDataSize> and work
  // function <extKernelWork>
  void kernelInit(Kernel* k, VM_NODE_PROC procLocation, Block* scratch,
    void* extKernelData, int extKernelDataSize, ExtKernelWork extKernelWork);

  // kernel status codes
  typedef enum {
      KERNEL_UNSTARTED,
      KERNEL_WAITING,
      KERNEL_RUNNING,
      KERNEL_PAUSED,
      KERNEL_FINISHED
  } KERNEL_STATUS;

  //
  // kernel control functions, described in more detail below:
  //

  // non-blocking function that indicates that kernel <k> should not 
  // execute the work function until kernel <dependsOnKernel> is FINISHED.  
  // This function can only be called when the <k> is in the UNSTARTED state.
  void addDependence(Kernel* k, Kernel* dependsOnKernel);

  // hint to low-level compiler to ready the kernel in the ICache.
  void kernelReady(Kernel* k);

  // non-blocking function that starts or resumes execution of this kernel. 
  // The kernel continues to run until its status is PAUSED or FINISHED.
  void kernelRun(Kernel* k);

  // non-blocking function that interrupts execution of a kernel on a
  // best-effort basis, and then sets the kernel's status to PAUSED.  This 
  // should be followed by a call to kernelWait() if the control thread wants to
  // ensure that the kernel is paused.
  void kernelPause(Kernel* k);

  // non-blocking function that interrupts execution of a kernel on a 
  // best-effort basis, and then sets the kernel's status to FINISHED.  This 
  // should be followed by a call to wait() if the control thread wants to 
  // ensure that the kernel is finished.
  void kernelEnd(Kernel* k);

  // waits for the status of the kernel to be PAUSED or FINISHED.
  void kernelWait(Kernel* k);

  // waits for at least one kernel to be PAUSED or all kernels to be FINSIHED
  void kernelWaitMultiple(Kernel* k0, Kernel* k1, ...);

  // returns the current status of the kernel as last known by the control
  // thread
  KERNEL_STATUS kernelGetStatus(Kernel* k);
\end{verbatim}}

\sss{Kernel Execution Model}


\begin{figure}[t]
\framebox[6.5in]{
\begin{minipage}{6in}
\begin{center}
\psfig{figure=state.eps,width=5in}
\end{center}
\caption{Legal transitions of a kernel's {\tt status} \protect\label{fig:kernel-status}}
\end{minipage}}
\end{figure}

Kernels have a simple execution model. A kernel is initially {\tt UNSTARTED}. 
The control thread calls {\tt kernelRun()}, the kernel becomes {\tt WAITING}. When all kernels it depends on (as explicitly indicated by 
the {\tt kernelAddDependence} function) are {\tt FINISHED}, the kernel becomes {\tt RUNNING}. The kernel executes its {\tt work()} function. 
If either the control thread or the work function calls {\tt kernelPause()}, the kernel pauses in executing the work function and becomes {\tt PAUSED}. It remains {\tt PAUSED} until the control thread calls {\tt kernelRun()} again. If either the control thread or the work function calls {\tt kernelEnd()} at any time when the kernel is not {\tt FINISHED}, the kernel stops executing the work function and becomes {\tt FINISHED}. The kernel implicitly calls {\tt kernelEnd()} when the work function returns. A transition diagram for the legal states of a kernel appears in Figure~\ref{fig:kernel-status}.

Kernels can occur inside loops, and so can be executed multiple times. If the kernelAddDependence function is called to make kernel {\tt k1} dependent on kernel {\tt k2}, but {\tt kernelRun()} is called on {\tt k1} before {\tt kernelRun()} is called on {\tt k2}, the result is to make {\tt k1} dependent on the previous execution of {\tt k2}. If there is no such execution, the dependence is ignored. For instance:

{\small
\begin{verbatim}
  while (...) {
    kernelAddDependence(&k1.kernel, &k2.kernel);
    kernelRun(&k1.kernel);
    kernelAddDependence(&k2.kernel, &k1.kernel);
    kernelRun(&k2.kernel);
  }
\end{verbatim}}

\subsubsection{User-Defined Kernels}
\label{sec:kernelhlc}

The kernel base data type is extended to different kinds of 
kernels by declaring a new data type for each kernel 
which includes the kernel base data type,
an initialization function that calls the kernel 
initialization function, and work function that 
operates on the new data type. 

For example, a kernel for a simple amplifier could be as follows:

{\small
\begin{verbatim}
  typedef struct {
    Kernel kernel;
    IStream* in;
    OStream* out;
    int N;
  } Amplifier;

  void amplifierWork(Amplifier* amp);

  void amplifierInit(Amplifier* amp, VM_NODE_PROC procLocation, Block* scratch, 
                           IStream* _in, OStream* _out, int _N) {
      kernelInit(&amp->kernel, procLocation, scratch, 
        amp, sizeof(Amplifier), (ExtKernelWork)&amplifierWork);
      amp->in = _in;
      amp->out = _out;
      amp->N = _N;
  }

  void amplifierWork(Amplifier* amp) {
      while(!streamGetEOS(amp->in, 0)) {
        float x;
        streamPop(amp->in, &x);
        x = x * amp->N;
        streamPush(amp->out, &x);
      }
  }
\end{verbatim}}

\sss{User-defined Kernel Restrictions}

The initialization function must store the input and output streams with a one-to-one mapping from arguments to streams, and no surrounding control flow.  This allows {\tt work} to access the streams.

The {\tt work()} function only supports a subset of C; restrictions are listed in Figure~\ref{fig:restrict}.  

\begin{figure}[t]
\framebox[6.5in]{
\begin{minipage}{6in}
\begin{enumerate}

\item No pointers, except for those directly passed to 
stream, block, and kernel functions as described in this document.

\item No dynamic memory allocation.

\item No accesses to global variables.

\item No GOTO statements (all control flow is structured).

\item No recursive functions (all function calls have inline semantics).

\item No calls to functions that violate any of these restrictions.

\item Supported opcodes are only the logical, arithmetic, and boolean operations found in C (no special-purpose DSP operations at this time\footnote{DSP operations may be added at a future date pending further discussion by the forum.}).

\item Supported types include 64-bit {\tt double}, 64-bit signed and unsigned {\tt long}, 32-bit {\tt float}, 32-bit signed and unsigned {\tt int}, 16-bit signed and unsigned {\tt short}, 8-bit {\tt byte}, {\tt boolean}, arrays with a fixed (int literal) length, and {\tt struct}'s containing members of any other type.

\end{enumerate}

\caption{Restrictions on C code within kernels.\protect\label{fig:restrict}}
\end{minipage}}
\end{figure}

\subsubsection{Pre-Defined Kernels}
\label{sec:kernelsvm}

\label{sec:predef}

Special pre-defined kernels are used to move streams and blocks between memories. These kernels are typically executed by DMA processors, but may be executed by stream processors on some architectures.

\ssss{Copy} The primary use of this kernel is for copying elements between streams in different memory banks, though it can also be used for copying between streams in a single memory. 
{\small \begin{verbatim}
  typedef struct {
    Kernel kernel;
    // not exposed
  } Copy;
  
  const int STREAM_LENGTH_ALL = -1;
  
  void copyInit(Copy* copy, VM_NODE_PROC location, IStream* srcStr, 
                OStream* destStr, int length);
\end{verbatim}}

The {\tt length} argument indicates how many elements should be transferred. Passing a length of {\tt STREAM\_LENGTH\_ALL} indicates that all elements in the {\tt srcStr} are copied. Use of {\tt STREAM\_LENGTH\_ALL} requires use of {\tt setEOS} to set the end of {\tt srcStr} and results in the {\tt Copy} calling {\tt setEOS} on {\tt destStr} after all elements have been transferred.

\ssss{Scatter/Gather} A set of scatter and gather kernels allow copies between non-contiguous elements within blocks and streams.  The strided kernels are for copying regularly spaced chunks into or out of a block: 
{\small \begin{verbatim}
  typedef struct {
    Kernel kernel;
    // not exposed
  } StridedScatter;
  
  void stridedScatterInit(StridedScatter* scatter, VM_NODE_PROC location, 
                          IStream* srcStr, OBlock* destBlock, int length,
                          int destStride, int elementsPerStride);

  typedef struct {
    Kernel kernel;
    // not exposed
  } StridedGather;
  
  void stridedGatherInit(StridedGather* gather, VM_NODE_PROC location, 
                         IBlock* srcBlock, OStream* destStr, int length,
                         int srcStride, int elementsPerStride);
\end{verbatim}}

The above kernels copy elements in segments of {\tt elementsPerStride} elements. The {\tt srcStride} or {\tt destStride} indicates the number of elements between the start of adjacent segments, while {\tt length} represents the total number of elements that should be copied ({\tt STREAM\_LENGTH\_ALL} may be used as with copy, indicates up to end of block for gather).

The indexed scatter and gather kernels allow irregular accesses to a source or destination block: 
{\small \begin{verbatim}
  typedef struct {
    Kernel kernel;
    // not exposed
  } IndexedScatter;

  void indexedScatterInit(IndexedScatter* scatter, VM_NODE_PROC location,
                          IStream* srcStr, IStream* indexStr, OBlock* destBlock, 
                          int length, int elementsPerIndex);
                     
  typedef struct {
    Kernel kernel;
    // not exposed
  } IndexedGather;

  void indexedGatherInit(IndexedGather* gather, VM_NODE_PROC location, 
                         IBlock* srcBlock, IStream* indexStr, OStream* destStr, 
                         int length, int elementsPerIndex);
\end{verbatim}}

In the {\tt IndexedScatter} kernel, the {\tt indexStr} indicates the positions in the output stream at which the records should be written; in the {\tt IndexedGather} kernel, the {\tt indexStr} indicates the positions in the input stream at which the records should be read. The {\tt length} argument indicates the number of elements that should be copied ({\tt STREAM\_LENGTH\_ALL} may be used as with copy, indicates up to end of indices for gather).

\subsubsection{Black-Box Library Kernels}
\label{sec:kernelllc}

The API supports library routines via black-box kernels that are defined in the metadata and then instantiated by name in the stream control code.  These kernels are identical to user-defined kernels, except that their {\tt work} functions are not defined; instead, they are 
recognized by the low-level compiler for the architecture and are 
translated into hand-optimized library code.

To ensure that the low-level compiler can recognize a black-box kernel, the high-level compiler guarantees that it will not merge black-box kernels with other kernels, or rename a black-box kernel so that it would become unrecognizable to the low-level compiler.

\subsection{Control}
\label{sec:control}

Threaded code is used to declare streams, blocks, and kernels and control the execution of kernels.

An example follows:
{\small
\begin{verbatim}
  int length1;
  int length2;
  Stream s0;
  Stream s1;
  Stream s2;
  Stream s4;
  Stream s5;
  Block scratch2;
  Copy copy01;
  RLE rle;
  Copy copy45;

  // read file into memory location of s0 (not part of API)
  length1 = readFile("input.dat", GLOBALMEM1, 0x1000, 1024);

  streamInitWithDataRAM(&s0, GLOBALMEM1, 0x1000, 1024, 4, length1, 1, STREAM_NEVER_WRAPS);
  streamInitRAM(&s1, LOCALMEM1, 0x0, 256, 4, STREAM_UNALIASED_RAM);
  streamInitRAM(&s2, LOCALMEM1, 0x100, 128, 4, STREAM_NEVER_WRAPS);
  
  blockInit(&scratch2, LOCALMEM1, 0x180, 32, 1);

  // copy data from  main memory to local memory
  copyInit(&copy01, DMA1, &s0, &s1, STREAM_LENGTH_ALL);
  // rle encode it as it is loaded
  rleInit(&rle, PROC1, &scratch2, &s1, &s2);

  // run the kernels
  kernelRun(&copy01.kernel);
  kernelRun(&rle.kernel);
  kernelWait(&rle.kernel);

  // if the output is still too large, run additional compression, 
  // overwriting s2 in place
  length2 = rle.outputLength;
  if (length2 > SIZE_THRESHOLD) {
    Stream s3;
    Block scratch3;
    Zip zip;

    streamInitRAM(&s3, LOCALMEM1, 0x100, 128, 4, STREAM_NEVER_WRAPS);
    blockInit(&scratch3, LOCALMEM1, 0x180, 32, 1);
    
    zipInit(&zip, PROC1, &scratch3, &s2, &s3);
    kernelRun(&zip.kernel);
    kernelWait(&zip.kernel);
    length2 = zip.outputLength;
  }
  
  // copy data from  local memory to main memory
  streamInitWithDataRAM(&s4, LOCALMEM1, 0x100, 128, 4, length2, 1, STREAM_NEVER_WRAPS);
  streamInitRAM(&s5, GLOBALMEM1, 0x2000, 1024, 4, STREAM_NEVER_WRAPS),
  copyInit(&copy45, DMA1, &s4, &s5, STREAM_LENGTH_ALL),
  kernelRun(&copy45.kernel);
  kernelWait(&copy45.kernel);

  // store the result from memory to "output.dat" (not part of API)
  writeFile("output.dat", GLOBALMEM1, 0x2000, length2); \end{verbatim}}

The above code fragment illustrates several aspects of the stream control API.  In the rest of this section, we describe the 
capabilities and limitations of the stream control API.

\sss{Transferring Data Between Kernels}

There are two ways to transfer the outputs of one kernel to the inputs of another.  Perhaps the most natural way is to reuse the same stream, thereby carrying over the results; in our example, stream {\tt s2} is used by multiple kernels.  The other way to transfer elements is by allocating a new input stream that overlaps with the output stream in memory.  In this case, the control code should indicate that the kernel reading the new stream is dependent on the kernel that wrote the original stream; this is done by use of the kernel's {\tt kernelAddDependence} function, thereby saving the low-level compiler from doing location-based memory analysis to discover dependences between kernels.

\sss{Transferring Data Between Threaded Code and Kernels}

Before kernel execution, streams can be initialized with (possibly
non-streaming) data from general-purpose threaded code.  Likewise, the results of a streaming computation can be used in the threaded code following the kernel's execution.  Both of these transfers are done through memory, either using memory management kernels as in the example  or by directly accessing the memory assigned to a stream.  The control thread can rely on the sequential data layout guaranteed by streams when managing this communication (see Section~\ref{sec:streams}). 
Also note that most device I/O (such as file handling and terminal interaction) is done 
by threaded code, and then made available to streams through memory.  
For direct interaction with streams, I/O devices can be described as 
processors that support a single black-box kernel.

It is also possible for the control processor to inspect and modify the data members of a kernel when it is not in the 
{\tt WAITING} or {\tt RUNNING} states. Accesses to kernel fields are 
useful for passing parameters to a kernel or retrieving reduction 
values from a kernel.  For example: 

{\small
\begin{verbatim}
  // --- kernel code ---
  typedef struct {
    Kernel kernel;
    IStream* in;
    int sum;
  } SumKernel;

  void sumKernelWork();
  
  sumInit(SumKernel* k, VM_NODE_PROC procLocation, Block* scratch, IStream* _in) {
    kernelInit(&k->kernel, procLocation, scratch,
      k, sizeof(SumKernel), (ExtKernelWork)&sumKernelWork); 
    k->in = _in;
    k->sum = 0;
  }

  void sumKernelWork(SumKernel* k) {
      while(!streamGetEOS(k->in, 0)) {
          int x;
          streamPop(k->in, &x);
          k->sum += x;
      }
  }

  // --- control code ---
  Stream s1;
  Block scratch1;
  SumKernel sk;
  int finalSum;

  streamInitRAM(&s1, LOCALMEM1, 0x100, 128, 4, 0);
  
  // data is pushed to s1
  // ...

  blockInit(&scratch1, LOCALMEM1, 0x180, 16, 1);
  sumInit(&sk, PROC1, &scratch1, &s1);
  kernelRun(&sk.kernel);
  kernelWait(&sk.kernel);
  finalSum = sk.sum;
}\end{verbatim}}

\sss{Managing Kernel Instruction Memory}

The high-level compiler might anticipate upcoming kernel executions. The {\tt kernelReady} function allows this information to be transferred to the low-level compiler so that the kernel can be loaded into IMEM ahead of time.

\subsubsection{Restrictions on Stream Control}

There are restrictions on the stream control code to ensure a valid hardware mapping and allow simple analysis by the low-level compiler. However, there are no restrictions on non-streaming statements, which can be finely interleaved with the stream statements; these statements can be arbitrarily complex threaded code.

In order to represent a valid hardware mapping, there are several restrictions:

\begin{enumerate}

\item More than one kernel may read or write a stream over the course of a program but only one {\tt WAITING}, {\tt RUNNING}, or {\tt PAUSED} kernel may be reading a stream at any given time and only one {\tt WAITING}, {\tt RUNNING}, or {\tt PAUSED} kernel may be writing a stream at any given time.

\item A kernel may only read from or write to streams that are mapped to memories directly connected to the processor executing the kernel (there must exist a series of connections with no intervening 
processors or memories that connects the processor running the kernel to 
the memory that contains the stream.)

\item Only one stream mapped to a hardware FIFO may contain data at any given time.

\item Only one user-defined kernel may be {\tt RUNNING} or {\tt PAUSED} on a stream processor at any given time.

\item Any number of pre-defined memory management kernels may be {\tt RUNNING} or {\tt PAUSED} on a DMA processor at any given time.

\end{enumerate}

In order to facilitate static analysis in the
low-level compiler, there are a number of restrictions:

\begin{enumerate}

\item There may only be one call to an initialization function for a given stream, block, or kernel variable. That call must precede any use of the variable. This exposes exactly which initialization function is invoked for a given variable name.

\item It is illegal to take the address of a stream, block,
or kernel variable, except to pass it directly to a function declared in this document. Thus, these variables cannot be aliased other than streams and blocks within extensions of the kernel base data type.

\item Stream, block, and kernel variables may not be part
of structures except for extensions of the kernel base data type.

\item Any function that contains a stream, block, or kernel variable 
must NOT be called recursively or through a function pointer, even indirectly (e.g. cannot be called from a recursive function, 
or a function called from a recursive function, etc.).

\item Architecture resources must be specified by literals when they are passed to stream, block, or kernel functions.  That is, constants denoting processor nodes, memory nodes, connections, and channels must be passed to API functions directly, rather than passing the value in a variable.

\item Element sizes and flags must be specified by literals when they are passed to stream and block functions.

\end{enumerate}
