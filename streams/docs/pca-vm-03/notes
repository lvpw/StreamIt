Things to bring to front of intro:

- structure of morpwhare flow (hlc, llc, etc.)

  - reason this is interesting -- in streaming domain, much more opportunity for HLC orchestration of resources, etc.

  - responsibilities for each

  - expect that there will be some kind of feedback from llc

  - machine model diagram where SVM is function of machine model

- then machine model -> svm.  svm is specified as set of API calls.

- goals of svm?  Express high-performance mapping for multiple applications and architectures.  this means:

  - separate control and data-intensive code, so that data-intensive code can be explicitly compiled to stream processors
  - explicitly manage memory for data-intensive codes (DMA instead of caches)
  - expose streaming nature of computation (for communication-exposed architectures)
    - in many cases can be mapped onto FIFO's
    - i/o devices are also represented as black-box kernels; can be
      streamed directly into architecture without going through memory

- easy to translate by low-level compiler
- human comprehensible and writable
- includes performance hints where it can

-----

- (Peter) SVM describes mapping, is not intended as a programming language

  - all information relevant to the mapping is encoded in programming
    language terms, but there are certain restrictions to ensure that
    mapping is easy to extract

- (Peter) streaming and kernels are separate abstractions
- (Peter) spec introduces the notion of streaming DMA -- continuous data movement, not pre-blocked

- notion of machine model, SVM being a function of machine model (DIAGRAM)

- expect that there will have to be some kind of feedback for llc

- notion of pre-defined and black box kernels
  - for I/O, DMA, library functions
  - move, scatter/gather

- streams
  - init
  - peek, pop, push (with EOS)

- blocks
  - init, read, write

- kernels
  - init
  - dependences
  - run, pause, end


HLC responsibilities
 - parallelization for data, task, pipeline parallelism
 - does load balancing (fusion/splitting of stream language kernels)
 - assignes SVM kernels to particular processor resources
 - schedules order of execution of SVM kernels on processors
 - assigns svm/blocks to particular rams or fifo's
 - also manages compiler-controlled memories (SRF)
 * give performance hints in code

LLC responsibilities
 - code generation
 - routing
 - manages instruction memory on stream processors
 - manages communication between kernels and controls

*********************************************************************************

questions:

1. can a stream be aliased if it's in a FIFO?  that is, can you
declare another stream to be on the same fifo, and then pop items from
that other stream?  I guess not.

things to check with peter:

- only a single thread can control a given kernel?

- should we allow multiplexing of user kernels?

- I'm a little concerned about requiring that there are no data
  elements in the FIFO before you map a new stream there.  How would
  you generate SVM code to verify this?  It would be a mess, at the
  very least.  And on Raw it is fine to pipeline your use of FIFO's --
  maybe Monarch was a different story?

- I don't understand the supports_user_code property

- Can a tile be its own master, or not?  It should be for the sake of
morphing, I think (e.g., turning the whole Raw chip into a single
processor.)

done changes:

2. cleaned up description of STREAM_UNALIASED_RAM

3. Clarified STREAM_LENGTH_ALL for scatter/gather.

4. removed setEOS tag to StridedScatter, IndexedScatter kernels

5. clarified description of scatter/gather kernels

6. adding IOBlock (why wasn't it there?)

7. expanding documentation of API calls

8. added maxBuffering parameter to streamInit

9. removed "restrictions" that are covered by some requires clauses

10. added example of clearing FIFO state using SVM primitives

biggest changes:

 - clarifications of API calls and predefined kernels
 - updated to refer to new machine model
 - additions:
   - example of clearing FIfO state
   - timeline of thread/kernel interaction
   - performance flag for streams (maxBuffering)
   - a striction:  only one thread can control a given kernel

*********************************************************************************

> EASY-4. Create timeline for thread kernel interoperation to show
> efficiency of interaction

This will just be a diagram, somewhat like your slide from the San Diego
Morpwhare meeting, with calls going back and forth between the thread
and kernel.

*********************************************************************************
NOT DOING

- the business of access to 'global' variables?

- a grungy open issue: what's the interface for saying with control
codes run on which processors?  just have output of HLC that
associates them.

  - maybe a different file for each, with a mapping between them?  or
    just have a mapping between which function goes to which processor.

- implement reference versions of the predefined kernels

- could make more clear that the reason you would want to map more
than one stream to a fifo (thereby needing the "only one can retain
state at once" restriction) is that they could differ in changing EOS,
elementSize, flags, etc.

*********************************************************************************
DONE items.

> MED-2. Define clear semantics for:
>   - FIFO cleanup of any residual data after kernel termination
>   - When an up stream kernel stalls and a down-stream kernel terminates,
>    how does the up stream kernel, stream storage, etc. get cleaned up

I think this should all be controlled by the HLC.  For the example
given, the HLC will see that the downstream kernel can terminate
randomly, and thus it should keep a count of the number of items that
kernel has popped.  It also keeps track of how many items the upstream
kernel has pushed.  When the downstream kernel terminates, it tries to
terminate the upstream kernel, then uses a Drain kernel to get rid of
the difference in the number of items.

(That scenario would only be needed if the kernels are communicating
through a FIFO; a memory stream might be left with random data in it.)

But in all, there is no kind of complex draining or cascaded termination
built into the LLC.

> MED-6. Clarify control/kernel operation in multiprocessor environment
>   x Access to data, synchronization,
>   x Which functions are used by kernel vs. thread control
>   x Define interaction of multiple master threads and role with
>     streaming kernels

I think this is a matter of annotating each function with THREAD or
KERNEL.  There might be some issues in having multiple threads control a
given kernel simultaneously... will have to think about that.

x say that only a single thread can control a given kernel?

? I have a proplem with A8 (only one stream mapped to a hardware fifo
may retain state at any given time) as well as the general model for
FIFO's and streams.  Should it be possible for a sender and receiver
to use different stream objects?  hmm.

  * why would you ever map more than one stream to a fifo?  wouldn't
   it be simpler just to say that only one stream can be mapped to
   a given fifo?

    --> well, I guess if you were changing EOS, elementSize, flags, etc.

  - how would HLC ever enforce the restriction that only one stream on
    a given FIFO retains state at a given time?

  - why not just say that all streams mapped to a given fifo share the
    fifo semantics.  actually, why have streams when referring to a
    fifo?  They are first-in, first-out ... gah, but maybe not on a FIFO.

  - why can't you call streamInitWithDataRAM on a FIFO?  Apparently I
    don't really understand the Monarch FIFO's.

1. remove IStream/OStream/IOStream aliases.  This should remove the
confusing writeup about IOStreams; instead we just have the constraint
that each stream must have exactly one reader and exactly one writer,
and the same kernel can be the reader and writer.

  -- also remove IBlock/OBlock.  (Why wasn't there an IOBlock?)

  --> gah, this will make documenting some things harder

> 1. Items Bill Will Address
> **************************
>
> EASY-1. Provide precise semantics of multicast push (also multicast push with EOS)

Pushes an item onto the given streams, in any order (or simultaneously.)
Will not return until an item has been pushed onto all streams.

For example, if s1 is empty and s2 is full, then the following are
all legal implementations of streamMulticastPush(x, s1, s2):

  - Push x onto s1, wait until s2 is not full, then push x onto s2.
  - Wait until s2 is not full, push x onto s2, then push x onto s1.
  - Wait until s2 is not full, push x onto s1, then push x onto s2.

- bad cases:

  - a kernel is paused and then re-initialized when someone was
    waiting for it to finish.  Does that count as satisfying the
    dependence, or not?  no, it should go through kernelEnd.

*********************************************************************************

Promised changes due 8/17/03

I can clarify the SVM document and produce a new draft within a few
days.  However, some of the proposed revisions would need more
initiative from other architecture teams, and I am comfortable letting
them be for now.

In what follows, I divided up all the SVM action items from the last
Morphware meeting.  This represents my current plan for this revision.

I categorized things as follows:

  1. Items I plan to address.

  2. Items that require changes to the metadata (Peter)

  3. Items to discuss with Mike Vahey (and possibly others?).  I believe
     these changes are not needed, but we need to reach a consensus.

  4. Items I don't understand.

  5. Items to let be for now.

If an architecture team is particularly concerned about something in
category (4) or (5), perhaps you could take the lead on that item.

Also, I'd be happy to present this revision at the meeting, although I
expect this should be a quick set of diffs and clarifications from the
last revision rather than a full review of the SVM.

-Bill

------------------------------------------------------------------------

1. Items Bill Will Address
**************************

EASY-1. Provide precise semantics of multicast push

EASY-4. Create timeline for thread kernel interoperation to show
efficiency of interaction

MED-2. Define clear semantics for:
  - FIFO cleanup of any residual data after kernel termination
  - When an up stream kernel stalls and a down-stream kernel terminates,
   how does the up stream kernel, stream storage, etc. get cleaned up

MED-6. Clarify control/kernel operation in multiprocessor environment
  - Access to data, synchronization,
  - Which functions are used by kernel vs. thread control
  - Define interaction of multiple master threads and role with
    streaming kernels

2. Items for Peter to Address in the Metadata
*********************************************

EASY-2. Add new meta data item to show required alignment of a data item
within a memory (for correctness or performance)

EASY-6. Add to meta data the number of kernels that can be run on a
processor concurrently.

NEW: I propose that we add in the metadata a list of types that a given
processor supports.  This will fix all of the following items:

  EASY-3. Include data type for signed and unsigned 8 bit data

  MED-1. Define allowable implementation subsets of SVM API
     - Define specific profiles if appropriate

  MINUTES-1 adding signed 8 bit type.  Make 64-bit types optional.
     Allow an SVM to implement some subset of the types.

3. Items to Discuss with Mike Vahey (and others)
************************************************

- Do we need an "unloaded" state?  This covers:

  EASY-5. Clarify kernel states, needs and transitions

  MINUTES-2 adding "unloaded" state for kernels; effect how long kernel
     values persist, useful in multiprocessor synchronization.

MED-7. Clarify links / connections role in the SVM API.

4. Items I don't understand
***************************

MED-3. SVM execution on a sequential processor

MED-5. Define means of representing I/O functions in SVM and metadata

5. Items to let be for now
**************************

MED-4. Provide means for timely notification to thread control of
special event in stream kernel (e.g., exception or interrupt method)

MED-8. Performance feedback
 - HLC passes expected performance numbers as comments to LLC
  (for development purposes)
 - LLC may want to create data collection metric

MED-9. Extend and refine concept of operations

HARD-1. Real time or latency aspects of stream processing
  - Define requirements
  - Assess impact on SVM API and necessary changes

HARD-2. Fault tolerance or morph controls for dynamic reassignment of
kernels/communications to underlying resources
  - Assess when logical resources should be bound to physical resources
  - Determine how compile time constraints impact code relocation

HARD-3. Determine type and use of cost functions for each SVM function

> Bill,
>
> One of the action items out of the last Forum meeting was for the
> architecture groups + Reservoir to update the SVM spec with the various
> comments and clarifications from the last meeting.  We hoped to have an
> update to re-post to the Forum by about now; and then to go over the
> changes in Santa Fe.  Will there be an update available to post soon
> (hopefully, very soon)?  And how about you leading the discussion of it at
> the Forum this time?
>
> -- Mark R
>
>
> _______________________________________________________________________
> Dr. Mark A. Richards                                Voice: 404-894-2714
> Principal Research Engineer & Adjunct Professor       FAX: 404-894-0560
> School of Electrical & Computer Engineering
> Georgia Institute of Technology
> 777 Atlantic Drive                 e-mail: mark.richards@ece.gatech.edu
> Atlanta, GA 30332-0250         web: http://www.ece.gatech.edu/~mrichard
>

*********************************************************************************

Call with Peter on 4/23/03
--------------------------

issues:

  - Graphs
  - canPop / canPush
  - routing issues (stream-stream connections)

---

- implement canPop but not canPush
  - keep the index into canPop
  - have end-of-stream token

- no graphs

- so have popEos, pushEos, peekEos (possibly do a postpass on syntax)
  - preserves kahn semantics - can't tell buffer size by pushing
  - canPop returns bool

- suspend is a method call from the work function

  - can still specify dependences on inputs to kernels, for before
    they start running

- agree:  input the connectivity to the HLC
  - not sure whether or not HLC outputs the routing information
  - (connection+)-fifo-(connection+) processor

- will pass the token to Peter for the next 

- multicast:  
  - push, pop are methods of kernel
  - also have varargs push

- undefined streams:  peekEos 

- keep aliasing guarantees we had before

-----

- issues:

  - who's taking control of this document

  - Graphs, etc.

  - what about canPop, canPush / draining & killing semantics


conference call with mike vahey, peter, francois
------------------------------------------------

- I/O devices just have input/output assembly instruction.  data
  coming in will stream in forever.  if attached to file there is an
  end-of-file signal.

- different classes of memory in the processor.  use a PPC somewhere,
  have DMA engines between memory and processor

- have internal memories between the elements of the processing core.
  these can stream in data from addresses, store to addresses.

- ratio is ~1 memory unit for every pair of adder/multiplier combo's.

- so we can represent core as N adders, N multipliers

- can peek on the interconnect, up to about 4 items. the interconnect
  between memories and functional units is also buffered.

- want to assign a single op to a given functional unit

- you can have cycles in the dataflow graph

- the basic functional unit is both an adder and a multiplier

- internal memories used for FIFO's on occaision, or FFT stuff, or
  bit reversal on occaision; can have random access

- minimum size of small memories is ~512 words

- regarding threaded kernels... alternate mode of execution is in
  threaded form, kind of doing SIMD stuff; have an actual register
  file.  256-bit wide datapath, could operate in parallel.

- in actual baseline chip, there are twice as many adders in dataflow
  mode.  Also in dataflow, you can do both add and multiply, but in
  threaded, you can do either add or multiply.  (So factor of two
  automatically.)

- can run up to 8 threaded kernels on a chip, all of them accessing
  the FPCA in threaded mode.

- can run part of the chip in dataflow, part of the chip in threaded
  kernel mode.  e.g. 3/8'ths one and 5/8'ths the other.

- can have tokens passed around like standard dataflow architecture,
  e.g. for limited support for control flow, etc.

- you can access leftover items in graph; there's a command to purge
  them if you like.  can suspend the graph and then restart that
  graph running, even if DMA was blocking or something.

- usually think of a single stream being assigned to a resource; you
  can multiplex multiple streams on a resource but they're still
  in-order between them.

- discussing canPush/canPop -- currently there is no ability to test
  the availability of a given data item, or if a FIFO is full.  It's
  the same problem on Raw, incidentally.

  - maybe it's preferable to implement an EOS token instead of having
    canPop, since on FIFO's there's not necessarily a way to test.
 
  - But canPush could still be a little problematic, as there's no
    backwards push in the dataflow graph; maybe the control thread
    should detect a finished kernel downstream, and then explicitly
    terminate everyone upstream.

 - So we're going to go off and think about canPush/canPop to see if
   there's a better solutoin than above, but we think we should
   eliminate them.

- can reset a given FIFO queue, if you wanted to.

- can turn off individual functional units, e.g. for kernel.suspend

- discussing unordered streams... decided to keep for data-parallel
  conditionals and instruction scheduling by low-level compiler; can
  always implement as ordered stream.

- Calvin from UT will be in charge of streaming on TRIPS?  Will
  contact him next.

*******************************************************************

- think about how to simplify routes

ignore with monarchs:
---------------------
- how to represent raw

with monarch:
-------------
- discuss with monarch:  infinite capacity on connections
- whether or not contents of streams at a connection are persistent
- can dataflow have loops?  definition of dataflow.

talking with peter
------------------

- PC+MC+P

- connections just have bandwidth and latency now.  connections can
have direction.

- have multi-tier connections for busses (e.g. connections mapped to
other connections)

- connections are stupid.  there is another memory fifo.  can have
  0-capacity FIFO's.

- estimated # cycles for prework/work/postwork, where prework and 
  postwork represents startup and shutdown.  don't need to give times
  for ones that it can't execute.

- processor spec:  SIMD or dataflow.  Dataflow is SIMD without control flow.

- come back to the multicast point.

- eliminate register-based streams (BILL THINK ABOUT THIS)

- axe all functions from stream: length, totalLength, getCapacity, reset
  - but think about length

  - best-effort suspend.  Next time (ASAP) that work() returns, if it
    returns RUNNING then change status to SUSPENDED instead.  Also
    applies to prework.

bill's recommended changes
--------------------------

CONCEPTUAL

- Things to add from Forum discussion:

  - best-effort suspend.  Next time work() returns, if it returns
    RUNNING then change status to SUSPENDED instead.  Also applies to
    prework.

  - support for multicast.

    - decide if this is with pre-defined kernel or with plain sharing?
      I think that plain sharing would be hard for the C++ runtime system
      to support, so go with pre-defined kernel.

     * Should it be allocated to resource, though?

- Let's get rid of Send/Receive kernels.
  - benefits:
    - don't need them anyway since there's only one kernel on each processor
    - no more double assignment of these kernels to raw tiles
    - no more weird redundancy between send/receive and graphs links, esp.
      with respect to termination semantics
    - Raw can represent as a single graph that gets broken down into
      synchronous pieces

  - to deal with I/O, have black-box library kernels.

- Metadata / VM Description

  - indicate number of each kind of functional unit in a processor
    - maybe with DATAFLOW type of machine??

  - DMA controllers are another type of processor.  They are
    associated with some set of memory-processor connections (there are
    not explicit connection into and out of the DMA engine).  Their
    capabilities only apply to this set; one transfer out of the entire
    set is active at a time.

  - Give in metadata a list of all kernels (pre-defined and block box)
    that each processor can execute.  This is important for I/O kernels
    that can only execute on some resources, and for DMA that can only do
    certain types of memory operations.  (Alternatively, give estimated
    cost / execution time for each of these kernels?)

- The argument of BaseStorage is now a Location, which can be either:

  - RegisterLocation:  registers of processor (processor node, capacity, initLength)
  - MemoryLocation:    memory (processor node, address, capacity, initLength, aliased, wraps)
  - ConnectLocation:   connection (connection, persistent)

  - capacity could be infinite

  - could define other types of locations if ever needed

- Regarding stream functions:

  - Let's delete stream.reset, since people will have to worry about
    supporting it.  You can just construct a separate graph.  I don't
    think reset() is important for the sake of performance.

  - I think we can tell Mike Vahey that stream.length and
   stream.totalLength can be implemented in other ways by the LLC when
   they are needed by the HLC and not supported by the implementation
   of stream.  (Just keep a counter somewhere... you can work
   backwards from HLC calls to these functions to see where you should
   put the counters.)

CHANGES TO DOCUMENT

- Should add prework to black-box kernels.

- (Keckler) should have header for document, that this is just
  syntactical expression

- (Keckler) should add explicit list of everything the LLC should do

---

x maybe I don't understand how the DMA controller would usually work.
What does it buffer into?

x could declare streams in global namespace.  Then they could be
attached to connections for Raw.  Could say that we guarantee only one
stream per resource at a time?  Or I guess, if you try to run multiple
at the same time, there are no guarantees on the behavior.

x graph.wait is problematic for polling across multiple processors?

x what do we do about pre-defined matrix multiply kernel across multiple processors?

x I don't think we need addDependence if all kernels are pipelined
when they're connected to a given stream object.  Well, maybe if one
kernel on a different processor was picking up half of a streaming
computation or something?

x can you pipeline the end of one graph with the beginning of the next one?

x maybe it's just that each kernel has a source/sink with network
capabilities in between?  shouldn't necessarily have to store streams
in between dma and kernel processor, etc.

-----------------------------------------------------------------------------

ideas:

x eliminate graphs, eliminate send/receive, put istream/ostream in
  control code

x have send/receive bound to a given abstract identifier, use for
  pipelining between separate graphs.

  x what do you do about waiting for any kernel in a graph to suspend?
    (or does this even make sense if they're on different processors?)

    -> maybe wait() should just take a list of kernels and waits until
       one of them suspends or finishes, returning which one of them did?

  x how do you communicate between separate threads of control, e.g. on Raw?

comments from Feb. PI meeting:
------------------------------

Big issues:

- need dma controllers in metadata
- need non-memory allocations of streams

Mike Vahey's coments:

- written from a storage perspective.  Should have other ways to store
streams.

- could think about other ways to transfer streams and blocks between
stream processors and thread processors

only bill's worries:

- on Raw, might want custom matrix multiply kernel running across
several tiles


************************************************************

regarding peter's new proposal:
- what about still having iter argument to run()?

-----
going off chip from raw:
- three connections multiplexed:
  - memory dynamic network
  - general dynamic network
  - static network 1

completely bi-directional

14 ports on the chip in all

************************************************************
MY PLAN

- write the new Streaming Virtual Machine section
- write the new Metadata section
  - include description of Raw
  - will involve defining an actual API for accessing stuff.

- send to Peter with dummy placeholders for other chapters, ask if I
  should take care of integrating or if this should be left to UT

************************************************************
THINGS TO CHANGE

old issue summary: 4468
peter's update after talking to stanford: 4785
most recent summary:  5013

metadata
--------

* do we need notion of explicit DMA controllers?
* how do you represent a bus?

- need to write Raw in current metadata
- allow multiple I/D per processor

- add list of black-box function names, along with their SVM-style code code

streaming
---------

x new stream buffer:
  x follow peter's pseudocode
  x 9 kinds (figure out some kind of inheritance)
    x 3: input, output, both
    x 3: inorder, outorder, random
    x inorder inherits from out-of-order because of read/write

  x properties:
    x capacity
    x reset -- makes everything back to zero
    x length
      x how many "live items" in it
      x if random, then just returns capacity
      x this is updated after each return from start()
    x totalLength
      x how many items pushed onto it
      ? if random, then just returns capacity
    x has copy constructor for copying elements
    x guaranteed of data layout if totalLength < capacity
    x EOS tokens are below the level of the SVM. Control code should
      abstractly know the length of a stream or (if it is being
      produced/received) the number of elements available and if more are
      expected. There are multiple ways to implement this abstraction for
      different kinds of hardware.
    x note that only allows fixed-size records.  Variable sized
      records can be supported at language-level and compiled into
      fixed size scheme with some kind of data encoding

x kernels
  x take an argument for the resource where they should execute
  x take an argument for random-access stream buffer that the LLC
    can use to store temporaries that overflow local kernel mem.
  x should include work_info, prework_info
  x new restriction: work function must return
  x for copy kernel, include src_stride and dst_stride

x graphs
  x add dependence info to constructors.  must be literals.
    x to avoid memory-based location analysis in low-level compiler
  x add non-blocking start method
    x does this call pre_work?
    x can you call it on a given graph object even after you've terminated?
      for running some graphs twice, etc.  Maybe call reset in between.
  x add non-blocking terminate method
    x does this call post_work?
  x calls to start first calls wait on inputs first -- but calls
    to start are asynchronous
  x consistency is not guarnateed for parallel writes.  same with
    reuse of internal buffers -- nothing is guaranteed
  x use "finish" instead of "termination" throughout document
  x doesn't run on a given resource anymore; resource assignment
    is done at kernel level
  x new restriction: must be connection in architecture graph for every
    link in graph
  x Send/receive protocol needs to be adjusted for output full on
    receive side.

x stream control:
  x allow support for compiler-managed imem - e.g. call kernelLoad(kernel)
    to give hint that kernel should be loaded
  x still can't inspect kernels while they're running, but can poll using
    the start method
  x embedded in normal GP/threaded code with streaming restrictions
    only on streaming objects
  x the control code does file I/O and such outside of a kernel space
  x Add a 64 bit signed/unsigned integer type (also to within kernels)

x library support

   x for library support: add to metadata a list of kernels that the llc
     implements, supply their SVM representation -- also specify the
     annotation functions for everything, but leave out declaration of
     work; the HLC guaranteest hat it won't muck with them (fuse them
     or anything) and then LLC can implement how it wants

   x OPEN ISSUE:  this will require having separate graph for each
     library function.  will make it impossible to run graph in 
     pieces and poll the pieces, since calling start calls terminate?

just the document
-----------------

x be consistent between _ and capitalization for delimiting
multiple-word identifiers

x KernelInfo class should remove static argument to setPush/pop/peek.

x Say a given INSTANCE of a kernel can appear in only one graph.

******************************************************************************
NOT DOING

- come back to enumerating some kind of set of configurations, maybe
  by an array that has rows and columns for different kinds of
  config's

- is it worthwhile to represent static rates, etc. for sub-segments of
  a stream graph?  (some functions that are called inside a kernel?)

- Mike Vahey says "Pg 12, Not clear about 'only copy across one
  connection'"

************************************************************
RAW NOTES WITH PETER

in the afternoon
----------------

length still returns how many items have been written to stream
  - if it's random, then just returns size
  -> length return how many items have been (pushed)

StreamBuffers -> 
  - capacity
  - length
  - totalLength
  - reset - sets pointers to beginning, 

- you can copy them, read 
- guaranteed of data layout if totalLength<capacity

- some inheritance order between 9 classes

next day
--------

- dependence information between graphs has to be literals as well

his current email:
------------------

- have outOfOrder Istream, outOfOrder ostream.  inorder inherits from
out-of-order because of read/write methods

- read/write and push/pop with optional argument to write into an output stream 

- terminate is non-blocking

- if you call start, then it does the equivalent of calling wait() on
inputs first -- but call to start() is still asynchronous

- the dependence annotations between graphs is because you don't want
to do memory-based location analysis in the low-level compiler

- for library support: add to metadata a list of kernels that the llc
implements, supply their SVM representation -- also specify the
annotation functions for everything, but leave out declaration of
work; the HLC guaranteest hat it won't muck with them (fuse them or
anything) and then LLC can implement how it wants

- be sure to say that consistency is not guarnateed for parallel writes

* still an open issue:  number of dma controllers in the metadata, etc
  * need to describe in RAW

as per old mail
---------------

- allow multiple I/D per processor

- as per sharing memory space for internal buffers, should just be
dealt with by the fusion of the high-level compiler (#3)

- have "memory block" that is above stream, takes resource, pointer,
size.  pass this as argument to constructor but nothing else -- just
for storing locals if the lower-level stream needs to.

------
finishing conversatoin at 6 p.m.

- should use the word "finish" instead of "termination" throughout the
document so that we don't confuse the fault-tolerance case

- "components of kernel" should include work_info, prework_info.

----

- threaded processor can just map contents to physical locations of
streams

- need to assign a required resource that executes a given kernel.
Graph doesn't run on a single resource; a kernel runs on a resource.
e.g. DMA controller.

