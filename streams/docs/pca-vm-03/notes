Call with Peter on 4/23/03
--------------------------

issues:

  - Graphs
  - canPop / canPush
  - routing issues (stream-stream connections)

---

- implement canPop but not canPush
  - keep the index into canPop
  - have end-of-stream token

- no graphs

- so have popEos, pushEos, peekEos (possibly do a postpass on syntax)
  - preserves kahn semantics - can't tell buffer size by pushing
  - canPop returns bool

- suspend is a method call from the work function

  - can still specify dependences on inputs to kernels, for before
    they start running

- agree:  input the connectivity to the HLC
  - not sure whether or not HLC outputs the routing information
  - (connection+)-fifo-(connection+) processor

- will pass the token to Peter for the next 

- multicast:  
  - push, pop are methods of kernel
  - also have varargs push

- undefined streams:  peekEos 

- keep aliasing guarantees we had before

-----

- issues:

  - who's taking control of this document

  - Graphs, etc.

  - what about canPop, canPush / draining & killing semantics


conference call with mike vahey, peter, francois
------------------------------------------------

- I/O devices just have input/output assembly instruction.  data
  coming in will stream in forever.  if attached to file there is an
  end-of-file signal.

- different classes of memory in the processor.  use a PPC somewhere,
  have DMA engines between memory and processor

- have internal memories between the elements of the processing core.
  these can stream in data from addresses, store to addresses.

- ratio is ~1 memory unit for every pair of adder/multiplier combo's.

- so we can represent core as N adders, N multipliers

- can peek on the interconnect, up to about 4 items. the interconnect
  between memories and functional units is also buffered.

- want to assign a single op to a given functional unit

- you can have cycles in the dataflow graph

- the basic functional unit is both an adder and a multiplier

- internal memories used for FIFO's on occaision, or FFT stuff, or
  bit reversal on occaision; can have random access

- minimum size of small memories is ~512 words

- regarding threaded kernels... alternate mode of execution is in
  threaded form, kind of doing SIMD stuff; have an actual register
  file.  256-bit wide datapath, could operate in parallel.

- in actual baseline chip, there are twice as many adders in dataflow
  mode.  Also in dataflow, you can do both add and multiply, but in
  threaded, you can do either add or multiply.  (So factor of two
  automatically.)

- can run up to 8 threaded kernels on a chip, all of them accessing
  the FPCA in threaded mode.

- can run part of the chip in dataflow, part of the chip in threaded
  kernel mode.  e.g. 3/8'ths one and 5/8'ths the other.

- can have tokens passed around like standard dataflow architecture,
  e.g. for limited support for control flow, etc.

- you can access leftover items in graph; there's a command to purge
  them if you like.  can suspend the graph and then restart that
  graph running, even if DMA was blocking or something.

- usually think of a single stream being assigned to a resource; you
  can multiplex multiple streams on a resource but they're still
  in-order between them.

- discussing canPush/canPop -- currently there is no ability to test
  the availability of a given data item, or if a FIFO is full.  It's
  the same problem on Raw, incidentally.

  - maybe it's preferable to implement an EOS token instead of having
    canPop, since on FIFO's there's not necessarily a way to test.
 
  - But canPush could still be a little problematic, as there's no
    backwards push in the dataflow graph; maybe the control thread
    should detect a finished kernel downstream, and then explicitly
    terminate everyone upstream.

 - So we're going to go off and think about canPush/canPop to see if
   there's a better solutoin than above, but we think we should
   eliminate them.

- can reset a given FIFO queue, if you wanted to.

- can turn off individual functional units, e.g. for kernel.suspend

- discussing unordered streams... decided to keep for data-parallel
  conditionals and instruction scheduling by low-level compiler; can
  always implement as ordered stream.

- Calvin from UT will be in charge of streaming on TRIPS?  Will
  contact him next.

*******************************************************************

- think about how to simplify routes

ignore with monarchs:
---------------------
- how to represent raw

with monarch:
-------------
- discuss with monarch:  infinite capacity on connections
- whether or not contents of streams at a connection are persistent
- can dataflow have loops?  definition of dataflow.

talking with peter
------------------

- PC+MC+P

- connections just have bandwidth and latency now.  connections can
have direction.

- have multi-tier connections for busses (e.g. connections mapped to
other connections)

- connections are stupid.  there is another memory fifo.  can have
  0-capacity FIFO's.

- estimated # cycles for prework/work/postwork, where prework and 
  postwork represents startup and shutdown.  don't need to give times
  for ones that it can't execute.

- processor spec:  SIMD or dataflow.  Dataflow is SIMD without control flow.

- come back to the multicast point.

- eliminate register-based streams (BILL THINK ABOUT THIS)

- axe all functions from stream: length, totalLength, getCapacity, reset
  - but think about length

  - best-effort suspend.  Next time (ASAP) that work() returns, if it
    returns RUNNING then change status to SUSPENDED instead.  Also
    applies to prework.

bill's recommended changes
--------------------------

CONCEPTUAL

- Things to add from Forum discussion:

  - best-effort suspend.  Next time work() returns, if it returns
    RUNNING then change status to SUSPENDED instead.  Also applies to
    prework.

  - support for multicast.

    - decide if this is with pre-defined kernel or with plain sharing?
      I think that plain sharing would be hard for the C++ runtime system
      to support, so go with pre-defined kernel.

     * Should it be allocated to resource, though?

- Let's get rid of Send/Receive kernels.
  - benefits:
    - don't need them anyway since there's only one kernel on each processor
    - no more double assignment of these kernels to raw tiles
    - no more weird redundancy between send/receive and graphs links, esp.
      with respect to termination semantics
    - Raw can represent as a single graph that gets broken down into
      synchronous pieces

  - to deal with I/O, have black-box library kernels.

- Metadata / VM Description

  - indicate number of each kind of functional unit in a processor
    - maybe with DATAFLOW type of machine??

  - DMA controllers are another type of processor.  They are
    associated with some set of memory-processor connections (there are
    not explicit connection into and out of the DMA engine).  Their
    capabilities only apply to this set; one transfer out of the entire
    set is active at a time.

  - Give in metadata a list of all kernels (pre-defined and block box)
    that each processor can execute.  This is important for I/O kernels
    that can only execute on some resources, and for DMA that can only do
    certain types of memory operations.  (Alternatively, give estimated
    cost / execution time for each of these kernels?)

- The argument of BaseStorage is now a Location, which can be either:

  - RegisterLocation:  registers of processor (processor node, capacity, initLength)
  - MemoryLocation:    memory (processor node, address, capacity, initLength, aliased, wraps)
  - ConnectLocation:   connection (connection, persistent)

  - capacity could be infinite

  - could define other types of locations if ever needed

- Regarding stream functions:

  - Let's delete stream.reset, since people will have to worry about
    supporting it.  You can just construct a separate graph.  I don't
    think reset() is important for the sake of performance.

  - I think we can tell Mike Vahey that stream.length and
   stream.totalLength can be implemented in other ways by the LLC when
   they are needed by the HLC and not supported by the implementation
   of stream.  (Just keep a counter somewhere... you can work
   backwards from HLC calls to these functions to see where you should
   put the counters.)

CHANGES TO DOCUMENT

- Should add prework to black-box kernels.

- (Keckler) should have header for document, that this is just
  syntactical expression

- (Keckler) should add explicit list of everything the LLC should do

---

x maybe I don't understand how the DMA controller would usually work.
What does it buffer into?

x could declare streams in global namespace.  Then they could be
attached to connections for Raw.  Could say that we guarantee only one
stream per resource at a time?  Or I guess, if you try to run multiple
at the same time, there are no guarantees on the behavior.

x graph.wait is problematic for polling across multiple processors?

x what do we do about pre-defined matrix multiply kernel across multiple processors?

x I don't think we need addDependence if all kernels are pipelined
when they're connected to a given stream object.  Well, maybe if one
kernel on a different processor was picking up half of a streaming
computation or something?

x can you pipeline the end of one graph with the beginning of the next one?

x maybe it's just that each kernel has a source/sink with network
capabilities in between?  shouldn't necessarily have to store streams
in between dma and kernel processor, etc.

-----------------------------------------------------------------------------

ideas:

x eliminate graphs, eliminate send/receive, put istream/ostream in
  control code

x have send/receive bound to a given abstract identifier, use for
  pipelining between separate graphs.

  x what do you do about waiting for any kernel in a graph to suspend?
    (or does this even make sense if they're on different processors?)

    -> maybe wait() should just take a list of kernels and waits until
       one of them suspends or finishes, returning which one of them did?

  x how do you communicate between separate threads of control, e.g. on Raw?

comments from Feb. PI meeting:
------------------------------

Big issues:

- need dma controllers in metadata
- need non-memory allocations of streams

Mike Vahey's coments:

- written from a storage perspective.  Should have other ways to store
streams.

- could think about other ways to transfer streams and blocks between
stream processors and thread processors

only bill's worries:

- on Raw, might want custom matrix multiply kernel running across
several tiles


************************************************************

regarding peter's new proposal:
- what about still having iter argument to run()?

-----
going off chip from raw:
- three connections multiplexed:
  - memory dynamic network
  - general dynamic network
  - static network 1

completely bi-directional

14 ports on the chip in all

************************************************************
MY PLAN

- write the new Streaming Virtual Machine section
- write the new Metadata section
  - include description of Raw
  - will involve defining an actual API for accessing stuff.

- send to Peter with dummy placeholders for other chapters, ask if I
  should take care of integrating or if this should be left to UT

************************************************************
THINGS TO CHANGE

old issue summary: 4468
peter's update after talking to stanford: 4785
most recent summary:  5013

metadata
--------

* do we need notion of explicit DMA controllers?
* how do you represent a bus?

- need to write Raw in current metadata
- allow multiple I/D per processor

- add list of black-box function names, along with their SVM-style code code

streaming
---------

x new stream buffer:
  x follow peter's pseudocode
  x 9 kinds (figure out some kind of inheritance)
    x 3: input, output, both
    x 3: inorder, outorder, random
    x inorder inherits from out-of-order because of read/write

  x properties:
    x capacity
    x reset -- makes everything back to zero
    x length
      x how many "live items" in it
      x if random, then just returns capacity
      x this is updated after each return from start()
    x totalLength
      x how many items pushed onto it
      ? if random, then just returns capacity
    x has copy constructor for copying elements
    x guaranteed of data layout if totalLength < capacity
    x EOS tokens are below the level of the SVM. Control code should
      abstractly know the length of a stream or (if it is being
      produced/received) the number of elements available and if more are
      expected. There are multiple ways to implement this abstraction for
      different kinds of hardware.
    x note that only allows fixed-size records.  Variable sized
      records can be supported at language-level and compiled into
      fixed size scheme with some kind of data encoding

x kernels
  x take an argument for the resource where they should execute
  x take an argument for random-access stream buffer that the LLC
    can use to store temporaries that overflow local kernel mem.
  x should include work_info, prework_info
  x new restriction: work function must return
  x for copy kernel, include src_stride and dst_stride

x graphs
  x add dependence info to constructors.  must be literals.
    x to avoid memory-based location analysis in low-level compiler
  x add non-blocking start method
    x does this call pre_work?
    x can you call it on a given graph object even after you've terminated?
      for running some graphs twice, etc.  Maybe call reset in between.
  x add non-blocking terminate method
    x does this call post_work?
  x calls to start first calls wait on inputs first -- but calls
    to start are asynchronous
  x consistency is not guarnateed for parallel writes.  same with
    reuse of internal buffers -- nothing is guaranteed
  x use "finish" instead of "termination" throughout document
  x doesn't run on a given resource anymore; resource assignment
    is done at kernel level
  x new restriction: must be connection in architecture graph for every
    link in graph
  x Send/receive protocol needs to be adjusted for output full on
    receive side.

x stream control:
  x allow support for compiler-managed imem - e.g. call kernelLoad(kernel)
    to give hint that kernel should be loaded
  x still can't inspect kernels while they're running, but can poll using
    the start method
  x embedded in normal GP/threaded code with streaming restrictions
    only on streaming objects
  x the control code does file I/O and such outside of a kernel space
  x Add a 64 bit signed/unsigned integer type (also to within kernels)

x library support

   x for library support: add to metadata a list of kernels that the llc
     implements, supply their SVM representation -- also specify the
     annotation functions for everything, but leave out declaration of
     work; the HLC guaranteest hat it won't muck with them (fuse them
     or anything) and then LLC can implement how it wants

   x OPEN ISSUE:  this will require having separate graph for each
     library function.  will make it impossible to run graph in 
     pieces and poll the pieces, since calling start calls terminate?

just the document
-----------------

x be consistent between _ and capitalization for delimiting
multiple-word identifiers

x KernelInfo class should remove static argument to setPush/pop/peek.

x Say a given INSTANCE of a kernel can appear in only one graph.

******************************************************************************
NOT DOING

- come back to enumerating some kind of set of configurations, maybe
  by an array that has rows and columns for different kinds of
  config's

- is it worthwhile to represent static rates, etc. for sub-segments of
  a stream graph?  (some functions that are called inside a kernel?)

- Mike Vahey says "Pg 12, Not clear about 'only copy across one
  connection'"

************************************************************
RAW NOTES WITH PETER

in the afternoon
----------------

length still returns how many items have been written to stream
  - if it's random, then just returns size
  -> length return how many items have been (pushed)

StreamBuffers -> 
  - capacity
  - length
  - totalLength
  - reset - sets pointers to beginning, 

- you can copy them, read 
- guaranteed of data layout if totalLength<capacity

- some inheritance order between 9 classes

next day
--------

- dependence information between graphs has to be literals as well

his current email:
------------------

- have outOfOrder Istream, outOfOrder ostream.  inorder inherits from
out-of-order because of read/write methods

- read/write and push/pop with optional argument to write into an output stream 

- terminate is non-blocking

- if you call start, then it does the equivalent of calling wait() on
inputs first -- but call to start() is still asynchronous

- the dependence annotations between graphs is because you don't want
to do memory-based location analysis in the low-level compiler

- for library support: add to metadata a list of kernels that the llc
implements, supply their SVM representation -- also specify the
annotation functions for everything, but leave out declaration of
work; the HLC guaranteest hat it won't muck with them (fuse them or
anything) and then LLC can implement how it wants

- be sure to say that consistency is not guarnateed for parallel writes

* still an open issue:  number of dma controllers in the metadata, etc
  * need to describe in RAW

as per old mail
---------------

- allow multiple I/D per processor

- as per sharing memory space for internal buffers, should just be
dealt with by the fusion of the high-level compiler (#3)

- have "memory block" that is above stream, takes resource, pointer,
size.  pass this as argument to constructor but nothing else -- just
for storing locals if the lower-level stream needs to.

------
finishing conversatoin at 6 p.m.

- should use the word "finish" instead of "termination" throughout the
document so that we don't confuse the fault-tolerance case

- "components of kernel" should include work_info, prework_info.

----

- threaded processor can just map contents to physical locations of
streams

- need to assign a required resource that executes a given kernel.
Graph doesn't run on a single resource; a kernel runs on a resource.
e.g. DMA controller.

