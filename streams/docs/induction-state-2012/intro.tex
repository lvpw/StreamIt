\section{Introduction}

With a growing need to scale programs more effectively with multicore 
architectures, programs need to be written such that they efficiently exploit 
parallelism across many cores.  Stream programs offer an attractive approach to 
exposing such parallelism.  Furthermore, this domain is well-suited over many 
applications including audio, video, and digital signal processing.  

The stream programming paradigm exposes much parallelism by virtue of the 
structure of the programs written.  Stream programs are constructed as a set of 
independently processing actors that communicate via data channels.  These 
actors are fired repeatedly on a periodic schedule.  Dependencies between 
actors are derived largely through communication channels.  Accordingly, 
compilers can very easily introduce parallel execution by leveraging this 
dependence information and the independent nature of the actors.

The parallelism exposed in stream programs can be classified in a variety of different ways.  The stream graph, representing how the actors of the corresponding stream program communicate with one another, can be partitioned in many ways and assigned to cores accordingly.  It is important to partition the graph in such a way that you leverage the right combination of task, data, and pipeline parallelism.  

Task parallelism refers to a pair of actors that operate on different parallel branches such that outputs to one will never reach the input of the other.  This form of parallelism is simple to exploit, as each actor can be assigned to independent cores.

Pipeline parallelism refers to chains of actors that are directly connected in the stream graph.  Accordingly, the producer and consumer of data in each chain can be assigned to independent cores.  Communication between actors can be maintained using an on-chip network.

Data parallelism refers to stateless actors.  Such actors have no dependencies between execution steps.  Because the execution of these actors are independent, it is possible to assign different execution steps to independent cores.  In exposing this form of parallelism, the stateless actor would be replicated and assigned to various cores so that multiple parts of the input stream can be manipulated in parallel.

Data parallelism can be inhibited when presented with actors that must maintain mutable state between execution steps.  Such actors cannot be replicated and executed independently and in parallel because each of these execution steps are dependent on previous execution steps.  While this may not inhibit task or pipeline parallelism, this does obscure potential data parallelism opportunities.

A common category of state that actors maintain is that of induction state.  Several actors are written so that execution is dependent on the number of times the actor is executed.  Common usage of induction state includes ..... [thies pact10]

In this paper, we propose eliminating induction variable from actor state by providing a new language construct.  This construct provides the current iteration value of the corresponding actor, indicating how many times this actor has been invoked.  This construct introduces internal state to the actor that acts as an iteration counter.  The compiler is able to leverage built-in capabilities to expose data parallelism in actors on filters that maintain this internal state.\cite{mgordon-phd}   


