\startchapter{The StreamIt Language}
\label{chap:language}

This chapter provides an overview and experience report on the basics
of the StreamIt language.  An advanced feature, teleport messaging, is
reserved for Chapter~\ref{chap:messaging}.  For more details on
the StreamIt language, please consult the StreamIt language
specification~\cite{streamit-lang-spec} or the StreamIt
cookbook~\cite{streamit-cookbook}.  A case study on MPEG-2 also
provides excellent examples of the language's
capabilities~\cite{drake-ipdps06}.

\section{Model of Computation}

The model of computation in StreamIt is rooted in (but not equivalent
to) synchronous dataflow~\cite{lee_static_1987}.  As described in
Chapter 1, synchronous dataflow represents a program as a graph of
independent nodes, or {\it actors}, that communicate over FIFO data
channels.  Each actor has an atomic execution step that is called
repeatedly by the runtime system.  The key aspect of synchronous
dataflow, as opposed to other models of computation, is that the
number of items produced and consumed by an actor on each execution is
fixed and known at compile-time.  This allows the compiler to perform
static scheduling and optimization of the stream graph.

StreamIt differs from synchronous dataflow in five respects:
\mybegin

\myitem {Multiple execution steps.}  Certain pre-defined actors have
  more than one execution step; the steps are called repeatedly, in a
  cyclic fashion, by the runtime system.  This execution model mirrors
  cyclo-static
  dataflow~\cite{bilsen_cyclo-static_1995,parks_comparison_1995}.  The
  actors that follow this model are {\it splitters} and {\it joiners},
  which scatter and gather data across multiple streams.  (While the
  language once supported multiple execution steps for
  user-programmable actors as well, the benefits did not merit the
  corresponding confusion experienced by programmers.)

\myitem {Dynamic rates.}  The input and output rates of actors may
  optionally be declared to be dynamic.  A dynamic rate indicates
  that the actor will produce or consume an unpredictable number of
  data items that is known only at runtime.  Dynamic rates are
  declared as a range (min, max, and a hint at the average), with any
  or all of the elements designated as ``unknown''.  While most of our
  optimizations in StreamIt have focused on groups of static-rate
  actors, we have runtime support for dynamic rates (as demanded by
  applications such as MPEG-2~\cite{drake-ipdps06}).

\myitem {Teleport messaging.}  Our support for irregular,
  out-of-band control messaging falls outside of the traditional
  synchronous dataflow model.  However, it does not impede static
  scheduling.  See Chapter~\ref{chap:messaging} for details.

\myitem {Peeking.}  StreamIt allows actors to ``peek'' at data items 
  on their input tapes, reading a value without dequeuing it from the
  channel.  Peeking is important for expressing sliding window
  computations.  To support peeking, two stages of scheduling are
  required: an initialization schedule that grows buffers until they
  accumulate a threshold number of peeked items, and a steady-state
  schedule that preserves the size of the buffers over time.  While
  peeking can be represented as edge-wise ``delays'' in the original
  nomenclature of synchronous dataflow~\cite{lee_static_1987}, most of
  the scheduling and optimization research on synchronous dataflow
  does not consider the implications of these delays.

\myitem {Communication during initialization.}  StreamIt allows
  actors to input and output a known number of data items during their
  initialization (as part of the {\it prework} function).  This
  communication is also incorporated into the initialization schedule.

\myend

With the basic computational model in hand, the rest of this section
describes how StreamIt specifies the computation within actors as well
as the connectivity of the stream graph.

\section{Filters}
\label{sec:filters}
\enlargethispage{0.3\baselineskip}

The basic programmable unit in StreamIt is called a {\it filter}.  It
represents a user-defined actor with a single input channel and single
output channel.  Each filter has a private and independent address
space; all communication between filters is via the input and output
channels (and teleport messaging).  Filters are also granted read-only
access to global constants.

An example filter appears in Figure~\ref{fig:fir-streamit}.  It
performs an FIR filter, which is parameterized by a length {\it N}.
Each filter has two stages of execution: initialization and steady
state.  During initialization, the parameters to a filter are resolved
to constants and the {\it init} function is called.  In the case of
FIR, the init function initializes an array of weights, which is
maintained as state within the filter.  During steady state execution,
the {\it work} function is called repeatedly.  Inside of work, filters
can {\it push} items to the output channel, {\it pop} items from the
input channel, or {\it peek} at a given position on the input channel.
Filters requiring different behavior on their first execution can
declare a {\it prework} function, which is called once between {\it
init} and {\it work}.

\begin{figure}[t]

\begin{minipage}{0.45\textwidth}
\centering
\ninepoint
\begin{verbatim}
float->float filter FIR(int N) {
  float[N] weights;

  init {
    for (int i=0; i<N; i++) {
      weights[i] = calcWeight(i, N);
    }
  }

  work push 1 pop 1 peek N {
    float sum = 0;
    for (int i=0; i<N; i++) {
      sum += weights[i] * peek(i);
    }
    push(sum);
    pop();
  }
}
\end{verbatim}
\end{minipage}
\begin{minipage}{0.55\textwidth}
\centering
\ninepoint
\begin{verbatim}
void init_FIR(float* weights, int N) {
  int i;

  for (i=0; i<N; i++) {
    weights[i] = calc_weight(i, N);
  }
}

void do_FIR(float* weights, int N,
            int* src, int* dest, 
            int* srcIndex, int* destIndex,
            int srcBufferSize, int destBufferSize) {

  float sum = 0.0;
  for (int i = 0; i < N; i++) {
    sum += weights[i] * 
           src[(*srcIndex + i) % srcBufferSize];
  }
  dest[*destIndex] = sum;
  *srcIndex = (*srcIndex + 1) % srcBufferSize;
  *destIndex = (*destIndex + 1) % destBufferSize;
}
\end{verbatim}

%% This version is more parallelizable!
%%
%% /* initialize weights for N-element FIR filter */
%% void init_filter(float* weights, int N) {
%%   int i;
%%  
%%   for (i=0; i<N; i++) {
%%     weights[i] = calc_weight(i, N);
%%   }
%% }
%%
%% /* given weights and an N-element circular buffer,
%%    do filter starting at given position of buffer */
%% float filter(float* weights, float* buffer, 
%%              int pos, int N) {
%%   int i;
%%   float sum = 0;
%%
%%   /* perform weighted sum, starting at index pos */
%%   for (i=0; i<N; i++, pos++) {
%%     sum += weights[i] * buffer[pos];
%%     pos = (pos + 1) % N;
%%   }
%%   return sum;
%% }

\end{minipage}
\begin{minipage}{0.45\textwidth}
\centering
\caption{FIR filter in StreamIt.\protect\label{fig:fir-streamit}}
\end{minipage}
\begin{minipage}{0.55\textwidth}
\centering
\caption{FIR filter in C.\protect\label{fig:fir-c}}
\end{minipage}
\end{figure}

The work and prework functions declare how many items they will push
and pop, and the maximum number of items they might peek, as part of
their declarations.  To benefit from static scheduling, these
expressions must be resolvable to constants at compile time (dynamic
rates are declared using a different
syntax~\cite{streamit-lang-spec}). While a static analysis can infer
the input and output rates in most cases, in general the problem is
undecidable.  Our experience has been that rate declarations provide
valuable documentation on the behavior of the filter.  In cases where
the rates can be inferred, the declarations can be checked by the
compiler.

The StreamIt version of the FIR filter is easy to parallelize and
optimize.  Because there is no mutable state within the filter (that
is, the {\it weights} array is modified only during initialization),
the compiler can exploit data parallelism and instantiate many copies
of the FIR filter, each operating on different sections of the input
tape.
%To the best of our knowledge, StreamIt is the first language
%that allows tractable parallelization of general-purpose
%sliding-window computations such as FIR filters.  
Also, due to a lack of pointers in the language, values can easily be
traced through arrays from their initialization to their use.  This
allows the compiler to infer that the FIR filter computes a linear
function, subject to aggressive optimization~\cite{lamb-pldi03}.
Also, using a transformation called scalar
replacement~\cite{sermulins-lctes05}, the {\it weights} array can be
eliminated completely by unrolling loops and propagating constants
from the init function to the work function.

A traditional C implementation of an FIR filter (shown in
Figure~\ref{fig:fir-c}) resists parallelization and optimization.  The
sliding-window nature of the FIR computation results in a circular
buffer, where elements are addressed using a modulo operation.  Modulo
operations are very difficult to analyze in a compiler; rather than
recognizing the underlying FIFO queue, conservative compilers will
regard each read and write as falling anywhere in an array.  The
problems are confounded by the presence of pointers.  To parallelize
calls to do\_FIR, compilers would need to prove that the {\it weights}
and {\it src} arrays did not overlap with {\it dest}, {\it srcIndex},
or {\it destIndex}.  Similar analysis would be needed to track the
values of {\it weights} from their initialization to their use (in two
different procedures).  Such precise alias analyses are usually beyond
reach.  Worse still, it might not even be legal to call {\it do\_FIR}
in parallel, depending on the buffer sizes chosen by the programmer.
The underlying cause of all these obstacles is that the programmer has
over-specified the computation, imposing a scheduling and buffer
management policy that is better decided by the compiler.

Despite its simplicity, this example illustrates the potential of
improving both the programmability and analyzability of stream
programs via a domain-specific language design.  In addition to
exposing the right information to the compiler, the StreamIt version
is also shorter and easier to maintain, representing a win/win
situation for both man and machine.

\begin{figure}[t]
\vspace{0.4\baselineskip}
\centering
\begin{minipage}{0.598in}
{\centering
\psfig{figure=pipeline.eps,width=0.598in} \\
}
\end{minipage} 
\hspace{0.45in}
\begin{minipage}{1.69in}
{\centering
\psfig{figure=splitjoin.eps,width=1.69in} \\
}
\end{minipage}
\hspace{0.45in}
\begin{minipage}{1.326in}
{\centering
\psfig{figure=feedback.eps,width=1.326in} \\
}
\end{minipage}
\\ ~ \\ {\mbox{~}\protect\small \mbox{~}(a) A pipeline. ~~~~~~~~~~~~~~~~~~~~(b) A splitjoin. ~~~~~~~~~~~~~~~~~~~~~~~(c) A feedbackloop.~~~~~~~~}
\caption{Hierarchical stream structures in StreamIt.\protect\label{fig:structures}}
\end{figure}

\begin{figure}[t]
\centering
\psfig{figure=fir-pipeline.eps,width=2.8in}
\hspace{0.15in}
\psfig{figure=fir-pipeline2.eps,width=0.598in}
\caption{Example pipeline with FIR filter.\protect\label{fig:pipeline}}
\vspace{0.4\baselineskip}
\end{figure}

\begin{figure}[t]
\centering
\psfig{figure=fm-radio-with-code.eps,width=0.9\textwidth}
\caption[Example of a software radio with equalizer.]{Example of a
  software radio with equalizer.  There is a natural correspondence
  between the structure of the code and the structure of the graph.
  In the code, stream structures can be lexically nested to provide a
  concise description of the application.\protect\label{fig:fm-radio}}
\end{figure}

\begin{figure}[t]
\centering
\psfig{figure=transpose.eps,width=0.8\textwidth}
\caption{Matrix transpose in StreamIt.\protect\label{fig:transpose}}
\end{figure}

\begin{figure}[t]
\vspace{0.3\baselineskip}
\centering
\begin{minipage}{2.5in}
\centering
\psfig{figure=bitreverse-pattern.eps,width=1in}
\end{minipage}
\hspace{0.5in}
\begin{minipage}{3in}
\centering
\psfig{figure=bitreverse-c.eps,width=2.02in}
\end{minipage}

\begin{minipage}{2.5in}
\caption{Data movement in a 3-digit bit-reversed ordering.\protect\label{fig:bitreverse-pattern}}
\end{minipage}
\hspace{0.5in}
\begin{minipage}{3in}
\centering
\caption{Bit-reversed ordering in an imperative language.\protect\label{fig:bitreverse-c}}
\end{minipage}

\end{figure}

\begin{figure}[t]
\centering
\psfig{figure=bitreverse-streamit.eps,width=4.5in}
\caption{Bit-reversed ordering in StreamIt.\protect\label{fig:bitreverse-streamit}}
\end{figure}

\section{Stream Graphs}
\enlargethispage{\baselineskip}

One of the new and experimental ideas in StreamIt is to enforce a {\it
  structured} programming model when building stream graphs.  Rather
than allowing programmers to connect filters into arbitrary graphs,
the language provides three hierarchical primitives for building
larger graphs out of smaller ones.  As illustrated in
Figure~\ref{fig:structures}, these structures are a pipeline, a
splitjoin, and a feedbackloop.  Like a filter, each stream structure
has a single input channel and single output channel, allowing them to
be composed and interchanged freely.  We collectively refer to filters
and stream structures as {\it streams}.

The pipeline structure represents a serial composition of streams,
with the output of one stream flowing to the input of the next.
Figure~\ref{fig:pipeline} illustrates the syntax for pipelines; the
{\it add} keyword indicates that a new stream should be instantiated
and appended to the current pipeline.  A splitjoin represents a set of
parallel and independent streams; a {\it splitter} distributes data
from the input channel to the parallel components, while a {\it
joiner} interleaves the streams' results onto the output channel.  In
this case, each call to {\it add} specifies a separate parallel stream
(see Figure~\ref{fig:fm-radio}).  The language provides a fixed set of
pre-defined splitters and joiners, encompassing duplication and
round-robin behavior (detailed in the next section).  Finally, the
feedbackloop structure provides a way to induce cycles in the stream
graph.

%% The primary motivation for introducing structure in the language is to
%% ensure a disciplined and readable programming style.  There is an
%% analogy here to structured control flow in an imperative language.

The motivations for introducing structured dataflow in a stream
language are analogous to those for introducing structured control
flow in an imperative language.  While there was once a
debate~\cite{dijkstra_go_1968} between unstructured control flow
(using GOTO statements) and structured control flow (using
if/then/else and for loops), in the end structured control flow came
to dominate because it allows the programmer to reason locally.
Rather than being lost in a sea of ``spaghetti code'', programmers can
recognize common patterns because the language enforces a canonical
and hierarchical expression of the control.  While skeptics once
argued that certain patterns would be more naturally expressed using
GOTO statements, over time there emerged structured idioms that were
equally recognizable.  For example, while a state machine can be
written using a GOTO statement for each state transition, it can also
be written as a dispatch loop.  Structured control flow also benefited
compilers, because non-sensical control flow graphs could be ruled out
in favor of the common case.  The field of loop optimizations would
have been much more difficult to develop if researchers had to cope
with the full complexity of an unstructured programming model.

We believe that imposing structure on a stream graph can offer similar
benefits.  From the programmer's perspective, structured streams offer
a disciplined and readable way to describe, parameterize, and compose
stream graphs.  For example, Figure~\ref{fig:fm-radio} shows the
StreamIt code corresponding to a software radio program.  There are
three things to notice about the figure.  First, there is a natural
correspondence between the structure of the code and the structure of
the stream graph.  Rather than reasoning about an ad-hoc set of nodes
and edges, the programmer can visualize the graph while reading the
code.  Second, the graph description is parameterized.  The number of
parallel streams in the equalizer is dictated by a parameter {\it N}.
Thus, the programmer can easily describe a broad family of stream
graphs; the compiler evaluates the values of the parameters to
spatially unroll the actual stream structure.  Finally, imposing a
single-input, single-output discipline on stream programs enables
modularity and compositionality.  The LowPassFilter and HighPassFilter
can be drawn from a common library, without knowing the details of
their internal representations.

Enforcing structure in the language can also benefit the compiler.
Rather than dealing with the complexity of full graphs, the compiler
can focus on a few simple cases.  This property helped us to formulate
phased scheduling~\cite{karczma-thesis,karczmarek-lctes03}, linear
optimizations~\cite{lamb-pldi03,lamb-thesis,agrawal-thesis,agrawal-cases05},
and mapping to the compressed domain~\cite{thies07compression}.

We give more details on our experience with structure in Section~\ref{sec:lang-experience}.

\enlargethispage{0.3\baselineskip}
\section{Data Reordering}

Another novelty of the StreamIt language is the provision of flexible,
composable, and parameterized language primitives for scattering,
gathering, and reordering data.  These primitives take the form of
pre-defined splitter and joiner nodes, which appear in both splitjoins
and feedbackloops.

There are two types of splitters.  The first splitter, {\it
  duplicate}, copies each input item to all of the output channels.
The second splitter, {\it roundrobin}, is parameterized with a set of
weights, $w_1 \dots w_n$, where $n$ is the number of output channels.
It sends the first $w_1$ input items to the first stream, the next
$w_2$ items to the second stream, and so on, repeating in a cyclic
fashion.  If all of the outputs have the same weight $w$, the splitter
can be written as {\it roundrobin(w)}; similarly, if all the outputs
have weight 1, the programmer can write simply {\it roundrobin}.
Roundrobin is also the only type of joiner available.

By composing these simple primitives -- roundrobin splitters,
roundrobin joiners, and duplicate splitters -- a large number of data
distribution and reordering patterns can be elegantly expressed.  For
example, Figure~\ref{fig:transpose} illustrates StreamIt code for a
matrix transpose.  The reordering needed can be expressed by a single
splitjoin.  The splitjoin has an empty stream (called an {\it
Identity}) for every column in the matrix; a roundrobin(1) splitter
moves the columns into the splitjoin, while a roundrobin(M) joiner
moves the rows to the output channel.

Another example is bit-reversed ordering.  As illustrated in
Figure~\ref{fig:bitreverse-pattern}, a $k$-digit bit-reversed ordering
is a permutation in which the element at index $n$ (where $n$ has
binary digits $b_0b_1 \dots b_k$) is reordered to appear at index
$b_kb_{k-1} \dots b_0$.  For example, in a 3-digit bit reversal, the
item at index one (001) is reordered to index four (100).  In a
traditional language such as C, the code to perform bit-reversal is
very complex; see Figure~\ref{fig:bitreverse-c} for a standard
algorithm~\cite{press_numerical_1992}.  Given the doubly-nested loops,
conditionals, shift expressions, and swap operations, it is unlikely
that any compiler will arrive at a sensical representation for the
logical reordering performed by this computation.  It is equally
difficult for humans to comprehend the code.

However, the StreamIt version (Figure~\ref{fig:bitreverse-streamit})
of bit reversal is far simpler\footnote{Satish Ramaswamy in our group
discovered this representation of bit-reversal.}.  It represents bit
reversal as a recursive reordering.  In the base case, there are only
two elements and no reordering is needed (a 1-digit bit reversal is
the identity operation).  Otherwise, the reordering consists of
separating elements into two groups based on the lowest-order bit of
the input position, reordering both groups independently, and then
joining the groups based on the highest-order bit of the output
position.  This pattern can be expressed with a roundrobin(1)
splitter, a recursive call to BitReverse(N/2), and a roundrobin(N/2)
joiner.  The intuition is: bit reversal is equivalent to a tree of
fine-grained splitting and coarse-grained joining.  A graphical
depiction of this tree appears in
Figure~\ref{fig:bitreverse-streamit}.

Why bother to represent distribution and reordering operations in an
elegant and analyzable way?  The reason is that stream programming
centers on data movement, and preserving information about exactly
where each data item is going enables the compiler to perform more
aggressive optimizations.  For example, standardized splitters and
joiners have enabled us to map reordering operations to a programmable
on-chip network~\cite{gordon-asplos02} and have enabled certain
domain-specific
optimizations~\cite{lamb-pldi03,agrawal-cases05,thies07compression}.
Other researchers have also leveraged this representation to
automatically generate vector permutation
instructions~\cite{mani-permutations} and to facilitate program
sketching~\cite{bit-streaming}.

While the reordering primitives we have defined are quite expressive,
it should be noted that they are not complete.  Because splitters
always distribute their first input item to the first output channel
(and likewise with joiners), it is impossible to express a general
permutation in which the first item is reordered to a different
position of the stream.  However, this behavior can be emulated by
introducing simple computational nodes, such as a filter that
decimates some of its inputs.  Of course, it could also be rectified
by adding programming language support for adjusting the order of
items output.  To our knowledge, the only benchmark in our suite that
could leverage such a primitive is synthetic aperture radar (SAR), in
which four matrix quadrants are re-shuffled in preparation for an FFT.
We have not found this functionality to be broadly needed.

%% Some programs are elegant, some are exquisite, some are sparkling.
%% My claim is that it is possible to write grand programs, noble
%% programs, truly magnificient ones!
%% -- Don Knuth, Computer Programming as an Art, ACM Turing Award Lecture, 1974

\section{Experience Report}
\label{sec:lang-experience}

\begin{table}[t!]
\vspace{-2\baselineskip}
\psfig{file=benchmarks,width=\textwidth}
\vspace{-1.5\baselineskip}
\caption{Overview of the StreamIt benchmark suite.\protect\label{tab:lang-benchmarks}}
\vspace{-0.5in}
\end{table}

\begin{table}[t!]
\vspace{-2\baselineskip}
\psfig{file=benchmarks-params,width=\textwidth}
\vspace{-1.5\baselineskip}
\caption{Parameterization and scheduling statistics for StreamIt 
benchmarks.\protect\label{tab:lang-benchmarks-params}}
\vspace{-0.5in}
\end{table}

\begin{table}[t!]
\vspace{-2.5\baselineskip}
\psfig{file=benchmarks-filters,width=\textwidth}
\vspace{-1.5\baselineskip}
\caption{Properties of filters and other constructs in StreamIt 
benchmarks.\protect\label{tab:lang-benchmarks-filters}}
\vspace{-0.5in}
\end{table}

Over the past eight years, we have gained considerable experience in
developing applications in StreamIt.  We reflect on this experience
first via a quantitative analysis of our benchmark suite, and then via
qualitative impressions from StreamIt programmers.

An overview of the StreamIt benchmark suite appears in
Table~\ref{tab:lang-benchmarks}.  At the time of this writing, the
suite consists of 67 programs, including 29 realistic applications, 4
graphics rendering pipelines, 19 libraries and kernels, 8 sorting
routines, and 7 toy examples.  Benchmarks range in size from 21 lines
(Fibonacci) to over 4,000 lines (MPEG2 encoder), with a total of
33,800 non-comment, non-blank lines in the suite\footnote{Counting
commented lines (8,000) and blank lines (7,300), the benchmark suite
comes to 49,300 lines.}.  Over 20 people contributed to the suite,
including 6 from outside our group; median-pulse compression doppler
radar was developed at Halmstad University~\cite{ola-techrep}, TDE was
developed at the Information Sciences Insittute, an FFT and bitonic
sort were developed at UC Berkeley~\cite{mani-permutations}, and the
graphics pipelines were implemented primarily by the graphics group at
MIT~\cite{chen-graphics05}.  OFDM was adapted from an internal
performance test of Spectrumware~\cite{tennenhouse_spectrumware_1996},
while Vocoder was implemented with support from
Seneff~\cite{seneff80thesis}.  Other benchmarks were often adapted
from a reference implementation in C, Java, or MATLAB.

Graphical depictions of the stream graphs for each benchmark can be
found in Appendix~\ref{chap:stream-graphs}, while the complete source
code for a small benchmark (ChannelVocoder) can be found in
Appendix~\ref{chap:example-program}.  A subset of the benchmarks have
also been prepared for public release on the StreamIt
website~\cite{streamitweb}.  At the time of this writing, some of the
larger benchmarks (MPEG2, GMTI, Mosaic, FAT, HDTV) are not fully
supported by the compiler.  However, their functional correctness has
been verified in the Java runtime for the StreamIt language.

It is important to recognize that most of the benchmarks are
parameterized, and we study only one assignment of those parameters in
our quantitative evaluation.  Table~\ref{tab:lang-benchmarks-params}
details the parameterization of the StreamIt benchmarks (in addition
to scheduling statistics, which are discussed later).  In two-thirds
(44) of the benchmarks, the parameters affect the structure of the
stream graph, often by influencing the length of pipelines, the width
of splitjoins, the depth of recursion hierarchies, or the absence or
presence of given filters.  The same number of benchmarks contain
parameters that affect the I/O rates of filters (e.g., the length of
an FIR filter), but do not necessarily affect the structure of the
graph.  Changes to the I/O rates also imply changes to the schedule
and possibly the balance of work across filters.  In selecting values
for these parameters, our primary goal was to faithfully represent a
real-life application of the algorithm.  In some cases we also
decreased the sizes of the parameters (e.g., sorting 16 elements at a
time) to improve the comprehensibility of the stream graph.  For
benchmarking purposes, researchers may wish to scale up the parameters
to yield larger graphs, or to vary the ratio between parameters to
obtain graphs of varying shapes and work distributions.

More detailed properties of the filters and streams within each
benchmark are given in Table~\ref{tab:lang-benchmarks-filters}.  In
terms of size, benchmarks declare (on average) 11 filter types and
instantiate them 63 times in the stream graph.  GMTI contains the most
filters, with 95 static types and 1,111 dynamic instances; it also
contains 1,757 instances of the Identity filter, to assist with data
reordering.

We organize further discussion of the benchmark suite according to the
key outcomes of our survey.  We use the term ``stateful'' to refer to
filters that retain mutable state from one execution to the next;
filters containing only read-only state are classified as
``stateless''.  Stateless filters are amenable to data parallelism, as
they can be replicated any number of times to work on different parts
of the input stream.  However, stateful filters must be run in a
serial fashion, as there is a dependence from one iteration to the
next.  While separate stateful filters can be run in a task-parallel
or pipeline-parallel mode, the serial nature of each individual filter
represents an eventual bottleneck to the parallel computation.

\mybegin

\myitem {Peeking is widely used for a variety of sliding 
window computations.  Without peeking, such computations would often
introduce a stateful bottleneck in the program.}  Twenty two
benchmarks -- and more than half of the realistic applications --
contain at least one filter that peeks.  (That is, these filters
declare a peek rate larger than their pop rate, examining some items
that are not dequeued from the input channel until a later execution.
We do not count filters that merely call the peek primitive, as those
items may be popped during the same execution.)  Benchmarks contain up
to 4 filter types that peek; in programs with any peeking, an average
of 10 peeking filters are instantiated.

While peeking is used for many purposes, there are a few common
patterns.  The most common is that of an FIR filter, where a filter
peeks at N items, pops one item from the input, and pushes a weighted
sum to the output.  FIR filters account for slightly less than half
(15 out of 35) of the peeking filter declarations.  They are
responsible for all of the peeking in 7 benchmarks (3GPP, OFDM,
Filterbank, TargetDetect, DtoA, Oversampler, RateConvert) and some of
the peeking in 3 others (Vocoder, ChannelVocoder, FMRadio).

\begin{figure}[t]
\vspace{1.5\baselineskip}

\begin{minipage}{0.5\textwidth}
\centering
\ninepoint
\begin{verbatim}
int->int filter DifferenceEncoder_Stateless {

    prework push 1 peek 1 {
        push(peek(0));
    }

    work pop 1 peek 2 push 1 {
        push(peek(1)-peek(0));
        pop();
    }
}
\end{verbatim}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\centering
\ninepoint
\begin{verbatim}
int->int filter DifferenceEncoder_Stateful {
    int state = 0;

    work pop 1 push 1 {
        push(peek(0)-state);
        state = pop();
    }
}
\end{verbatim}
\end{minipage}

\begin{minipage}{0.45\textwidth}
\centering
\caption{Stateless version of a difference encoder, using peeking
and prework.\protect\label{fig:diff-stateless}}
\end{minipage}
\begin{minipage}{0.05\textwidth}
~
\end{minipage}
\begin{minipage}{0.45\textwidth}
\centering
\caption{Stateful version of a difference encoder, using 
internal state.\protect\label{fig:diff-stateful}}
\end{minipage}
\end{figure}

A second pattern of peeking is when a filter peeks at exactly one item
beyond its pop window.  An example of this filter is a difference
encoder, as used in the JPEG transcoder and Vocoder benchmarks.  On
its first execution, this filter's output is the same as its first
input; on subsequent executions, it is the difference between
neighboring inputs.  As illustrated in
Figure~\ref{fig:diff-stateless}, a difference encoder can be written
as a stateless filter using peeking (and prework, as described later).
Otherwise, the filter is forced to maintain internal state, as
illustrated in Figure~\ref{fig:diff-stateful}.  Across our benchmark
suite, this pattern accounts for more than one quarter (10 out of 35)
of the peeking filter declarations.  It accounts for all of the
peeking in 4 benchmarks (Mosaic, JPEG decode, JPEG transcode, HDTV,
BubbleSort) and some of the peeking in 2 others (Vocoder, FMRadio).
It should be noted that the operation performed on the two items is
sometimes non-linear; for example, Mosaic determines the correlation
between successive frames; FMRadio performs an FM demodulation and
HDTV performs an XOR.

The remaining peeking filters (10 out of 35) perform various
sliding-window functions.  For example, MP3 reorders and adds data
across large (>1000 item) sliding windows;
%GSM performs a coarse-grained (pop 40, peek 80, pop 160) sliding
%duplication in preparation for other steps;
802.11 and SampleTrellis do short (3-7 item) bit-wise operations as
part of an error-correcting code; Vocoder and Audiobeam use peeking to
skip N items (by default 1-14), analogous to an inverse delay;
ChannelVocoder performs a sliding autocorrelation and threshold across
N items (by default 100).

Without peeking, the filters described above would have to be written
in a stateful manner, as the locations peeked would be converted to
internal states of the filter.  This inhibits parallelization, as
there is a dependence between successive filter executions.  To
estimate the resulting performance impact,
Table~\ref{tab:lang-benchmarks-filters} lists the approximate amount
of work in the most computationally-heavy peeking filter in each
benchmark.  For 11 benchmarks, this work represents a significant
fraction of the program load (minimum 3.1\%, median 8\%, maximum
97.6\%) and would represent a new bottleneck in a parallel
computation.  For 8 benchmarks, the state that would be introduced by
peeking is dwarfed by state already present for other reasons.  For
the remaining 3 benchmarks, the peeking filters represent a negligible
(0.1\%) fraction of work.

\myitem {Prework functions are useful for expressing startup 
conditions, and for eliminating associated state.}  The prework
function allows a filter to have different behavior on its first
invocation.  This capability is utilized by 15 benchmarks, in 20
distinct filter declarations (results not shown in table).

The most common use of prework is for implementing a delay; on the
first execution, the filter pushes N placeholder items, while on
subsequent executions it acts like an Identity filter.  A delay is
used in 8 benchmarks (MPD, HDTV, Vocoder, 3GPP, Filterbank, DToA,
Lattice, and SampleTrellis).  Without prework, the delayed items would
need to be buffered internally to the filter, introducing state into
the computation.

Other benchmarks use prework for miscellaneous startup conditions.  As
mentioned previously, the difference encoder in
Figure~\ref{fig:diff-stateless} relies on prework (used in JPEG
transcoder and Vocoder), as does the analogous difference decoder
(used in JPEG decoder).  The MPEG2 encoder and decoder use prework in
filters relating to picture reordering, while GSM and CRC use prework
for functions analogous to delays.  Prework is also used for
initialization in MPD, HDTV, and 802.11.

\newpage
\myitem {Stateful filters are less common than we expected, though 
are nonetheless required for complete expression of many algorithms.
Further state could be eliminated via new language constructs,
compiler analyses, or programmer interventions.}  

After effective use of peeking and prework primitives, one quarter (17
out of 67) of the benchmarks still contain one or more filters with
mutable state.  There are 49 stateful filter types in the StreamIt
benchmark suite, representing approximately 6\% of the total filters.
While other researchers have noted that stream programs are rich in
data parallelism~\cite{imagine03ieee}, we nonetheless expected to see
a greater proportion of filters that retained mutable state between
execution steps.  The heaviest stateful filter in each benchmark
ranges from 0.3\% to 42.4\% (median 4.7\%) of the overall work,
representing an eventual bottleneck to parallelization.

Of the stateful filters, at least 22 (about 45\%) represent
fundamental feedback loops that are an intrinsic part of the
underlying algorithm.  Filters in this category include the
bit-alignment stage of MPEG encoding, which performs data-dependent
updates to the current position; reference frame encoding in MPEG
encoder, which sometimes stores information about a previous frame;
the parser in MPEG decoder, which suspends and restores its current
control flow position in order to maintain a constant output rate; the
motion prediction, motion vector decode, and picture reordering stages
of MPEG decoder, which contain data-dependent updates of various
buffers; the pre-coding and Ungerboeck encoding stages of HDTV, which
are simple feedback loops; the Ungerboeck decoding stage of HDTV (and
analogously in SampleTrellis) which mutates a persistent lookup table;
multiple feedback loops in GSM; an accumulator, adaptive filter, and
feedback loop in Vocoder; incremental phase correction in OFDM; and
persistent screen buffers in the graphics pipelines.

The remaining filters classified as stateful may be amenable to
additional analyses that either eliminate the state, or allow
restricted parallelism even in the presence of state.  The largest
category of such filters are those in which the state variables are
modified only by message handlers (messaging is described in the next
chapter).  Whether such messages represent a genuine feedback loop
depends on whether the filter sending the message is data-dependent on
the outcome of the filter receiving the message.  Even if a feedback
loop does exist, it may be possible to exploit bounded parallelism due
to the intrinsic delay in that loop, or speculative parallelism due to
the infrequent arrival of most teleport messages.  In our benchmarks,
there are 16 filters in which the state is mutated only by message
handlers; they originate from MPEG encoder, MPEG decoder, Mosaic, and
both versions of FHR.  There are also 4 additional filters (drawn from
MPEG encoder, MPEG decoder, and Mosaic) in which message handlers
account for some, but not all, of the state.

A second category of state which could potentially be removed is that
of induction variables.  Several filters keep track of how many times
they have been invoked, in order to perform a special action every N
iterations.  For example, MPEG encoder counts the frame number in
assigning the picture type; MPD and Radar (fine grained version) count
the position within a logical vector while performing FIR filtering;
and SampleTrellis includes a noise source that flips a bit every N
items.  Other filters keep track of a logical two-dimensional
position, incrementing a column counter on every iteration and only
incrementing the row counter when a column is complete.  Filters in
this category include motion estimation from MPEG encoder, and two
filters from MPD.  Other filters in MPD contain more complex induction
variables; an accumulator is reset when a different counter
wraps-around to zero.  Taken together, there are a total of 9 filters
that could become stateless if all induction variables could be
converted to a closed form.

There are two approaches for eliminating induction variables from
filter state.  The first approach is to recognize them automatically
in the compiler.  While this is straightforward for simple counters,
it may prove difficult for nested counters (tracking both row and
column) or co-induction variables (periodically reseting one variable
based on the value of another).  The second approach is to provide a
new language primitive that automatically returns the current
iteration number of a given filter.  This information can easily be
maintained by the runtime system without inhibiting parallelization;
shifting the burden from the programmer to the compiler would improve
both programmability and performance.

The third and final category of state that could potentially be
removed is that which results from writing a logically coarse-grained
filter at a fine level of granularity.  This can result in a filter in
which state variables are reset every N executions, corresponding to
one coarse-grained execution boundaries.  Such filters can be
re-written in a stateless manner by moving state variables to local
variables in the work function, and scaling up the execution of the
work function to represent N fine-grained iterations.  Such coarsening
would eliminate the state in bubble sort, which is reset at boundaries
between data sets, as well as a complex periodic filter (LMaxCalc) in
MPD.  It would also eliminate many of the induction variables
described previously, as they are also periodic.  This approach
provides a practical solution for eliminating state, and was employed
in translating Radar from the original fine-grained version to a
coarse-grained alternative (both of which appear in our benchmark
suite).  The drawbacks of this transformation are the effort required
from the programmer and also the increased size of the resulting
filter.  Coarse-grained filters often incur a larger code footprint, a
longer compile time, and a less natural mapping to fine-grained
architectures such as FPGAs.  While the StreamIt language aims to be
agnostic with respect to the granularity of filters, in some cases the
tradeoff between writing stateless filters and writing fine-grained
filters may need to be iteratively explored to achieve the best
performance.

\myitem {Feedback loops are uncommon in our benchmarks, but represent 
significant bottlenecks when present.}  While our discussion thus far
has focused on stateful filters, seven benchmarks also contain
explicit feedback loops in the graph structure.  Four of these loops
(Fib, FHR feedback, H264 subset, CRC) represent significant
bottlenecks to parallelization, with workloads ranging from 73\% to
99\% of the overall execution.  The loop in GSM is shadowed by a
stateful filter; the loop in DToA represents only 0.7\% of the
runtime; and the loop in Mosaic, while likely a bottleneck, is
difficult to quantify due to dynamic rates.  Unlike some of the
stateful filters, these feedback loops are all intrinsic to the
algorithm and are not subject to automatic removal.  However, feedback
loops can nonetheless afford opportunities for parallelism due to the
delay in the loop -- that is, if items are enqueued along the feedback
path at the start of execution, then they can be processed in
parallel.  Further analysis of these delays is needed to assess the
potential parallelism of feedback loops in our benchmark suite.

% The state observed can be explained as follows.  Vocoder performs an
% adaptive DFT that uses a stateful decay to ensure stability; it also
% needs to retain the previous output across one iteration within a
% phase transformation.  MPEGDecoder maintains significant state in
% the parser, and also has negligible state in retaining predicted
% motion vectors across one iteration of work.  Radar repeatedly
% operates on long columns of an array requiring special behavior at
% the boundaries; thus, the state tracks the position in the column
% and does some internal buffering.  Radar can be rewritten at a
% coarse level of granularity to eliminate this state.

\myitem {Splitjoins and Identity filters are very common in the 
benchmarks.}  These two language constructs found broad application
across our benchmark suite.  Splitjoins appear in over three quarters
(53 out of 67) of the benchmarks, with a median of 8 instantiations
per benchmark.  Roundrobin splitters accounted for 65\% of the
instantiations, while the other splitters are of duplicate type.  (All
joiners are of roundrobin type.)  Identity filters were used in half
(33 of 67) of the benchmarks, with a median of 13 instantiations per
benchmark.  Identity filters are recognized by the compiler as a
pass-through operation, allowing it to map communication instructions
directly to a network fabric.

\begin{table}[t!]
\psfig{file=messaging-table,width=\textwidth}
\caption{Use of teleport messaging in StreamIt 
benchmarks.\protect\label{tab:lang-messaging}}
\end{table}

\myitem {Teleport messaging and dynamic rates are uncommon in 
the benchmarks, but provide critical functionality when utilized.}
These language features were not fully specified until years after the
initial release of the compiler, which contributes to their smaller
representation in the benchmark suite.

As detailed in Table~\ref{tab:lang-messaging}, teleport messages are
utilized by four of the benchmarks (MPEG2 encoder, MPEG2 decoder,
Mosaic, and FHR).  There are a total of 8 logical messages, often
between multiple senders or multiple receivers.  Both upstream and
downstream messages are utilized; all messages are sent with a latency
of zero.  While relatively few of the benchmarks use teleport
messaging, the functionality provided is essential.  As described in
the next chapter for the case of FHR, and elsewhere for
MPEG2~\cite{drake-thesis} and Mosaic~\cite{aziz-thesis}, messaging
greatly simplifies and improves the expression of these algorithms in
a streaming context.

Similarly, as illustrated in Table~\ref{tab:lang-benchmarks-params},
dynamic rates are utilized by only 9 benchmarks, but are absolutely
necessary to express these benchmarks in StreamIt.  Though there are a
total of 76 dynamic-rate filters instantiated across the benchmarks,
these instantiations correspond to only 14 filter types that perform a
set of related functions.  In JPEG and MPEG2, dynamic-rate filters are
needed to parse and also create both the BMP and MPEG formats.  MPEG2
encoder also requires a dynamic-rate filter to reorder pictures
(putting B frames in the appropriate place).  All of these filters
have unbounded push, pop, and peek rates, though in JPEG and MPEG2
decoder there is a minimum rate specified.

In Mosaic, dynamic rates are used to implement a feedback loop (in the
RANSAC algorithm) that iterates an unpredictable number of times; the
signal to stop iteration is driven by a teleport message.  The entry
to the loop pops either 0 or 1 items, while the exit from the loop
pushes either zero or one items.  Mosaic also contains three
parameterized filters, in which the input and output rates are
governed by the number of points of interest as determined by the
algorithm.  The count is established via a teleport message, thus
fixing the input and output rates prior to a given iteration.

In the graphics pipelines, the only dynamic-rate filters are the
rasterizers, which expand each triangle into an unknown number of
pixels.

\newpage
\myitem {Neighboring filters often have matched I/O rates.}  Many of
  the advanced scheduling strategies for synchronous dataflow graphs
  have the highest payoff when the input and output rates of
  neighboring filters are mismatched.  For example, the CD-DAT
  benchmark (shown in Figure~\ref{fig:cd-dat}) is used in many
  studies~\cite{murthy_minimizing_1994,bhattacharyya_optimal_1995,teich_3d_1999,bhattacharya_quasi-static_2000,chandrachoodan_efficient_2001,murthy_buffer_2004,ko_memory-constrained_2006};
% TODO: this was first page of google results for unquoted string, ``cd-dat dataflow''
%  - fill in the rest
  it converts compact disk auto (sampled at 44.1 khz) to digital audio
  tape (sampled at 48 khz).  Performing this conversion in stages
  improves efficiency~\cite{murthy_minimizing_1994}.  However,
  neighboring filters have different communication rates which share
  no common factors, resulting in a large steady-state schedule.

  In our benchmark suite, mismatched communication rates as seen in
  CD-DAT are rare.  The common case is that the entire benchmark is
  operating on a logical frame of data which is passed through the
  entire application.  Sometimes there are difference in the input and
  output rates for filters that operate at different levels of
  granularity; for example, processing one frame at a time, one
  macroblock at a time, or one pixel at a time.  However, these rates
  have a small common multiple (i.e., the frame size) and can be
  accommodated without growing the steady state schedule.  The JPEG
  transcoder provides an example of this; Figure~\ref{fig:jpeg}
  illustrates part of the stream graph that operates on a single 8x8
  macroblock.

  To provide a quantitative assessment of the number of matched rates
  in our benchmark suite, Table~\ref{tab:lang-benchmarks-params}
  summarizes the key properties of the steady state schedule derived
  for each program.  We consider the minimal steady state schedule,
  which executes each filter the minimum number of times so as to
  consume all of the items produced by other filters in the graph.  We
  count the number of times that each filter executes in this
  schedule, which we refer to as the {\it multiplicity} for the
  filter.  The table illustrates, for each benchmark, the minimum
  multiplicity, the mode multiplicity, and the percentage of filters
  that have the mode multiplicity (the mode frequency).

%% RESTORE IF TALKING ABOUT MEDIAN, MAX:
%% The table illustrates, for each benchmark, the minimum, median, and
%% maximum multiplicity across all filter instances in that benchmark.
%% It also illustrates the most common multiplicity (the mode) as well as
%% the percentage of filters that have that multiplicity (the mode
%% frequency).

  The most striking result from the table is that 90\% (60 out of 67)
  of the benchmarks have a minimum filter multiplicity of 1.  That is,
  there exists at least one filter in the program that executes only
  once in the steady state schedule.  This filter defines the logical
  frame size for the execution; all other filters are simply scaled up
  to satisfy the input or output requirements of the filter.  

%% RESTORE IF TALKING ABOUT MEDIAN, MAX:
%% Further, more than half of the benchmarks (55 out of 67) exhibit a
%% median filter multiplicity of 1.  This means that more than half of
%% the filters in these programs execute only once in the steady state.
%% For 7 benchmarks, the maximum multiplicity is also 1, implying that
%% all of the filters execute exactly once, with perfectly matched rates.

  The second highlight from the table is that, on average, 66\% of the
  filters in a program share the same multiplicity.  For over
  two-thirds of the benchmarks (46 out of 67), the most common
  multiplicity is 1; in these benchmarks, an average of 75\% of the
  filters also have a multiplicity of 1.  The mode multiplicity can
  grow higher than 1 in cases where one filter operates at a coarse
  granularity (e.g., a frame), but the majority of filters operate at
  a fine granularity (e.g., a pixel).  In these benchmarks, 46\% of
  the filters still share the same multiplicity.

  The prevalance of matched rates in our benchmark suite also led to
  unexpected results in some of our papers.  For example, in our work
  on phased scheduling, we developed a new scheduling algorithm that
  reduces the buffer requirements needed to execute a synchronous
  dataflow graph~\cite{karczmarek-lctes03}.  The space saved on CD-DAT
  is over 14x.  However, the median savings across our benchmark suite
  at the time (a subset of the suite presented here) is less than
  1.2x.  The reason is that the potential savings on most benchmarks
  was extremely small due to matched input and output rates; simply
  executing each node once would often give the minimal possible
  buffering.  This result emphasizes the importance of optimizing the
  common case in realistic programs, rather than restricting attention
  to small examples.

\begin{figure}[t!]
\centering
\psfig{file=cd-dat,width=4.5in}
\vspace{-6pt}
\caption[CD-DAT, an example of mismatched I/O rates.]{The CD-DAT
  benchmark~\cite{murthy_buffer_2004} exhibits unusually mis-matched
  I/O rates.  Nodes are annotated with the number of items pushed and
  popped per execution, as well as their execution multiplicity in the
  steady state. Since neighboring filters produce different numbers of
  items, each filter has a large multiplicity in the steady state.
  This demands clever scheduling strategies to avoid extremely large
  buffer sizes.\protect\label{fig:cd-dat}}
~ \\
\psfig{file=jpeg.eps,width=5.8in}
\vspace{-6pt}
\caption[JPEG transcoder excerpt, an example of matched I/O rates.]{This 
excerpt from the JPEG transcoder illustrates matched I/O rates, as
found in many benchmarks.  The graph is transforming pixels from an
8x8 macroblock.  Nodes are annotated with the number of items pushed
and popped per execution, as well as their execution multiplicity in
the steady state.  Since neighboring filters often produce the same
number of items on each execution, all filters except for Identity and
Adder execute exactly once in the steady state.  This offers less
flexibility to optimize the schedule, and affords less benefit from
doing so.
\protect\label{fig:jpeg}}
\vspace{-24pt}
\end{figure}

\myend

\enlargethispage{0.3\baselineskip}
In addition to our observations about the benchmark characteristics,
we also offer some lessons learned from developers' experiences in
implementing stream programs.  As noted in
Table~\ref{tab:lang-benchmarks}, the StreamIt benchmarks were
developed by 22 different people; all but one of them were students,
and half of them were undergraduates or M.Eng students at MIT.  As the
developers were newcomers to the StreamIt language, we expect that
their experience would reflect that of a broader user population;
their coding style was not influenced by the intent of the original
language designers.  We summarize their experience as follows:

\mybegin

\myitem {Structured streams are a useful and tractable means of
  writing programs.  However, they are occasionally unnatural and, in
  rare cases, insufficient.}  Overall, we found structured streams --
  the hierarchical composition of pipelines, splitjoins, and
  feedbackloops -- to be a good match for the applications in our
  benchmark suite.  While the developer sometimes had to refactor an
  unstructured block diagram into structured components, the result
  was nonetheless a viable way to represent the application.

\begin{figure}[t]
\vspace{-0.2\baselineskip}
\centering
\psfig{file=interleaving.eps,width=3.5in}

(a) Unstructured ~~~~~~~~~~~~~~~~~~~~~~~~~ (b) Structured~~~~~~
\caption[Refactoring a stream graph to fit a structured programming
  model.]{Example of refactoring a stream graph to fit a structured
  programming model.  Both graphs achieve equivalent communication
  between filters.
\protect\label{fig:interleaving}}
\end{figure}

  One shortcoming of structure is that it can force programmers to
  multiplex and demultiplex conceptually-distinct data streams into a
  single channel.  The underlying cause of this hazard is illustrated
  in Figure~\ref{fig:interleaving}.  Because filters C and D are
  running in parallel, their input streams must converge at a common
  splitter under a structured programming model.  However, this
  implies that the auxiliary communication from A to D must also pass
  through the splitter, in a manner that is interleaved with the
  output of B.  An extra splitjoin (at the top of
  Figure~\ref{fig:interleaving}b) is needed to perform this
  interleaving.  A more realistic example of the same hazard is shown
  in Figure~\ref{fig:3gpp}, which corresponds to our 3GPP benchmark.

\begin{figure}[t!]
\psfig{file=3gpp.eps,height=\textheight}
\vspace{-0.9in} ~ \\
\mbox{~}\hspace{2.03in}\begin{minipage}{4in}
\caption[Use of Identity filters is illustrated by the 3GPP benchmark.]{Stream graph of a 3GPP Radio Access
  Protocol application.  Shaded filters indicate Identity nodes that
  are used to bypass data items around intermediate filters.  They are
  also used in splitjoins for data duplication and
  reordering.\protect\label{fig:3gpp}}
\vspace{-0.5in}
\end{minipage}
\end{figure}

  Needless to say, this pattern of multiplexing and demultiplexing
  adds considerable complexity to the development process.  It
  requires the programmer to maintain an unwritten contract regarding
  the logical interleaving of data streams on each physical channel.
  Moreover, the addition of a new communication edge in the stream
  graph may require modification to many intermediate stages.

  While there is no perfect solution to this problem, we have
  sometimes embraced two imperfect workarounds.  First, the data items
  in the multiplexed streams can be changed from a primitive type to a
  structure type, allowing each logical stream to carry its own name.
  This approach would benefit from a new kind of splitter and joiner
  which automatically packages and un-packages structures from
  adjoining data channels.  The second approach is to employ teleport
  messaging; as described in the next chapter, it allows
  point-to-point communication and avoids interleaving stream data.
  However, since it is designed for irregular control messages, it
  does not expose information about the steady-state dataflow to the
  compiler.

  In practice, we have chosen to tolerate the occasional complexity of
  stream multiplexing rather than to fall back on an unstructured
  programming model.  However, it may be valuable to consider a
  natural syntax for unstructured components of the stream graph --
  the analog of break and continue statements (or even a rare GOTO
  statement) in structured control flow. It is important to note,
  however, that there is no overhead introduced by adding splitters
  and joiners to the stream graph; the StreamIt compiler analyzes the
  communication (via an analysis known as {\it synchronization
  removal}) to recover the original unstructured communication.

\begin{figure}[t]
\centering
\psfig{file=inadequate.eps,width=2in}

\caption[A communication pattern unsuitable for structured streams.]{A
  communication pattern unsuitable for structured streams.  This
  pattern can arise in video compression, where each block informs its
  neighbors of its motion prediction before the next processing
  step.\protect\label{fig:inadequate}}.
\vspace{-12pt}
\end{figure}
\enlargethispage{0.3\baselineskip}

  Finally, there are rare cases in which the structured primitives in
  StreamIt have been inadequate for representing a streaming
  communication pattern.  Figure~\ref{fig:inadequate} illustrates an
  example from video compression, where each parallel filter performs
  a motion prediction for a fixed area of the screen.  Between
  successive frames, each filters shares its prediction with its
  neighbors on either side.  While this could be represented with a
  feedback loop around the entire computation, there would be
  complicated interleaving involved.  This case reflects a broader
  shortcoming, discussed in Section~\ref{sec:lang-future-work}, that
  StreamIt is not designed for multidimensional data processing.

\myitem {Programmers can accidentally introduce unnecessary mutable
  state in filters.}  Filters that have no mutable state are
  attractive because they can be run in a data-parallel fashion.
  Unfortunately, the performance cost of introducing state is not
  exposed in the current StreamIt language.  Thus, we found that
  several programmers, when faced with two alternative implementations
  of an algorithm, would sometimes choose the one that includes
  mutable state.  Figure~\ref{fig:state} gives a pedantic example of
  this problem, while Figure~\ref{fig:state2} illustrates a realistic
  case from MPD.  Prior to conducting our performance evaluations, we
  examined all stateful filters in the benchmarks and rewrote them as
  stateless filters when it was natural to do so.  In future stream
  languages, it may be desirable to require an extra type modifier on
  stateful filters, such as a {\it stateful} keyword in their
  declaration, to force programmers to be cognizant of any added state
  and to avoid it when possible.

\begin{figure}[t]
\hspace{0.1\textwidth}
\begin{minipage}{0.35\textwidth}
\centering
\ninepoint
\begin{verbatim}
void->int filter SquareWave() {
  work push 2 {
    push(0);
    push(1);
  }
}
\end{verbatim}
\end{minipage}
\hspace{0.1\textwidth}
\begin{minipage}{0.35\textwidth}
\centering
\ninepoint
\begin{verbatim}
void->int filter SquareWave() {
  int x = 0;
 
  work push 1 {
    push(x);
    x = 1 - x;
  }
}
\end{verbatim}
\end{minipage}

\begin{minipage}{0.5\textwidth}
\centering
(a) Stateless
\end{minipage}
\begin{minipage}{0.5\textwidth}
\centering
(b) Stateful
\end{minipage}
\caption[Accidental introduction of filter state (pedantic example).]{Programmers 
  can accidentally introduce unnecessary filter state when writing
  programs.  In this example, the intended output is a square wave,
  emitting alternate values of 0 and 1.  Both implementations shown
  are functionally equivalent.  However, the stateless version (a)
  appears data-parallel to the compiler, while the stateful version
  (b) appears sequential.\protect\label{fig:state}}
\end{figure}

\begin{figure}[t]
\begin{minipage}{0.5\textwidth}
\centering
\ninepoint
\begin{verbatim}
float->float splitjoin 
CFARDelayToLMax_Stateless(int rows) {
    split roundrobin;
    add Delay(rows-1);
    add Delay(rows-1);
    add Identity<float>();
    add Delay(rows-1);
    add Delay(rows-1);
    join roundrobin;
}

float->float filter Delay(int N) {
    prework push N {
        for (int i=0; i<N; i++) {
            push(0.0);
        }
    }

    work push 1 pop 1 {
        push(pop());
    }
}
\end{verbatim}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\centering
\ninepoint
\begin{verbatim}
float->float filter
CFARDelayToLMax_Stateful(int rows) {
    float[rows] guardNoise;
    float[rows] thresh;
    float[rows] sumDb;
    float[rows] guardDb;
    int popPos = 0;
    int pushPos = 1;

    work pop 5 push 5 {
        guardNoise[popPos] = pop();
        push(guardNoise[pushPos]);
        thresh[popPos] = pop();
        push(thresh[pushPos]);
        push(pop());
        sumDb[popPos] = pop();
        push(sumDb[pushPos]);
        guardDb[popPos] = pop();
        push(guardDb[pushPos]);

        popPos++;
        pushPos++;

        if(popPos >= rows) {
            popPos = 0;
        }
        if(pushPos >= rows) {
            pushPos = 0;
        }
    }
}
\end{verbatim}
\end{minipage}
~ \\
\begin{minipage}{0.5\textwidth}
\centering
(a) Stateless
\end{minipage}
\begin{minipage}{0.5\textwidth}
\centering
(b) Stateful
\end{minipage}
\caption[Accidental introduction of filter state (real example).]{A 
  second example, drawn from MPD, in which a stateless computation was
  written in a stateful style in the original implementation.  The
  original version (b) performs a complex delay and reordering of
  interleaved vectors on the input stream, and appears stateful to the
  compiler.  It can be rewritten as a stateless construct (a), which
  separates the logical streams using a splitjoin and applies a
  stateless delay to each one.\protect\label{fig:state2}}
\end{figure}

\myitem {Multi-phase filters confuse programmers and are not
  necessary.}  At one point in the StreamIt project, we embraced the
  cyclo-static dataflow
  model~\cite{bilsen_cyclo-static_1995,parks_comparison_1995} for all
  filters.  Under this model, the programmer can define multiple work
  functions that are executed under a specified pattern.  By dividing
  execution into more fine-grained units, cyclo-static dataflow can
  offer lower latency than synchronous dataflow, and can also avoid
  deadlock in tightly constrained loops.

  However, our experience is that having the option of multiple
  execution steps is confusing to beginning StreamIt programmers.
  There is a tendency to interpret multiple execution steps as
  belonging to multiple distinct filters.  It is also difficult to
  explain to a non-expert why one method should be designated as an
  execution step, rather than as a plain subroutine call.

  Multiple execution steps did prove to be important to the semantics
  of splitters and joiners, which would have an unreasonably large
  granularity if they were forced to transfer a full cycle of data at
  a single time.  However, because StreamIt relies on a few built-in
  primitives for splitting and joining, the subtlety of this execution
  semantics could be hidden from the programmer.  Apart from splitters
  and joiners, we did not encounter any scenarios (in our limited
  benchmark suite) that demanded multiple execution steps in filters.

  Thus, after making a significant investment to support the full
  generality of cyclo-static dataflow in the StreamIt compiler, we
  eventually changed course and removed the capability from the
  language.

\myitem {Input and output rates can typically be inferred from the
  code inside a filter.  However, it is still worthwhile for the
  programmer to declare them.}  We were surprised how many StreamIt
  benchmarks contained completely static control flow inside the body
  of filters.  That is, the path of control taken through the {\it
    work} function is often independent of the data values input to
  the filter.  Exceptions to this pattern include sorting algorithms,
  compression algorithms, and parsing algorithms (e.g., the MPEG-2
  bitstream parser).

  When the control flow is static, it is often feasible for the
  compiler to infer the number of items pushed and popped via a static
  analysis.  Such an analysis could save the programmer the trouble of
  annotating each work function with its input and output rates.

  However, we did find that it is valuable for programmers to annotate
  the input and output rates even when they can be inferred.  As is
  commonly the case with type declarations, these annotations provided
  documentation to other users regarding the intended behavior of the
  filter, making it easier to understand and maintain.  They also
  provided a level of redundancy, so that, when possible, the compiler
  could check the consistency between the declared rates and the
  actual implementation.

\myend

\section{Related Work}
\label{sec:lang-related}

As described in Chapter 1 and elsewhere~\cite{stephens_survey_1997},
there is a long history of programming language support for streams in
the dataflow, functional, and synchronous language domains.  Here we
compare to StreamIt's more immediate contemporaries.

The Brook language is architecture-independent and focuses on data
parallelism~\cite{brook04}.  Stream kernels are required to be
stateless, though there is special support for reducing streams to a
single value.  Sliding windows are supported via stencils, which
indicate how data elements should be replicated across multiple
processing instances.  While StreamIt supports a single stream graph
operating a conceptually infinite stream, Brook supports multiple
graphs, embedded in a C program, that operate on finite-length
streams.  An independent comparison of the two languages by Mattson
and Lethin~\cite{mattson_streaming_2003} aptly summarizes the
philosophical difference, in that StreamIt was designed by compiler
writers (it is ``clean but more constrained'') while Brook was driven
by application developers and architects, and is ``rough but more
expressive''.

Brook is one of several stream-oriented languages that evolved out of
the graphics community. Cg exploits pipeline parallelism and data
parallelism, though the programmer must write algorithms to exactly
match the two pipeline stages of a graphics processor~\cite{cg03}.
The sH language, subsequently commercialized by RapidMind, is embedded
within C++ as a set of
macros~\cite{mccool_shader_2002,mccool_shader_2004}.  Like StreamIt,
sH specializes stream kernels to their constant arguments, and fuses
pipelined kernels in order to increase their granularity.  Unlike
StreamIt, sH performs these optimizations dynamically in a
Just-In-Time (JIT) compiler, offering increased flexibility.  However,
StreamIt offers increased expressiveness in that 1) StreamIt can
express arbitrary stream graphs, while sH appears to be limited to
pipelines, and 2) StreamIt can express kernels with state, while sH
kernels must be stateless.
% true but minor:
% sH supports data-parallel procedures with control flow
%  (SPMD, not just SIMD)
Accelerator~\cite{tarditi_accelerator_2006} also employs a
Just-In-Time strategy to target GPUs from C\#; the system derives
parallelism from data-parallel array types rather than explicit stream
kernels.

Stream\-C/Ker\-nel\-C preceded Brook and operates at a lower level of
abstraction; kernels written in KernelC are stitched together in
StreamC and mapped to the data-parallel Imagine
processor~\cite{imagine03ieee}.  SPUR adopts a similar decomposition
between ``microcode'' stream kernels and skeleton programs to expose
data parallelism~\cite{spur05samos}.

StreamIt is not the first language to incorporate the notion of a
sliding window.  In the Warp project, the AL
language~\cite{tseng89thesis} had a window operation for use with
arrays, and Printz's ``signal flow graphs'' included nodes that
performed a sliding window~\cite{printz91thesis}.  The ECOS graphs
language allows actors to specify how many items are read but not
consumed~\cite{huang_ecos_1992}; the Signal language allows access to
the window of values that a variable assumed in the
past~\cite{le_guernic_signal--data_1986}; and the SA-C language
contains a two-dimensional windowing
operation~\cite{draper_compiling_2001}.  However, to the best of our
knowledge, we are the first to demonstrate the utility of sliding
windows in improving parallelism and programmability across a large
benchmark suite.

To summarize the differences to other stream languages, StreamIt
places more emphasis on exposing task and pipeline parallelism (all
the languages expose data parallelism).
%and on sliding window operations (filters that peek).  
By adopting the synchronous dataflow model of execution, StreamIt
focuses on well-structured and long-running programs that can be
aggressively optimized.  We are not aware of structured streams or
hierarchical mechanisms for data reordering in other stream languages.
%The implicit infinite loop around programs is
%also a key StreamIt characteristic that enables optimizations.
Spidle~\cite{spidle03} is also a recent stream language that was
influenced by StreamIt.

\section{Future Work}
\label{sec:lang-future-work}

\vspace{12pt}

There are many directions in which to expand and refine the StreamIt
language.  Based on his study of MPEG-2 in StreamIt, Matthew Drake
makes a sound case for adding support for programmable splitters and
joiners, re-initialization of streams, draining of streams, and
dispatch splitjoins~\cite{drake-thesis}.  He also discusses extensions
to teleport messaging, described in the next chapter.  We endorse his
recommendations and also highlight the following research directions:

% cite written proposal to move programmable splitters and joiners
% into the language?

\mybegin

\myitem {Dynamic changes to stream structure.}  A long-time goal of
  the StreamIt group has been to define and implement support for
  dynamic changes to the stream graph.  For example, an adaptive
  channel decoder may decide to add or remove filtering stages; an FIR
  filter may dynamically scale the size of the window it considers; a
  network router may add or remove streams to represent new logical
  flows; or an AMPS cellular base station may add and remove streams
  to support new clients.

  There are several challenges and opportunities in supporting dynamic
  stream graphs.  As described in the next chapter, our basic model
  for runtime adaptation is to re-evaluate the initialization code for
  stream structures by sending a teleport message to that stream.  The
  difficulty comes in timing the re-initialization, migrating filter
  state and buffered data items to the new graph, and maintaining as
  much static information as possible about the possible
  configurations of graphs that will be adopted at runtime.  Many of
  these issues arise not from dynamism, but from incorporating a
  notion of finite streams into the language; as the current language
  views all streams are conceptually infinite, it does not have to
  deal with boundary conditions or termination procedures, both of
  which are prerequisites for dynamic reconfiguration.  While we have
  developed extensive internal notes and proposals on language support
  for dynamism, we omit them from this dissertation because we have
  yet to reach consensus on many aspects of the design.

  As an intermediate step towards supporting a fully-reconfigurable
  stream graph, it would also be interesting to introduce primitives
  that allow programmers to indicate which parts of code should be
  evaluated at compile time, versus being evaluated at load time or
  runtime.  The current StreamIt compiler requires the structure and
  communication rates in the stream graph to be evaluated at compile
  time, though the StreamIt language could also be interpreted as
  binding these values at load time (during program initialization).
  While compile-time evaluation improves optimization opportunities,
  it is not always permissible by the application.  For example, if an
  external file is used to drive the structure or parameters of the
  stream graph, then compile-time evaluation is safe if that file is
  fixed across all executions (e.g., a simulator for a specific
  processor architecture) but unsafe if it may vary from one execution
  to the next (e.g., a scene description for a rendering engine).  We
  envision that a simple type modifier, such as a ``dynamic'' keyword,
  could be used to distinguish these cases.  The type system would
  guarantee that everything that depends on dynamic data is also
  declared dynamic.  This would allow the compiler to maximally
  evaluate other sections of the stream graph at compile time.

\newpage
\myitem {Multidimensional data.}  The current version of StreamIt is
  a natural fit for handling one-dimensional sequences of data, but
  falls short in exposing the dependences and flexibility inherent in
  manipulating multi-dimensional data.  When handling sequences of
  multidimensional data (such as video frames), the programmer is
  currently left with two alternatives.  One option is to take a
  coarse-grained approach in which filters push and pop entire arrays
  at a time.  However, this results in nested loops within filter
  code, reducing the problem to a traditional loop analysis without
  gaining any leverage from the streaming domain.  The second option
  is to take a fine-grained approach, in which individual arrays are
  split up into columns or blocks and distributed over many filters.
  However, this mapping forces the programmer to specify a fixed
  decomposition of the data in the array (row-major, column-major,
  blocked, etc.) and makes it more difficult for the compiler to infer
  the underlying dependences and adjust the schedule as needed.

  One possibility for handling multidimensional data could be to add
  iterators that apply a filter (or entire stream graph) to all of the
  elements of an array.  The Brook language~\cite{brook04} adopts a
  similar approach in a construct termed {\it stencils}.  However,
  stencils generally operate on a single array at a time and are not
  integrated into a larger stream graph.  An opportunity for future
  work would be to create a unified environment for processing
  sequences of arrays and data items within arrays, including
  compiler-friendly ``bridge'' operators that decompose arrays into
  data streams and assemble data streams into arrays.  Research
  challenges arise in the specification of boundary conditions on the
  sides of an array, the dependences and reuse between different parts
  of an array, and the possibility for carried state across separate
  arrays.  Many of these issues are again rooted in StreamIt's ties to
  an infinite stream abstraction.  Integrated support for finite
  streams will be needed to effectively handle multidimensional data.

\myitem {External interfaces.}  In practice, it is important for any
  domain-specific language to have well-defined interfaces for
  interacting with languages and systems that fall outside of the
  domain.  In the case of streaming, this encompasses interfaces for
  embedding stream graphs within general purpose languages, as well as
  for embedding general-purpose computations within stream graphs.
  While we have developed an internal, ad-hoc interface for
  interfacing between StreamIt and C, there are interesting research
  questions in rigorously defining the semantics of such hybrid
  computational models. 

  For example, one characteristic of synchronous dataflow is that data
  streams are virtually infinite; however, from a general-purpose
  language, streaming computations can also be gainfully applied to
  large arrays.  Thus, it will be valuable to develop formal notions
  of draining the stream graph, and perhaps mechanisms to maintain the
  state of a stream graph from one instantiation to another.

  There are also interesting questions that relate to the memory model
  of hybrid systems.  Synchronous dataflow represents a fully
  distributed model with no access to shared state; however, other
  general-purpose programming models often embrace a shared-memory
  abstraction.  As described in the next chapter, one approach to
  unifying these abstractions could be to allow streaming updates to
  shared memory so long as they are committed according to a
  deterministic static schedule.

\myend

\section{Chapter Summary}

This chapter describes the design rationale and experienced gained
from the StreamIt language, one of the first programming languages
that exposes and exploits the inherent regularity of stream programs.
StreamIt is rooted in the synchronous dataflow model, with added
support for multiple execution steps, dynamic communication rates,
teleport messaging, peeking, and communication during initialization.
Key novelties of the language are the notion of structured streams --
akin to structured control flow in an imperative language -- as well
as hierarchical and parameterized splitjoins for data reordering.  The
design of the basic computational node in StreamIt, the filter, also
exposes inherent parallelism that is masked by pointer manipulation
and modulo operations in a traditional C implementation.

The development of a large-scale benchmark suite in StreamIt led to
several insights and surprises.  Language support for sliding windows
and communication during the initialization stage enabled many filters
to be written in a stateless manner, exposing parallelism that would
have been masked without these features.  We were surprised how few
filters contained mutable state; this suggests that many programs can
leverage data parallelism, rather than relying on task and pipeline
parallelism, to achieve parallel performance.  Our benchmarks often
contain matched input and output rates, where filters need to execute
only a small number of times before satisfying the steady-state data
requirements of their neighbors.  This property reduces the space of
scheduling alternatives as well as the benefit derived (e.g., in
buffer space) from complex filter interleavings.
%% Our benchmark suite also contained few feedback loops.  Of course,
%% these observations are valid only insofar as our choice of
%% benchmarks; we are actively expanding our coverage to include other
%% styles of programs that may lead to different conclusions.

Continuous feedback from StreamIt developers also provided a valuable
critique of the StreamIt language.  While structured streams were a
natural way to represent common programs, in some cases the programmer
needed to refactor an unstructured stream graph into a more complex
structured representation.  An optional mechanism for infrequent
unstructured communication may be valuable in future languages.
Programmers were also prone to accidentally introduce mutable filter
state, impeding parallelization.  Future languages should expose this
performance cost to the programmer so that they avoid unnecessary
serialization.  We found that multi-phase filters (as in cyclo-static
dataflow) are likely to confuse programmers and are not necessary to
express computations in our benchmark suite.  Finally, while the input
and output rates of most filters could be inferred, it was still
worthwhile to declare them from a software engineering standpoint.

There is rich potential for future work in stream languages, including
support for dynamically changing the stream structure, support for
multidimensional data, and support for external interfaces.
