\subsection{Experimental Evaluation}
\label{sec:evaluation}

We use a cluster of workstations as our evaluation testbed. Our
StreamIt compiler automatically partitions an input program into a set
of threads that are mapped to the workstations and then run concurrently.
We chose a cluster-based evaluation for two reasons. 
First, a number of streaming applications run on the server side
(e.g., cell phone base stations, radar processing, HDTV editing) and
require large computational resources. Second, clusters provide a
simple abstraction for distributed and parallel computing---multiple program
counters, and distributed memories---which 
is at the heart of emerging multi-core and tile-based architectures
for embedded, desktop, and server computing.
In our experiments, we are primarily interested in quantifying two
performance metrics: throughput and communication overhead.
For the purpose of this paper, throughput is defined
as the number of outputs produced per unit of time, and communication
overhead reflects the quantity of data transmitted between
workstations.


The teleport messaging-based implementation of the frequency hopping
radio was compiled into 28 threads
whereas the alternate version---relying on a feedback-loop---was
compiled into 32 threads.  Each thread implements a
specific subset of the stream graph  and is assigned to one of
sixteen 750Mhz Pentium~III workstations, each with a
256~Kb cache.  The machines are interconnected using a fully switched
high speed network, and the threads intercommunicate via
dedicated  TCP/IP connections. 

Our compiler maps threads to workstations using an algorithm that aims
to reduce the overall application bottleneck while
maximizing the throughput of the output filter (i.e., most downstream
actor) in the stream graph.

\begin{figure}[t]
\psfig{figure=throughput-graph.eps,width=3.3in}
\caption{\small Throughput as a function of the number of workstations
in the cluster. 
\protect\label{fig:fhr-throughput}}
\end{figure}

In Figure~\ref{fig:fhr-throughput}, we report the measured throughput 
($y$-axis) for various cluster sizes ranging from one to sixteen
interconnected workstations. Note that due to the limited parallelism in the
two implementations of the frequency hopper, cluster configurations
with more than five workstations lead to negligible gains in
terms of throughput. From the data, we can observe that teleport
messaging achieves a maximal throughput that is 49.8\% better than its
feedback-loop counterpart. Furthermore, a detailed analysis of the
results shows that teleport messaging reduces the communication
overhead by 35\%.


Each message has contains an iteration number, this number tells at which
iteration the receiver should act upon the message. Sender calculates this
iteration given the current iteration of the sender and the latency of the
message. The sender has access to an SDEP or SDEP^(-1) function that has been
compiled into the executable code.
                                                                                                     
Nodes that receive negative latency messages from an upstream sender or a
positive latency messages from downstream sender are called restricted
execution nodes and can only execute as many iterations as it has received in a
credit message from the message sender. A schedule at which credit messages
should be sent by the message sender is calculated during compile time and
embedded in sender?s code. Note that after some initialization period the
schedule becomes cyclic and repeats during subsequent steady state cycles only
the credits have increased by a fixed offset.
                                                                                                     
The implementation assumes that for each node that receives messages there is no
more than one message sender. We also assume that messages arrive as fast or
faster than data items, since otherwise we would need to synchronize execution
for 0 and small positive latency downstream messages.
                                                                                                     
