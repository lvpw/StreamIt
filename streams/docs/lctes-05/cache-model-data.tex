\subsection{Data Cache}

The results in Figure~\ref{fig:scaling-data} show that scaling can
reduce the running time of a program, but ultimately, it degrades
peformance. In this section, we provide a crude analytical model that
helps in reasoning about the relationship between scaling and the data
cache miss rate. 

We distinguish between two types of data working sets. The static data
working set of an actor represents state, e.g., \texttt{weights}
field in FIR example shown in Section~\ref{sec:streamit}.
The dynamic data working set is the data generated by
the work function. Both of these working sets impact the data cache
behavior of an actor.

Intuitively, the presence of state suggests that it is
prudent to maximize that working set's temporal locality. In this
case, scaling positively improves the data cache performance. To see
that this is true, we can define a data miss rate ($\mt{DMR}$) based on
a derivation similar to that for the instruction miss rate, replacing
replace $C_I$ with $C_D$ in Equation~\ref{eq:imiss}, and $I(w)$ with
$\mt{State}(w)$ when calculating the reuse distance. Here, $C_D$
represents a constant proportional to the data cache size, and
$\mt{State}(w)$ represents the total size of the static data in the
specified actor. 

Execution scaling however also increases the I/O requirements of a
scaled actor. Let $o$ and $u$ equal the declared pop and push rates
of an actor, respectively; if the actor is a filter with peeking, then
let $o$ equal the larger of the peek and pop rates. The scaling of an
actor by a factor $M$ therefore increases the pop rate to $M\times o$
and the push rate to $M\times u$. Combined, we represent the dynamic
data working set of an actor as $\mt{IO}(w, M) =
M\times(o+u)$. Therefore, the measure the data reuse distance
($\mt{DRD}$), we use
\[
  \mt{DRD}(S,M,i)=\sum_{j} \mt{State}(S[j]) + \mt{IO}(S[j],M)
\]
over all distinct actors occurring in $\mt{phase}(S^M,i)$.
We can then determine if a specific work function will
result in an data cache miss (on its next firing) by evaluating
the following step function:
\begin{equation}
\label{eq:dmiss}
  \mt{DMISS}(S,M,i) =
    \begin{cases}
      0& \text{if $\mt{DRD}(S,M,i) \leq C_D$; hit: no cache refill,}\\
      1& \text{otherwise; miss: (some) cache refill.}
    \end{cases}
\end{equation}
Finally, to model the data miss rate ($\mt{DMR}$):
\begin{eqnarray}
  \label{eq:dmrM}
  \mt{DMR}(S, M) &=& \frac{1}{M \times |S|}\sum_{i=1}^{|S|} \mt{DMISS}(S,M,i).
\end{eqnarray}

It is evident from Equation~\ref{eq:dmrM} that scaling can lead
to lower miss rates, but not indefiniately. This is because the miss
rate is directly proportional to the I/O rate, which increases
monotonically with the scaling factor.

Note that in order to generalize the data miss rate equation so that it properly
accounts for the dynamic working set, we must consider the amount of
data reuse within a phase. This is because any actor that fires within
a phase $\mt{phase(S,i)}$ might consume some or all of the data
generated by $S[i]$. The current model is simplistic, and leads to
exagerated I/O requirements for a phase. We also do not model the
effects of cache conflicts, and take an ``atomic'' view of cache
misses (i.e., either the entire working set hits or misses).

These observations suggest that in order to maximize the locality of
any static data in an actor, the compiler should not only favor short
phases, but also, it should schedule actor executions so that
producer-consumer pairs appear within the same phase. Our cache-aware
optimizations, described in the next section, exploits these
observations. 