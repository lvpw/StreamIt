\section{Buffer Management}
\label{sec:buffer}

A salient characteristic of stream programs is the use of FIFO
channels to communicate between parallel components.  Such channels
make explicit the communication between actors, allowing execution to
proceed in parallel or out-of-order so long as items are produced
before they are consumed.  FIFO channels also provide a natural
abstraction for the programmer, as complex modules can be assembled
from a set of small, reusable components.  For these reasons, it is
important to optimize the performance of communication channels.  An
efficient implementation enables a high-level abstraction for
composing actors without sacrificing performance.

Buffer management in StreamIt is more involved than some other stream
languages, due to the {\tt peek} operation.  The {\tt peek} operation
allows a actor to access an item on its input channel without
removing the item from the channel (removal is done via the {\tt pop}
operation).  The {\tt peek} functionality is very important for
components such as FIR (Finite Impulse Response) actors that access
data over a sliding window.  Because a given data item is accessed by
multiple iterations of the actor, there must be a persistent buffer
that stores items across executions.  In the context of a
uniprocessor, efficient buffer management translates to efficient
maintenance and addressing of this buffer in memory.  On a parallel
system, buffers can also be implemented using network links.

In this section, we explore two basic strategies for buffer management
in stream programs.  The first strategy, termed {\it modulation},
implements a traditional circular buffer that is indexed by wraparound
head and tail pointers.  The second strategy, termed {\it copy-shift},
avoids modulo operations by shifting the buffer contents after each
execution.  We demonstrate that, while a naive implementation of
copy-shift can be $2\times$ to $3\times$ slower than modulation, optimizations that
utilize execution scaling can boost the performance of copy-shift to
be significantly faster than modulation (51\% speedup on StrongARM,
48\% speedup on Pentium~3, and 5\% speedup on Itanium~2).

\input{fusion-fig1}

Our study is done in the context of a synthetic benchmark, shown in
Figure~\ref{fig:code-orig}.  
%As depicted in Figure~\ref{fig:code-graph}, 
The benchmark is a pipeline consisting of a simple source and an FIR
actor.  On each iteration, the source pushes a single item.  The FIR
actor calculates a weighted sum over {\tt PEEK} items of the input,
then pops a single item from the channel.  In our experiments, we vary
the {\tt PEEK} value from 1 to 128 items.

\input{fusion-fig2}

\subsection{Modulation}

Figure~\ref{fig:code-modulation} illustrates a fused version of the
benchmark using modulation for buffer management.  For simplicity, we
illustrate each buffer management strategy as a source-to-source
transformation in StreamIt.  Each fused actor contains a {\tt
prework} function in which the source actor executes several times to
prime the communication channel with initial items, as well as a {\tt
work} function that represents the steady-state execution.

The modulation scheme uses a traditional circular-buffer approach.
Three variables are introduced: a {\tt BUFFER} to hold all items
transfered between the actors, a {\tt push\_index} to indicate the
buffer location that will be written next, and a {\tt pop\_index} to
indicate the buffer location that will be read next (i.e., the
location corresponding to {\tt peek(0)}).  The communication
primitives are translated as follows: 

{\scriptsize
\begin{verbatim}
push(val); ==>  BUFFER[push_index] = val;
                push_index = (push_index + 1) % BUF_SIZE;

pop();     ==>  pop_index = (pop_index + 1) % BUF_SIZE;

peek(i)    ==>  BUFFER[(pop_index + i) % BUF_SIZE]
\end{verbatim}}
\noindent The StreamIt compiler converts the modulo operations to
bitwise-and operations by scaling the buffer to a power of two.  Note
that if there are no {\tt peek} operations, then the buffer will be
empty following each execution of the downstream actor.  In this
case, the indices can be reset to zero at the start of each execution
and the modulo operations can be eliminated.  However, in our example
the FIR actor does perform peeking, so the modulo operations are
needed.

{\bf Experimental setup.}  Figures~\ref{fig:buf-arm},~\ref{fig:buf-p3}
and~\ref{fig:buf-i2} illustrate the performance of various buffer
management strategies on a 137Mhz StrongARM-1110, a 600Mhz Pentium~3
and a 1.3Ghz Itanium~2, respectively.  The figures illustrate the
execution time per $10^7$ outputs for the synthetic benchmark
(Figure~\ref{fig:code-orig}) across a range of {\tt PEEK} values.  To
ensure a fair comparison with the scalar replacement optimization
(Section~\ref{sec:scalar-replacement}), all loops in the original
actor are fully unrolled.

{\bf Evaluation.}  The time required for the modulation strategy
increases linearly with the peek rate.  This is expected, as there is
a constant overhead per peek operation.  Relative to the other
strategies, modulation performs noticeably better on the Itanium~2.
We attribute this to the six integer units on the Itanium~2; since
there is not much additional work in this benchmark, it can likely
process the modulo operations in parallel with other operations using
software pipelining.

\subsection{Copy-Shift}

The copy-shift strategy, illustrated in Figure~\ref{fig:copy-shift},
shifts the live items to the front of the buffer at the beginning of
each execution.  Because each execution starts writing to and reading from
the buffer at the same location, there is no need for the indices to
wraparound and the modulo operations can be eliminated.  This savings
is compounded by additional optimizations enabled by the copy-shift
approach, as described in the subsequent sections.

However, the cost of this strategy comes in the copying operations: at
the start of each execution, $(\mbox{\it peek} - \mbox{\it pop})$
items are copied from the persistent {\tt BUFFER} to the beginning of
a local {\tt TEMP\_BUFFER}.  All subsequent operations reference the
{\tt TEMP\_BUFFER}, and the live items are copied back to the {\tt
BUFFER} upon completion.  While these two variables could also be
combined into a single buffer, keeping them separate results in a
smaller live data set when the actor is not executing.

The communication primitives are translated as follows:

{\scriptsize
\begin{verbatim}
push(val); ==>  TEMP_BUFFER[push_index] = val;
                push_index = push_index + 1;

pop();     ==>  pop_index = pop_index + 1;

peek(i)    ==>  TEMP_BUFFER[pop_index + i]
\end{verbatim}}
\noindent Compared to the modulation scheme, the copy-shift strategy
references the {\tt TEMP\_BUFFER} and does not perform modulo
operations.

{\bf Evaluation.}  As shown in
Figures~\ref{fig:buf-arm},~\ref{fig:buf-p3} and~\ref{fig:buf-i2},
the unoptimized copy-shift strategy is the slowest strategy that we
evaluate.  Though the cost per peek operation is smaller than the
modulation scheme, the copying overhead per iteration also grows with
the peek rate and cancels out any savings; overall, copy-shift
performs from $2\times$ to $3\times$ slower than modulation.  The following sections
describe optimizations that can justify taking the copy-shift
approach.

\subsection{Copy-Shift with Scalar Replacement}
\label{sec:scalar-replacement}

The first optimization enabled by the copy-shift scheme is dubbed {\it
scalar replacement}.  In contrast to the modulation scheme, the
copy-shift approach can result in array operations that access the
same location on every execution of the actor.  The idea behind
scalar replacement is to fully unroll the loops in the actor, thereby
resolving each array index to an integer literal.  Then, since each
location is fully resolved at compile time, an $n$-length array can be
replaced by a set of $n$ scalar variables: one for each item in the
buffer.  This transformation is illustrated in
Figure~\ref{fig:code-scalar-replace}.

Scalar replacement offers several performance benefits. Scalar
variables can be register allocated, and as local variables they are
subject to a range of dataflow optimizations (constant propagation,
copy propagation, dead code elimination, etc.).  Replacing array
operations with scalars also eliminates array index calculations.
Despite these benefits, scalar replacement is nearly impossible to do
in a general-purpose language such as C because array contents might
be aliased with other pointers.  StreamIt arrays represent values that
are independent in memory, thereby facilitating this optimization.

Note that scalar replacement can only be applied when array indices
can be resolved to compile-time constants.  In the presence of unpredictable
control flow within an actor, or if the loops are too large to fully unroll,
then scalar replacement does not apply.

{\bf Evaluation.}  Compared to an unoptimized copy-shift strategy,
Figures~\ref{fig:buf-arm},~Figures~\ref{fig:buf-p3}
and~\ref{fig:buf-i2} illustrate that scalar replacement offers
modest gains on our synthetic benchmark.  At the maximum peek rate of
128, the StrongARM and Pentium~3 offer speedups of 16\% and 26\%,
respectively; these speedups are rougly uniform across all peek rates.
On the Itanium~2, speedups range from 5\% to 58\% depending on the
peek rate.  We conjecture that scalar replacement is more critical for
small actors that perform only a few operations.  Due to the high
communication-to-computation ratio in such actors, there could be
large gains from register-allocating and copy-propagating the
temporary variables.

\subsection{Copy-Shift with Execution Scaling}

A final optimization of the copy-shift strategy uses execution scaling
to dramatically decrease the overhead associated with copying the
buffer contents on each iteration.  In any actor, the number of items
inspected on one execution that are saved for the next
execution is $(\mbox{\it peek} - \mbox{\it pop})$.  This represents
the number of items copied by the copy-shift scheme.  However, this
cost can be amortized by scaling the number of executions of the
downstream actor in the fused code.  By enclosing the body of the
actor in a loop, the $\mbox{\it peek}$ and $\mbox{\it pop}$ rates can
be made arbitrarily large, while $(\mbox{\it peek} - \mbox{\it pop})$
remains constant.

Thus, execution scaling reduces the fraction of time spent copying to
an arbitrarily small level.  In our study, we scale the executions of
a actor until $(\mbox{\it peek} - \mbox{\it pop}) \leq \frac{1}{4}
\mbox{\it pop}$.  In the synthetic benchmark, this implies that each
actor body executes 16 times before the buffer contents are shifted.
The code resulting from this transformation is shown in
Figure~\ref{fig:code-scaling}.

Note that due to the large loops introduced by execution scaling, it
cannot be used in combination with scalar replacement.  If the loops
were unrolled to resolve the array indices, there could be a negative
impact on the instruction cache.

{\bf Evaluation.}  As shown in Figures~\ref{fig:buf-arm}
and~\ref{fig:buf-p3}, the copy-shift approach with execution scaling
performs significantly better than modulation on the StrongARM and
Pentium~3.  At the maximum peek rate of 128, the StrongARM exhibits a
51\% speedup while the Pentium~3 shows a 48\%.  These speedups make
sense, as each peek operation is cheaper due to the eliminated modulo
operations (implemented as bitwise-and in the modulation scheme),
while the overhead from copying is reduced to a fraction of the
original copy-shift approach.

The gains are less substantial on Itanium~2, where the speedup at
$\mbox{\it peek} = 128$ is only 5\% (Figure~\ref{fig:buf-i2}).  We
attribute this to the relatively high performance of the modulation
approach on Itanium~2; due to the six parallel integer units, the
bitwise-and operation can perhaps be run in parallel and does not
increase the critical path of the program.  This balance might be
different in programs with higher integer workloads within the actors.
Still, copy-shift with execution scaling does no worse than modulation
(on any architecture), and execution scaling always offers a large
speedup over the original copy-shift approach.

\subsection{Summary}

We conclude that copy-shift with execution scaling is the best buffer
management strategy for actors that utilize peeking.  This is
somewhat surprising because the unoptimized copy-shift strategy has
large overheads that result in a slowdown relative to a circular
buffer with modulation.  However, by leveraging the flexibility of the
parallel stream graph to perform execution scaling, the overheads are
amortized.  Compared to a plain circular buffer strategy, there are
significant improvements on StrongARM (51\% speedup) and Pentium~3
(48\% speedup) with respectable performance (5\% speedup) on
Itanium~2.

%% \subsection{Reusing Intermediate Storage Variables}

%% Once loops have been unrolled, actors have been fused into a
%% partition and arrays have been replaced with scalar variables we can
%% find approximations of live ranges for the new variables and use this
%% information to reduce stack space required by the partition's work
%% function.

%% We replace the scalar variables that have been created as a result of
%% destroying arrays with a minimal number of variables, where minimal
%% number is the maximum number of overlapping live ranges at any point
%% in the work function of the fused partition.

%% The above optimization improves data access locality.

