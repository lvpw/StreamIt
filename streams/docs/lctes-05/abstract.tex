
Stream computing is an increasingly popular model of computation
because it makes explicit the parallelism and communication in the
applications. This in turns lessens the burden on the compiler to
extract parallelism, and allows for greater innovation in mapping the
computation to a computing substrate. In this paper we propose a
methodology for compiling streaming applications to general purpose,
cache-based architectures. The work is done in the context of
StreamIt, a language and compiler specifically engineered for stream
computing. In StreamIt, a program is described as a structured dataflow
graph, where the nodes represent actors that carry out 
computation. The edges in a stream graph represent
communication. Our cache optimizations are amongst the first to 
jointly consider both instruction and data working sets, finding 
a schedule that enhances instruction locality without unduly
affecting data locality.  The
optimizations are founded upon a simple and intuitive model that
quantifies the temporal locality for a sequence of  actor
executions.  The cache-aware transformations lead to significantly
better utilization of the memory system, and as such, they deliver
a 249\% speedup (over unoptimized StreamIt) for our streaming benchmark 
suite on a StrongARM processor.  We also evaluate the optimizations on 
desktop processors, yielding a 154\% average speedup on the Pentium~3 
and a 152\% average speedup on Itanium~2.
