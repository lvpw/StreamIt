
Stream computing is an increasingly popular model of computation
because it makes explicit the parallelism and communication in the
applications. This in turns lessens the burden on the compiler to
extract parallelism, and allows for greater innovation in mapping the
computation to a computing substrate. In this paper we propose a
methodology for compiling streaming applications to general purpose,
cache-based architectures. The work is done in the context of
StreamIt, a language and compiler specifically engineered for stream
computing. In StreamIt, a program is described as a structured dataflow
graph, where the nodes represent actors that carry out 
computation. The edges in a stream graph represent
communication. Our cache optimizations are unique in that they 
account for both the instruction and data working sets, finding a
schedule of actor executions that compromises instruction locality
with data locality.  The
optimizations are founded upon two simple and intuitive models that
quantify $(i)$ the temporal locality for a sequence of  actor
executions, and $(ii)$ the overhead for managing the communication
between actors. The cache-aware transformations lead to significantly
better utilization of the memory system, and as such, they deliver
a 249\% speedup (over unoptimized StreamIt) for our streaming benchmark 
suite on a StrongARM processor.  We also evaluate the optimizations on 
desktop processors, yielding a 154\% average speedup on the Pentium~3 
and a 152\% average speedup on Itanium~2.
