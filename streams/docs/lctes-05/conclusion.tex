\section{Conclusions}
\label{sec:conclusion}

In this paper, we present a simple yet highly effective methodology
for running streaming programs on common cache-based architectures.
The work shows that we can exploit the abundant parallelism in
streaming codes to improve the behavior of the cache hierarchy and
deliver significant performance improvements on existing machines. We
evaluate our methodology on three architectures: the embedded
StrongARM processor, the superscalar Pentium~3, and the VLIW Itanium~2.

Our optimizations are simple but yield surprisingly big savings in
performance. First, we introduce {\it execution scaling}, which 
increases the execution frequency of every actor in the stream
graph. Intuitively, scaling improves instruction  locality because
it increases the amount of reuse from the instruction
cache. Concomitantly, it leads to performance gains of 145\% on the
StrongARM, 58\% on the Pentium~3, and 57\% on the Itanium~2.
It is worthy to note that execution scaling is a departure from
past optimization strategies for streaming programs, which try to
minimize buffer requirements. Our scaling transformation actually {\it
increases} the size of the data buffers between actors.

We also showed that scaling presents a tradeoff between 
instruction locality and data locality. Using a simple cache
model, we show how scaling impacts the instruction and data
caches. The model serves to motivate a heuristic for calculating the
scaling factor. The heuristic, which accounts for the size of the
instruction and data caches, works quite well in practice.

This paper also introduces {\it cache aware fusion}. The fusion
optimization helps to reduce the data requirements of a program, and
can reduce the total number of memory requests by as much as 50\%. The
fusion of actors in the stream graph is carried out judiciously, and
our algorithms are sensitive to the instruction and data working sets
of the coarsened execution units, as well as their impact on the cache
hierarchy. Cache aware fusion leads to performance gains of 84\% on
the StrongARM, 101\% on the Pentium~3, and 103\% on the Itanium~2.

Cache aware fusion also enables a set of novel buffer management
strategies for handling the streams of data between actors. Due to the
static nature of stream programs, we can often apply {\it scalar
  replacement} to remove array references, and thus communication
between fused actors is done through registers, rather than through
memory.  To allow scalar replacement to apply to sliding window 
computations, we introduce a {\it copy-shift} buffer management policy
that out-performs a traditional rotating buffer.

In summary, the application of execution scaling, cache aware fusion, and our
new buffer management strategies, can improve performance of
StreamIt programs by 249\% on the StrongARM, 154\% on the Pentium~3,
and 152\% on the Itanium~2.
