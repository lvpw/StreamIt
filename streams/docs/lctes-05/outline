intro
-----

- compiling streaming codes to general purpose, cache-based architectures
- need to cope with the memory hierarchy at three levels
        a> registers
        b> instruction cache
        c> data cache
        (unitified cache)

paper contributions:

1. filter fusion
 - for a general class of filters and topologies
   - peeking
   - parallel composition, not just sequential
 - optimizations
   - converting buffers to scalar variables
   - peek scaling
   - stack space reuse

2. cache optimizations
 - limit fusion to avoid cache problems
   - greedy partitioning algorithm
   - fuse so long as:
      - code fits in L1 cache
      - data fits in 1/2 of data cache
 - after fusion, schedule order of filter firings for improved locality
   - scale up until 90% of filters have their data fit in cache

example
-------
- fusion (w/ optimizations)
- cache opt (partitioning / multiplicity)

- forward reference to results

algorithm details
-----------------
- fusion -- is there any formal model?
- cache opt
  - formal model
  - partitioning algorithm

results
-------
- isolate effects of each optimization as much as possible

related work
------------
- filter fusion
- berkely cache optimizations thesis

conclusion
----------
