intro
-----

- compiling streaming codes to general purpose, cache-based architectures
- need to cope with the memory hierarchy at three levels
        a> registers
        b> instruction cache
        c> data cache
        (unitified cache)

paper contributions:

1. cache optimizations
 - limit fusion to avoid cache problems
   - greedy partitioning algorithm
   - fuse so long as:
      - code fits in L1 cache
      - data fits in 1/2 of data cache
 - after fusion, schedule order of filter firings for improved locality
   - scale up until 90% of filters have their data fit in cache

2. filter fusion
 - for a general class of filters and topologies
   - peeking
   - parallel composition, not just sequential
 - optimizations
   - converting buffers to scalar variables
   - peek scaling
   - stack space reuse

Cache Optimizations
-------------------
- example
- formal model
- multiplicity algorithm
- forward reference to results --------------------  Rodric here and above

- partitioning algorithm ------------------------- Bill here and below
- forward reference to results

Fusion Optimizations
--------------------
- example
- algorithm
- forward reference to results

Results
-------
- summary graph four bars:
  - baseline: no fusion, best unrolling
  - only fusion + partitioning
  - only multiplicity
  - fusion + multiplicity (best cacheopt line)

- cacheopt details
  - try different unrolling factors as baseline
  - should demonstrate that cacheopt + full unrolling does as well as
    any baseline unrolling factor
  - argue that this demonstrates robustness re: choosing an unrolling factor

- fusion details (time permitting)
  - separate effects of:
     - stack reuse
     - scalar replacement
     - peek scaling

Related work
------------
- filter fusion
- berkely cache optimizations thesis

Conclusion
----------
