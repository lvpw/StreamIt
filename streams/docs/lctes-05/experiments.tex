\section{Experimental Evaluation}
\label{sec:evaluation}

\begin{table}[t]
\center
\label{tab:benchmarks}
\vspace{-12pt}
{\tiny
\begin{tabular}{|c|c|c|} \hline
{\bf Benchmark}&{\bf description}&{\bf \# of actors}\\ \hline \hline
\texttt{beamformer} &beamformer with 12 sources and 4 detectors& 54 \\ \hline
\texttt{fft-fine	} &fine grained FFT implementation	&	121 \\ \hline
\texttt{fft-coarse} &coarse grained FFT implementation	&	26 \\ \hline
\texttt{fmradio	} &FM Radio with 10 way equalizer	&	49 \\ \hline
\texttt{filterbank} &simple filterbank program	&	53 \\ \hline
\texttt{bitonic	} &bitonic sort of 64 integers	&	972 \\ \hline
\texttt{matmult	} &matrix multiplication	&	48 \\ \hline
\texttt{fir	      } &finite impulse response program	&	132 \\ \hline
\texttt{3gpp	} &3GPP Radio Access Protocol application	&	105 \\ \hline
\texttt{filterbank2}&alternate implementation of a filterbank &	37 \\ \hline
\texttt{ofdm	 }&OFDM SpectrumWare performance test	&	16 \\ \hline
\end{tabular}
}
\vspace{-12pt}
\caption{Evaluation benchmark suite.}
\end{table}


In this section we evaluate the merits of the proposed cache-aware
optimizations and buffer management strategies. We use two
different architectures: a 600~MHz Pentium~3 and a 1.3~GHz
Itanium~2. Both have 16~Kb primary instruction and data caches.

Our benchmark suite (see Table~\ref{tab:benchmarks} consists of eleven
different StreamIt applications. They are compiled with the StreamIt
compiler which applies the optimizations described in this paper, and
outputs an functionally equivalent C program that is compiled with the
\texttt{gcc} (v3.4, -O3) on the Pentium and \texttt{ecc} 
(v7.0, -O3) for the Itanium.
% Each benchmark is
% then run five times, and the median user time is recorded.

\begin{figure}[t]
  \vspace{-24pt}
  \hspace{-0.3in}\psfig{figure=p3-caf.eps, width=3.7in}
  \vspace{-48pt}
  \caption{Performance results for a Pentium~3.  The bars for each
  benchmark appear in the same order as the legend.}
  \label{fig:results-p3}
  \vspace{-6pt}
\end{figure}

\begin{figure}[t]
  \vspace{-36pt}
  \hspace{-0.3in}\psfig{figure=itanium-caf.eps, width=3.7in}
  \vspace{-48pt}
  \caption{Performance results for an Itanium~2.  The bars for each
  benchmark appear in the same order as the legend.}
  \label{fig:results-ipf}
  \vspace{-12pt}
\end{figure}

Figures~\ref{fig:results-p3} and~\ref{fig:results-ipf} illustrate the
performance due the various compilation strategies. There are six bars
per benchmark. The first bar represents the baseline compiler which
schedules a stream graph to take advantage of producer-consumer
locality but does account for the instruction or data memory
footprints. The second bar, labeled {\tt scaling} represents the
performance gains compared to the baseline when multiplicity scaling
is applied to the stream graph. For example, {\tt scaling} cuts the
execution time of \texttt{filterbank} by 19\%. The third bar, labeled
{\tt CAF} adds cache-aware fusion to the baseline compiler. The fourth
bar, labeled \texttt{CAF+scaling}, simultaneously applies scaling and
fusion. The last two bars summarize the impact of the buffer
management strategies, and scalar-replacement in particular. 
The fifth bar, labeled \texttt{CAF+buffer}
applies the scalar-replacement in addition to fusion, an the last bar,
labeled \texttt{CAF+buffer+scaling}, applies all of the optimizations.

In general, scaling improves performance, with speedups ranging for
4-87\% compared to the baseline on the Petium. In the case of
\texttt{matmult} and \texttt{ofmd}, there is a slight degradation
(nearly 5\%) due to poor code size estimation. By comparsion, the
scaling results on the 
Itanium are more uniform, and in fact, scaling does not degrade the
performance of any of the benchmarks in suite. The discrepancy between
the Pentium and Itanium results is likely due to the in-order
nature of the latter. Unlike the Pentium which can tolerate a cache
miss by issuing instruction out-of-order, the Itanium pipelines stalls
when an outstanding memory request is not serviced in time for
its consuming instruction to execute. The Itanium VLIW architecture
therefore places a greater emphasis on the memory hierarchy, and our
locality enhancing optimizations help to bridge the gap between
processor and memory speeds.

Cache-aware fusion on the Pentium degrades performance for a few more benchmarks,
whereas it improved the performance of the applications on the Itanium.
A performance degradation as a result of fusion is generally caused by
an increase in the buffer management overhead. When
we combine \texttt{CAF} with scalar-replacement, the
performance consistently improves. On the Itanium, it is likely that
the wider instruction issue width hides some of the buffer overhead by
exploiting instruction level parallelism.

Note that our benchmark suite
includes two implementations of \texttt{FFT}. The first is a
fine-grained implementation (\texttt{fft-fine}) and the other is a
coarse-grained implementation (\texttt{fft-coarse}). The former
benefits more from our cache-aware fusion because there is greater
versatility in fusing filters to achieve balanced actors. On the other hand
a coarse grained implementation restricts the amount of fusion that
can be performed and increases the burden for more efficient buffer
management. In the case of \texttt{fft-coarse}, the scalar-replacement
strategy regains nearly 30-70\% of the performance when applied in
conjunction with fusion.

The best results overall are measured when all three optimizations are
applied (the last bar). In this case, the granularity-adjusted actors
are scaled to maximize cache locality. In addition, the scalar replacement
helps to reduce the overhead of moving data
between actors. As a result, the performance gains can be quite
dramatic, ranging up to 99\% savings in execution time.

