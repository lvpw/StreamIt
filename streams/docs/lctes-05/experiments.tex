\section{Experimental Evaluation}
\label{sec:evaluation}

\begin{table}[t]
\center
\label{tab:benchmarks}
\vspace{-12pt}
{\tiny
\begin{tabular}{|c|c|c|} \hline
{\bf benchmark}&{\bf description}&{\bf \# of actors}\\ \hline \hline
\texttt{bitonic	} &bitonic sort of 64 integers	&	972 \\ \hline
\texttt{fir	      } &finite impulse response program	&	132 \\ \hline
\texttt{fft-fine	} &fine grained FFT implementation	&	267 \\ \hline
\texttt{fft-coarse} &coarse grained FFT implementation	&	26 \\ \hline
\texttt{3gpp	} &3GPP Radio Access Protocol application	&	105 \\ \hline
\texttt{beamformer} &beamformer with 64 sources and 1 detector& 197 \\ \hline
\texttt{matmult	} &matrix multiplication	&	48 \\ \hline
\texttt{fmradio	} &FM Radio with 10 way equalizer	&	49 \\ \hline
\texttt{filterbank} &simple filterbank program	&	53 \\ \hline
\texttt{filterbank2}&alternate implementation of a filterbank &	37 \\ \hline
\texttt{ofdm	 }& Orthogonal Frequency Division Multiplexor~\cite{spectrumware}	&	16 \\ \hline
\end{tabular}
}
\vspace{-12pt}
\caption{Evaluation benchmark suite.}
\end{table}



\begin{figure*}
\begin{minipage}{3.4in}
\vspace{-36pt}
\hspace{-0.4in}\psfig{figure=arm2.eps,width=4.2in}
\vspace{-66pt}
\caption{Performance results for a StrongARM.\protect\label{fig:arm-perf2}}
\end{minipage}
\hspace{0.1in}
\begin{minipage}{3.4in}
\vspace{-36pt}
\hspace{-0.4in}\psfig{figure=arm1.eps,width=4.2in}
\vspace{-66pt}
\caption{Full fusion versus \texttt{CAF+scaling+buffer} on a StrongARM.\protect\label{fig:arm-perf}}
\end{minipage}
\end{figure*}

\begin{figure*}
\begin{minipage}{3.4in}
\vspace{-36pt}
\hspace{-0.4in}\psfig{figure=p3-2.eps,width=4.2in}
\vspace{-66pt}
\caption{Performance results for a Pentium~3.\protect\label{fig:p3-perf2}}
\end{minipage}
\hspace{0.1in}
\begin{minipage}{3.4in}
\vspace{-36pt}
\hspace{-0.4in}\psfig{figure=p3-1.eps,width=4.2in}
\vspace{-66pt}
\caption{Full fusion versus \texttt{CAF+scaling+buffer} on a Pentium~3\protect\label{fig:p3-perf}}
\end{minipage}
\end{figure*}

\begin{figure*}
\begin{minipage}{3.4in}
\vspace{-36pt}
\hspace{-0.4in}\psfig{figure=i2-2.eps,width=4.2in}
\vspace{-66pt}
\caption{Performance results for an Itanium~2.\protect\label{fig:i2-perf2}}
\end{minipage}
\hspace{0.1in}
\begin{minipage}{3.4in}
\vspace{-36pt}
\hspace{-0.4in}\psfig{figure=i2-1.eps,width=4.2in}
\vspace{-66pt}
\caption{Full fusion versus \texttt{CAF+scaling+buffer} on an Itanium~2\protect\label{fig:i2-perf}}
\end{minipage}
\end{figure*}



In this section we evaluate the merits of the proposed cache-aware
optimizations and buffer management strategies. We use three
different architectures: a 137MHz Strong-ARM-1110, a 600~MHz Pentium~3 and 
a 1.3~GHz Itanium~2. All three processors have 16~Kb primary instruction and data caches.


Our benchmark suite (see Table~\ref{tab:benchmarks}) consists of eleven
different StreamIt applications. They are compiled with the StreamIt
compiler which applies the optimizations described in this paper, and
outputs a functionally equivalent C program that is compiled with
\texttt{gcc} (v3.4, -O3) for the StrongARM and for the Pentium~3 and with
\texttt{ecc} (v7.0, -O3) for the Itanium~2. Each benchmark is
then run five times, and the median user time is recorded.


Figures~\ref{fig:arm-perf2}, ~\ref{fig:p3-perf2} and~\ref{fig:i2-perf2} 
illustrate the performance due to the various compilation strategies. 
Figures~\ref{fig:arm-perf}, ~\ref{fig:p3-perf} and~\ref{fig:i2-perf} 
compare full fusion strategy versus a combination of optimizations 
proposed in our paper. The average execution time due to various compilation 
strategies is displayed at the right side of all six figures and all 
execution times are normalized to the execution time of unoptimized 
StreamIt.


The Figures~\ref{fig:arm-perf2}, ~\ref{fig:p3-perf2} and~\ref{fig:i2-perf2} 
have four bars per benchmark. The first bar labeled {\tt scaling}
represents the performance gains compared to the baseline when multiplicity
scaling is applied to the stream graph. The second graph labeled 
{\tt CAF} shows the performance gains compared to the baseline when 
cache-aware fusion is applied to the stream graph. The third graph
labeled {\tt CAF+scaling} shows the performance gains from applying
multiplicity scaling to actors that have been produced using cache-aware
fusion. The last bar labeled \texttt{CAF+scaling+buffer} shows the
execution time when buffer management optimization is combined with
cache-aware fusion and multiplicity scaling.


Only \texttt{fmradio}, \texttt{filterbank}, \texttt{filterbank2}
and \texttt{ofdm} benchmarks have filters that peek, therefore those are the 
only benchmarks that benefit from optimized buffer management when we 
apply all of the optimizations together. 


Scaling improves performance, with a speedup of 148\% for
StrongARM a speedup of 58\% for Pentium~3 and a speedup of 57\% for Itanium~2 over the baseline for our benchmark suite. 
The 90-10 heuristic works quite well and there is only one instance
where scaling results in a performance degradation. The granularity adjusted
\texttt{3gpp} on StrongARM has a 17\% slowdown due to scaling. The is possibly 
due to a buffer for items in flight between the granularity adjusted
actors overwriting the state of an executing actor in the data cache.
Since StrongARM has no L2 cache then such eviction can be quite expensive.

As we coarsen the actors with cache-aware fusion, scaling results 
in less speedup. The speedup of \texttt{CAF+scaling} over \texttt{CAF} is
90\% for StrongARM, 22\% for Pentium~3 and only 20\% for Itanium~2. 
This is because some actors are implicity scaled by fusion to match 
input/output rates of succesive actors within a fused block. 


%% The Itanium~2 has less speedup possibly
%% because of data and instruction prefetch instructions generated by the 
%% \texttt{ecc} compiler.

%% By comparsion, the scaling results on the 
%% Itanium are more uniform, and in fact, scaling does not degrade the
%% performance of any of the benchmarks in suite. 

%% The discrepancy between
%% the Pentium and Itanium results is likely due to the in-order
%% nature of the latter. Unlike the Pentium which can tolerate a cache
%% miss by issuing instructions out-of-order, the Itanium pipeline stalls
%% when an outstanding memory request is not serviced in time for
%% its consuming instruction to execute. The Itanium VLIW architecture
%% therefore places a greater emphasis on the memory hierarchy, and our
%% locality enhancing optimizations help to bridge the gap between
%% processor and memory speeds.

%% whereas it improved the performance of the applications on the Itanium.

%% a few benchmarks on both platforms.
%% A performance degradation as a result of fusion is generally caused by
%% an increase in the buffer management overhead. 


Cache-aware fusion degrades performance only for \texttt{filter}-
\texttt{bank2} on StrongARM by 6\%. When we combine cache-aware fusion 
with multiplicity scaling, the performance consistently improves. 
The speedup of \texttt{CAF+scaling} over baseline is 250\% on StrongARM,
146\% on Pentium~3 and 144\% on Itanium~2.


%% Note that our benchmark suite
%% includes two implementations of \texttt{FFT}. The first is a
%% fine-grained implementation (\texttt{fft-fine}) and the other is a
%% coarse-grained implementation (\texttt{fft-coarse}). The former
%% benefits more from our cache-aware fusion because there is greater
%% versatility in fusing filters to achieve balanced actors. On the other hand
%% a coarse grained implementation restricts the amount of fusion that
%% can be performed and increases the burden for more efficient buffer
%% management. 


Note that the \texttt{ofmd} benchmark does not benefit from fusion or
scaling. This is because  \texttt{ofmd} has few actors that consume 
and produce a total of 16-66Kb data, therefore actors can not be scaled.
Also there is limited oportunity to fuse actors of \texttt{ofmd} 
benchmark, since there are actors that have an instruction size of 9Kb 
and fusing them with other actors would generate actors that exceed the
insturcion cache.


%% In the case of \texttt{fft-coarse}, the scalar-replacement
%% strategy regains nearly 30-70\% of the performance when applied in
%% conjunction with fusion.


The best results overall are measured when all optimizations are
applied in \texttt{CAF+scaling+buffer}. Note that on StrongARM
\texttt{CAF+scaling+buffer} consistenly outperforms full fusion
strategy (see Figure~\ref{fig:arm-perf}), except for a 43\% slowdown 
for \texttt{3gpp}, this is because our compiler predicts that the
fused version of \texttt{3gpp} will not fit into instruction cache 
due to a conservative code size estimation, however, the optimized code 
of the fused \texttt{3gpp} fits into 16kb instruction cache.


On average \texttt{CAF+scaling+buffer} imporves performance over full 
fusion with a 169\% speedup on StrongARM, a 34\% speedup on Pentium~3 
and only a 6\% speedup on Itanium~2. The reason full fusion is better
for several benchmarks on Pentium~3 and Itanium~2 is that 
full fusion allows large reduction of memory accesses by allowing better 
register allocation accross actor boundaries. In cases where full fusion 
outperforms \texttt{CAF+scaling+buffer}, full-fusion results in up to 50\% 
reduction in memory accesses.


If the cache-aware fusion is modified to allow the code size of a 
granularity adjusted actor to be up to one half of the L2 cache on 
Pentium~3 and Itanium~2, then \texttt{CAF+scaling+buffer} results
move closer to or become equal to results of the full fusion in cases where
previously \texttt{CAF+scaling+buffer} was worse than full-fusion.
This modification only reduces performance of \texttt{CAF+scaling+buffer}
for \texttt{ofdm}, where two actors that have a very low communication 
to computation ratio and large instruction size are fused, thus 
limiting the possibility of memory access reduction. 


%% In this case, the granularity-adjusted actors
%% are scaled to maximize cache locality. In addition, the scalar replacement
%% and copy-shift in conjunction with scaling helps to reduce the overhead of 
%% moving data between actors. As a result, the performance gains can be quite
%% dramatic, ranging up to a 5800\% speedup for \texttt{bitonic} on Pentium~3
%% and up to a 6400\% speedup for \texttt{bitonic} on Itanium~2.



