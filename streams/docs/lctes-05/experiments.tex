\section{Experimental Evaluation}
\label{sec:evaluation}

\begin{table}[t]
\center
\label{tab:benchmarks}
\vspace{-12pt}
{\tiny
\begin{tabular}{|c|c|c|} \hline
{\bf benchmark}&{\bf description}&{\bf \# of actors}\\ \hline \hline
\texttt{beamformer} &beamformer with 12 sources and 4 detectors& 54 \\ \hline
\texttt{fft-fine	} &fine grained FFT implementation	&	121 \\ \hline
\texttt{fft-coarse} &coarse grained FFT implementation	&	26 \\ \hline
\texttt{fmradio	} &FM Radio with 10 way equalizer	&	49 \\ \hline
\texttt{filterbank} &simple filterbank program	&	53 \\ \hline
\texttt{bitonic	} &bitonic sort of 64 integers	&	972 \\ \hline
\texttt{matmult	} &matrix multiplication	&	48 \\ \hline
\texttt{fir	      } &finite impulse response program	&	132 \\ \hline
\texttt{3gpp	} &3GPP Radio Access Protocol application	&	105 \\ \hline
\texttt{filterbank2}&alternate implementation of a filterbank &	37 \\ \hline
\texttt{ofdm	 }& Orthogonal Frequency Division Multiplexor~\cite{spectrumware}	&	16 \\ \hline
\end{tabular}
}
\vspace{-12pt}
\caption{Evaluation benchmark suite.}
\end{table}


In this section we evaluate the merits of the proposed cache-aware
optimizations and buffer management strategies. We use two
different architectures: a 600~MHz Pentium~3 and a 1.3~GHz
Itanium~2. Both have 16~Kb primary instruction and data caches.

Our benchmark suite (see Table~\ref{tab:benchmarks}) consists of eleven
different StreamIt applications. They are compiled with the StreamIt
compiler which applies the optimizations described in this paper, and
outputs a functionally equivalent C program that is compiled with the
\texttt{gcc} (v3.4, -O3) on the Pentium and \texttt{ecc} 
(v7.0, -O3) for the Itanium. Each benchmark is
then run five times, and the median user time is recorded.

% Please note that we were unable 
% to obtain results for \texttt{ofdm} on the Itanium because of its 
% large code size.


\begin{figure}[t]
  \vspace{-24pt}
  \hspace{-0.3in}\psfig{figure=p3-caf-new.eps, width=3.9in}
  \vspace{-48pt}
  \caption{Performance results for a Pentium~3.  The bars for each
  benchmark appear in the same order as the legend.}
  \label{fig:results-p3}
  \vspace{-6pt}
\end{figure}

\begin{figure}[t]
  \vspace{-36pt}
  \hspace{-0.3in}\psfig{figure=i2-caf-new.eps, width=3.9in}
  \vspace{-48pt}
  \caption{Performance results for an Itanium~2.  The bars for each
  benchmark appear in the same order as the legend.}
  \label{fig:results-ipf}
  \vspace{-12pt}
\end{figure}

Figures~\ref{fig:results-p3} and~\ref{fig:results-ipf} illustrate the
performance due to the various compilation strategies. The average 
execution time of all 11 benchmarks due to various compilation strategies 
is displayed at the right side of the figure. There are six bars per 
benchmark. The first bar represents the baseline compiler which
schedules a stream graph to take advantage of producer-consumer
locality but does not account for the instruction or data memory
footprints. The second bar, labeled {\tt scaling} represents the
performance gains compared to the baseline when multiplicity scaling
is applied to the stream graph. For example, scaling gives 53\%
speedup for \texttt{fft-fine} on a Pentium~3. The third bar, 
labeled {\tt CAF} adds cache-aware fusion to the baseline compiler. The fourth
bar, labeled \texttt{CAF+scaling}, simultaneously applies scaling and
fusion. The last two bars summarize the impact of the buffer
management strategies, and scalar-replacement in particular. 
The fifth bar, labeled \texttt{CAF+buffer}
applies scalar-replacement in addition to fusion, and the last bar,
labeled \texttt{CAF+buffer+scaling}, applies all of the optimizations.

In general, scaling improves performance, with a speedup of 
40\% for Pentium~3 and a speedup of 37\% for Itanium~2 over the baseline
for our benchmark suite. For Pentium~3 benchmarks \texttt{fft-coarse} and 
\texttt{matmult} have a 5\% and a 10\% slowdown due to overscaling. 
Without fusion there are many actors and even 90-10 heuristic can 
overscale some critical actor leading to data eviction from primary 
data cache.

As we coarsen the actors with fusion scaling results in less speedup.
The speedup of \texttt{CAF+scaling} over \texttt{CAF} is
31\% for Pentium~3 and only 8\% for Itanium~2. This is because some actors
are implicity scaled by fusion to match input/output rates of succesive 
actors within a fused block. The Itanium~2 has less speedup possibly
because of data and instruction prefetch instructions generated by the 
\texttt{ecc} compiler.

%By comparsion, the scaling results on the 
%Itanium are more uniform, and in fact, scaling does not degrade the
%performance of any of the benchmarks in suite. 

%The discrepancy between
%the Pentium and Itanium results is likely due to the in-order
%nature of the latter. Unlike the Pentium which can tolerate a cache
%miss by issuing instructions out-of-order, the Itanium pipeline stalls
%when an outstanding memory request is not serviced in time for
%its consuming instruction to execute. The Itanium VLIW architecture
%therefore places a greater emphasis on the memory hierarchy, and our
%locality enhancing optimizations help to bridge the gap between
%processor and memory speeds.

%whereas it improved the performance of the applications on the Itanium.

Cache-aware fusion degrades performance for a few benchmarks on both platforms.
A performance degradation as a result of fusion is generally caused by
an increase in the buffer management overhead. When
we combine \texttt{CAF} with scalar-replacement, the
performance consistently improves. 
The speedup of \texttt{CAF} over baseline is 44\% on Pentium~3
and 66\% for Itanium~2. 
The speedup of \texttt{CAF+buffer} over baseline is 77\% on Pentium~3
and 85\% for Itanium~2. 
On the Itanium, it is likely that
the wider instruction issue width hides some of the buffer overhead by
exploiting instruction level parallelism.

Note that our benchmark suite
includes two implementations of \texttt{FFT}. The first is a
fine-grained implementation (\texttt{fft-fine}) and the other is a
coarse-grained implementation (\texttt{fft-coarse}). The former
benefits more from our cache-aware fusion because there is greater
versatility in fusing filters to achieve balanced actors. On the other hand
a coarse grained implementation restricts the amount of fusion that
can be performed and increases the burden for more efficient buffer
management. 

Also note that \texttt{ofmd} benchmark does not benefit from fusion or
scaling. This is because \texttt{ofmd} benchmark has few actors that consume 
and produce a total of 16-66Kb data, therefore actors can not be scaled.
Also there is limited oportunity to fuse actors of \texttt{ofmd} 
benchmark, since there are actors that have instruction size of 9Kb 
and fusing them with other actors would generate actors that exceed 
insturcion cache.

%In the case of \texttt{fft-coarse}, the scalar-replacement
%strategy regains nearly 30-70\% of the performance when applied in
%conjunction with fusion.

The best results overall are measured when all optimizations are
applied (the last bar). In this case, the granularity-adjusted actors
are scaled to maximize cache locality. In addition, the scalar replacement
and copy-shift in conjunction with scaling helps to reduce the overhead of 
moving data between actors. As a result, the performance gains can be quite
dramatic, ranging up to a 5800\% speedup for \texttt{bitonic} on Pentium~3
and up to a 6577\% speedup for \texttt{bitonic} on Itanium~2.



