#!/usr/uns/bin/perl

##############################################################################
#
# This script is meant to be run weekly from crontab to keep the disk space
# used by old regression tests from becoming excessive.
#
# It finds the subdirectories of /home/bits8/streamit/regtest.  It ignores
# the 9 most recent directories (generally 8 real directories and a symlink)
#
# Regression test directories more ancient than the 8 most recent are removed.
# Before a directory is removed, the file streams/results.xml is compressed
# and stored in /home/bits8/streamit/old_regtest_results.  Our summary report
# and RT data can be (mostly) rebuilt from these files.
#
# So rather than having several GB of regression test data, we have circa 2MB
# stored as /home/bits8/streamit/old_regtest_results/results.xml.DATE.bz2.
#
# /home/bits8/streamit/old_regtest_results will eventually require some 
# cleanup.  If the size grows beyong 100M (circa 50 old results) then 
# every other result in /home/bits8/streamit/old_regtest_results will be
# deleted.  
#
##############################################################################


use Shell;
use strict;
use warnings;

# one line for total number of files, then files sorted in
# most recent first.

my $baser = "/home/bits8/streamit";
my $base = "$baser/regtest";
my $attic = "$baser/old_regtest_results";

#
# if attic size > 100M, delete every other results.xml... file in attic
#
my ($sizedu) = `du -sk $attic` =~ /^([0-9]+)/;
if ($sizedu > 100000) {
    print "$sizedu K used in $attic: deleting some files\n";
    opendir(ATTIC, $attic) || die "Cannot open $attic: $!";
    my @files = sort readdir(ATTIC);
    @files = grep { /^results\.xml/ } @files;
    closedir(ATTIC);
    my $n = 0;
    foreach (@files) {
	if ($n == 1) {
	    print "Removing old result $_\n";
	    unlink("$attic/$_") || die "Cannot unlink $attic/$_: $!";
	}
	$n = 1 - $n;		# alternate value of $n between 1 and 0
    }
}

#
# delete all but 8 latest regtest directories and summarize the results of the
# deleted directories in the attic.
# 

#my @dirs = ls('-lt', $base);   unreliable if touched directories!!!

# get all directories, regtest directories by name, which should
# be cronological order of creation.  reverse list of names and remove
# 0..7 to leave all but the 8 most recent regtest directories in the list.
opendir(BASE, $base) || die "Cannot open $base: $!";
my @dirs = sort readdir(BASE);
@dirs = grep { /^2[0-9]+\.[0-9]+\.[MTWFS][a-z][a-z]/ } @dirs;
closedir(BASE);
@dirs=reverse(@dirs);
@dirs = @dirs[8..$#dirs];

# remove summarize results into attic and remove regtest directories
# remaining in the list @dirs.
foreach (@dirs) {
    print "Summarizing $_. ";
    # do the bzip in a subshell of what `command` normally would provide.
    # redirect the output 
    my $errmes;
    if ($errmes = `(bzip2 -c $base/$_/streams/results.xml > /tmp/results.xml.$_.bz2) 2>&1`) {
       if ($errmes =~ /bzip2: Can.t open input file .+results.xml: No such file or directory\./) {
	   # If can't open input file, the usual reason is disk overflow
	   # so we want to delete the test directory despite the error.
	   print "Error during bzip $errmes";
	   print "Proceeding to delete\n";
	   # delete here and 'next' so doesn't copy 0-length .bz2 file to attic
	   print "Deleting $_\n";
	   system "rm -rf $base/$_";	# not 'unlink' since recursive removal
	   next;
       } else {
	   print "$?\n";
	   # Other bzip error: report it and skip deletion.
	   $! =~ s/(w+)/<$1>/g;
	   print "Error during bzip $errmes";
	   print "Omitting delete\n";
	   next;
       }
    }

    print "Deleting $_\n";
    system "rm -rf $base/$_";	# not 'unlink' since recursive removal

    system("mv /tmp/results.xml.$_.bz2 $attic/results.xml.$_.bz2") 
    && print 
    "Error moving /tmp/results.xml.$_.bz2 to $attic/results.xml.$_.bz2.\n"
    . "File left in /tmp.  Move manually when enough disk space";
}

