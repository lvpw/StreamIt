\documentclass[11pt,oneside]{article}
\usepackage[margin=1in,top=0.5in]{geometry}
\usepackage[pdftex]{graphicx,color}
\usepackage{verbatim,indentfirst}
\usepackage{listings}
\usepackage{textcomp}

\usepackage{pifont}
\newcommand{\X}{\ding{54} }
\newcommand{\note}[1]{\marginpar{{\it #1}}}
%\renewcommand{\note}[1]{}

\title{Dynamic Load Balancing for Executing\\ Stream Programs on a Cluster\\ \ \\}
\author{Hasti Ahlehagh \\ Quinn Mahoney \\ Janis Sermulins\\ \ \\}
\date{\today}


\begin{document}


\maketitle

\thispagestyle{empty}

%\vspace{60pt}

\begin{abstract}
 
This work considers dynamic load balancing for executing stream programs 
on a cluster. StreamIt is a high-level data-flow programming language and 
compiler for modern streaming systems \cite{thies}. This language is 
designed to facilitate the programming of large streaming applications; 
it outputs a set of components that can be distributed among a cluster of 
commodity computers. Load balancing is vital for improving performance. 
The current StreamIt implementation uses statically generated mappings to 
assign threads to cluster machines, but these static mappings assume 
that an equal amount of CPU resources are available on each cluster 
machine. In this study, we propose a new load balancing algorithm for 
detecting load imbalances. This allows a StreamIt program to adjust to 
varying CPU resources on cluster machines by collecting run-time 
statistics. We compare StreamIt performance with our dynamic load
balancing to the na\"{i}ve approach, which assumes that equal CPU resources 
are available on all cluster machines.
 
\end{abstract} 

%\newpage

\section{Introduction}
The emergence of different streaming applications like streaming media, 
software radio, and graphics packages on a variety of embedded and 
high-performance systems has fomented the need for a streaming language 
and compiler that facilitate modularity, programming productivity, and 
robustness. StreamIt is a high-level data-flow programming language and 
compiler introduced to facilitate the development of modern streaming 
applications \cite{thies}. StreamIt exploits the modular nature of the 
streaming application to distribute the computation workload to 
different processors, which results in faster execution. This 
characterisÂtic of StreamIt introduces load balancing issues, which is 
an important area for improvement. The performance of a StreamIt 
application is closely related to the distribution of the load on 
each processor.

The current StreamIt implementation uses static load balancing to assign 
threads to each cluster machine; it assumes that each machine has an 
equal amount of CPU resources available to run the application. However, 
this assumption is not always valid since the computers in a cluster may 
have a different number of processors or different clock speeds. 
Furthermore, there might be other processes executing on the cluster 
machines, which decrease the resources available to the StreamIt 
application. The resources consumed by these unrelated processes may 
also change dynamically. Therefore, dynamic load balancing is preferable 
because it can adapt to changing conditions as well as accommodate 
heterogeneous clusters.

In the current implementation, a Central Control Processor (CCP) runs 
on one of the cluster machines and monitors the running application. 
It periodically checks that each cluster machine is alive and reachable 
and uses this information to reconfigure the stream application if any of 
the machines fails or is disconnected from the network. We modified the 
CCP to collect statistics about CPU utilization from each cluster machine. 
This information can be used to optimize the distribution of the stream
program components. We propose an algorithm that computes an efficient 
mapping of stream program components to cluster machines
given the current CPU statistics.

The key challenges in designing a good dynamic load balancing algorithm
for StreamIt are: estimating the CPU resources needed for each component
of the stream program, estimating the CPU resources available for
StreamIt on each of the cluster machines, finding a suitable mapping for
the stream program components to cluster machines and deciding when
to change the current assignement due to a change in the CPU resources 
available. The estimation of the relative CPU resources needed by each 
stream program component has already been implemented in the StreamIt 
compiler. We propose a solution to the other key challenges.

In this paper we briefly present a description of the StreamIt language, 
compiler and an execution environment for a distributed cluster.
Then, we discuss the design of our dynamic load balancing algorithm
followed by an experimantal evaluation.
Finally we present some future work and conclude the paper.

\subsection*{Related Work}
 
Load balancing algorithms have been studied in various contexts such as
CPU usage in parallel processing and route selection in communication
networks. For our study, we only consider CPU utilization for load
balancing and assume the network bandwidth is abundant and that memory
usage is not a concern. Static and dynamic load balancing have been
studied in \cite{ghosh}, \cite{hamdi}, and \cite{zhang}. \cite{zhang}
uses simulation approach to compare the performance of dynamic and
static load balancing in heterogeneous distributed
systems. \cite{ghosh} studies fully distributed dynamic load balancing
in the context of graph theory and solves the problem of Incremental
Weight Migration on an arbitrary graph. They propose a randomized
algorithm that results in optimal convergence towards the equal
weighted graph. \cite{hamdi} introduces a dynamic load balancing
scheme for parallel image processing applications, where a central
manager is used to partition a given workload (an image) into a set of
several smaller sub-images, distribute them to all components
involved, and collect the results. In their computing environment,
bandwidth of the network is limited, and they try to optimize the
algorithm so that communication cost involved in transferring the data
is not greater than the cost of computing the data locally. Like
\cite{hamdi}, our dynamic load balancing algorithm uses a centralized
manager and the graph theory approach to compute the repartitioning of
the workload assigned to each cluster machine. We could not use the
algorithm proposed in \cite{hamdi} for two reasons: first, their
algorithm was very specific to the image processing application
whereas we needed a dynamic load balancing algorithm for StreamIt so
that any 3rd party Streamit application could benefit from it. Second,
the algorithm proposed in \cite{hamdi} compromises the load balancing
algorithm because of the limitation in the bandwidth of the network
while in our cluster machine bandwidth is plentiful.

%\newpage 

\section{Current StreamIt Implementation}

In this section we present how StreamIt programs can be compiled
to and executed on a cluster. We present the existing partitioner
and describe its shortcomings. We also explain
how by using the Central Control Process it is possible to restart a 
StreamIt program on a cluster from a recent checkpoint. We will 
need this property for our dynamic load balancing algorithm.

%in order to restart a StreamIt program after reconfiguration.

\subsection*{StreamIt Language}

Each StreamIt program can be represented as a graph with nodes and
edges. Each node represents a computation element and each edge
represents a FIFO data channel. See Figure~\ref{part1} for an example
graph. To perform file I/O, the first node can read data from a file
and write it to its output channel, the last node can read data from
its input channel and write it to a file.

\subsection*{Existing Partitioner}

The current StreamIt implementation estimates how much computational 
resources each stream program component will require. It then applies 
a sequence of $N-1$ vertical and horizontal cuts to the graph of the 
stream program to produce $N$ partitions such that the estimated work 
within all partitions is as uniform as possible. The algorithm starts
with a single partition that contains the whole graph. Each cut is applied
to only one of the existing partitions and therefore increases the number
of partitions by exactly one. In some cases, the algorithm must insert 
dummy components (whose outputs are equal to their inputs) in order to enforce 
certain properties of the stream graph. Better load balancing may be 
achieved if the algorithm is not restricted to only horizontal and 
vertical cuts as shown in Figure~\ref{part1} and Figure~\ref{part2}.


\begin{figure}[h] %  figure placement: here, top, bottom, or page
\begin{center}
\begin{minipage}{.35\textwidth}
\begin{center}
   \includegraphics*[width=180pt]{partition1.png} 
   \caption{Partitions considered by the existing partitioner}
   \label{part1}
\end{center}
\end{minipage}
\begin{minipage}{.06\textwidth}
\hspace{.06\textwidth}
\end{minipage}
\begin{minipage}{.45\textwidth}
\begin{center}
   \includegraphics*[width=240pt]{partition2.png} 
   \caption{Partitions not considered by the existing partitioner}
   \label{part2}
\end{center}
\end{minipage}
\end{center}
\end{figure}


\subsection*{Executing Stream Programs on a Cluster}

When executing a StreamIt application on a cluster, each stream program
component is executed as a separate thread. The StreamIt compiler
generates the code for each thread using the C language.
The existing static partitioner maps the threads to a given number
of cluster machines. The mapping is stored in a cluster configuration 
file. Note that multiple threads are often mapped to a single machine.

Initially, a process is started on each of the cluster machines. These 
processes read the cluster configuration file and create the necessary 
TCP connections between corresponding process running on the other 
cluster machines. Once the connections have been established, the 
computation threads are started. The computation continues for a 
specified number of iterations. This does not provide support for any 
dynamic reconfiguration or failure recovery.

\subsection*{Restarting a Stream Program from a Checkpoint}

The CCP process is started on one of the cluster machines. We make an 
assumption that this machine will not crash. In theory we could deal 
even with the CCP crashing. However, a failure of the CCP would require 
an intervention by a person who would have to start a new CCP process 
and start new computation processes on all of the cluster machines; the 
computation could then proceed from a recent checkpoint. 

On each of the cluster machines, a NodeServer thread connects to the CCP 
process and informs it that a machine is available for stream processing. 
The CCP then gives instructions to the NodeServer and periodically 
checks that the machine is alive.

Each time that a new cluster machine connects to the CCP or a connected
machine becomes unavailable, the mapping of threads to machines has to be 
changed.

\begin{list}{}
\item 1. The CCP sends a STOP\_ALL\_THREADS message to all connected machines.
\item 2. The CCP reads a mapping of threads to a given number of machines from a file (a set of files has to be pre-generated statically).
\item 3. The CCP sends out a CLUSTER\_CONFIG message that contains the mapping of threads to the machine IP addresses. At this point all machines perform the same steps as if a new stream program is to be executed unreliably; they create TCP connections and start computation (the only difference is that they may have to read state variables of the threads from a recent checkpoint; this information is present in the CLUSTER\_CONFIG message).
\end{list}
\ \\

In order to support the restarting of a stream application, each computation 
thread periodically saves its state variables to disk, each time creating 
a new file called a checkpoint. The checkpoints are created such that
if we restore all threads using a set of matching checkpoints then all
communication channels are empty; therefore, we do not need to checkpoint
data in the communication channels.

One thread of the CCP process deletes checkpoints that are no longer 
needed. For example, once all computation threads have created a 
checkpoint for the iteration 200, we no longer need checkpoints for 
earlier iterations (ex. 100) and can delete them (If we need to recover, 
we can use iteration 200 instead of any earlier iteration). 

\newpage 

\section{Design Overview}

Our implementation of the dynamic load balancing algorithm gathers 
statistics from the cluster machines, such as the percentage of the CPU 
utilized by the StreamIt program and the percentage of the CPU cycles 
that are idle. The CCP gathers this data periodically
and computes a new mapping of threads to machines that represents
the CPU resources available at each cluster machine. If the new mapping
is sufficiently different from the current mapping then the CCP initiates
a reconfiguration where the stream program is halted and restarted
from the most recent checkpoint. The restart allows us to adjust
the mapping of the threads to machines.

Initially, we assume that all cluster machines have equal CPU resources. 
However, as we gather the CPU usage statistics we can adjust the
mapping to improve the load balance. The result is that a stream program 
is able to reconfigure itself for optimization and react to changing 
conditions, such as other programs running on the same cluster.

\subsection*{Data Collection}

Our dynamic load balancing algorithm requires that certain data be 
collected. We divide this data into two categories, dynamic and static. 
The dynamic data is measured at run-time by each machine and sent to 
the CCP. This data includes the CPU usage of the StreamIt program on 
the machine, and the amount of idle CPU cycles. 
The static data is produced at compile-time by the 
StreamIt compiler. This information includes the estimate of the CPU 
resources required by each thread relative to other threads. 
This estimate, when combined with the actual CPU usage, 
allows us to estimate the relative speeds of different cluster machines.

Suppose that a cluster machine $i$ has threads whose work
estimates sum up to $work_i$, average CPU utilization by the
StreamIt program is $util_i$ and CPU has $idle_i$ idle cycles
($util_i$ and $idle_i$ are represented as integers from 0 to 100).
We calculate $R_i$, the relative amount of CPU resources available on the
machine $i$ by using the following formula:

$$
R_i = \displaystyle\frac{work_i}{util_i} * (util_i + idle_i)
$$

\subsection*{New Partitioner}

The existing partitioner calculates the best $N-1$ horizontal and vertical
cuts, such that the load balance among the $N$ partitions is as equal as
possible. The algorithm uses dynamic programming and is implemented in 
Java. The existing partitioner is invoked during the compilation of the 
StreamIt program to C. It is therefore inappropriate for execution 
during runtime.

We have developed an alternative partitioner, which does not use
dynamic programing, but is not restricted to making only horizontal
and vertical cuts. Because the algorithm is greedy its
execution time is negligible even for large graphs.

Figure~\ref{newpart} shows the execution of the new partitioner step
by step. The filled nodes have been added to a partition. The shaded nodes 
are eligible to be added in the current step because all nodes that supply 
input to them have been added to some partition. At each step,
the algorithm chooses any of the eligible (shaded) nodes and adds it
to the current partition as long as the current partition's work 
estimate does not become larger than a certain threshold. Once no
node can be added to satisfy this condition, a new partition is started.
Note that the algorithm resembles a breadth first search. In our example, the 
last node becomes eligible only after both of the previous nodes have been 
added to some partition. 

\begin{figure}[h] %  figure placement: here, top, bottom, or page
\begin{center}
   \includegraphics*[width=360pt]{partition3.png} 
   \caption{Execution of the new partitioner}
   \label{newpart}
\end{center}
\end{figure}

For a homogenous cluster, the threshold for all partitions is the 
sum of all the work estimates divided by the number of partitions. 
Once we have gathered statistics from the cluster machines, the 
thresholds are proportional to the $R_i$ values for each machine.

\subsection*{Dynamic Load Balancing Algorithm}

When we start executing a StreamIt program on a cluster consisting
of $N$ machines, the initial mapping of threads to machines
is constructed using our new partitioner, under the assumption that 
all machines have equal CPU resources.

The CCP collects current statistics from the cluster machines
every 1 to 2 seconds. Every 40 seconds, the CCP calculates the
average values of all statistics gathered during the previous 40 seconds.
Then CCP computes a new mapping of threads to machines using our 
new partitioner and the $R_i$ values that have been computed using 
the average values of CPU statistics.

\begin{figure}[htp]
\begin{center}
\framebox[.8 \textwidth]{
\vbox{
\begin{flushleft}
\begin{tabbing}
xxxx \= xxxx \= xxxx \= xxxx \= \kill
1. Receive Load Info from Machines\\
2. Find New Mapping of Threads to Machines\\
3. If ( More Than 4 Percent Difference )\\
\> Send STOP\_ALL\_THREADS to Machines\\
\> Send New Mapping to Machines\\
\> Ask Machines to Resume Computation from a Checkpoint\\
4. Goto Step 2
\end{tabbing}
\end{flushleft}
}
}
\caption{StreamIt dynamic load balancing algorithm}\label{load-balance}
\end{center}
\end{figure}


If the sum of the work estimates of the threads that are moved to a
different machine in the new mapping is more than 4 percent of the sum
of all work estimates, the CCP initiates a reconfiguration.  During a
reconfiguration, the CCP sends a STOP\_ALL\_THREADS message to all of
the machines and then sends out a new mapping of threads to
machines. The threads examine the most recent checkpoint and load
their state variables. The CCP makes sure that all threads examine the
same checkpoint by including a unique checkpoint identification number
along with the mapping that it sends to all machines.


\section{Experimental Results}

In this section, we study the performance of our dynamic load
balancing for different cluster configurations. Our cluster consists
of dual processor machines with processor speeds of 840MHz, 1GHz,
2.2GHz and 3.6GHz.  The network has a capacity of 1 Gigabit per second and
it is fully switched.  We use a MPEG-2 Decoder implementation in
StreamIt for evaluating our load balancing algorithm. We chose this
benchmark because it can be run for an extended amount of time alowing
us to see the effect of dynamic load balancing over time. We measure
the performance by inserting a timer in the last thread (the thread
that writes data to a file), the timer measures the time it takes to
gather data corresponding to a single frame.  This timer reflects the
steady state performance of the StreamIt program.

\begin{figure}[h] %  figure placement: here, top, bottom, or page
\begin{center}
\begin{minipage}{.49\textwidth}
\begin{center}
   \includegraphics*[width=230pt]{fig1.png} 
   \caption{MPEG2 decoder performance on a 2~machine cluster (1GHz,~3.6GHz).}
   \label{fig1}
\end{center}
\end{minipage}
\begin{minipage}{.49\textwidth}
\begin{center}
   \includegraphics*[width=230pt]{fig2.png} 
   \caption{MPEG2 decoder performance on a 3~machine cluster (840MHz,~1GHz,~3.6GHz).}
   \label{fig2}
\end{center}
\end{minipage}
\end{center}
\end{figure}


Figure~\ref{fig1} and Figure~\ref{fig2} show the performance of the MPEG2 
decoder on a non-homegeneous 2~machine and 3~machine cluster, respectively.
Results are captured in three different scenarios. The first scenario 
represents no reconfiguration, in which partitioning is done assuming that 
all machines have equal CPU resources. The next two scenarios represent 
our dynamic load balancing algorithm with two different thresholds of 
4~percent and 8~percent for reconfiguration. The different thresholds 
represent different sensitivity. With the 4~percent threshold the frequency 
of reconfiguration is higher than with the 8~percent threshold. 
We observe that our dynamic load balancing has almost the same performance
with both thresholds and performs better than the no reconfiguration
scenario.

\begin{figure}[h] %  figure placement: here, top, bottom, or page
\begin{center}
\begin{minipage}{.49\textwidth}
\begin{center}
   \includegraphics*[width=230pt]{fig3.png} 
   \vspace{12pt}
   \caption{MPEG2 decoder performance on a 3~machine cluster (all~1GHz).}
   \label{fig3}
\end{center}
\end{minipage}
\begin{minipage}{.49\textwidth}
\begin{center}
   \includegraphics*[width=230pt]{fig6.png} 
   \caption{MPEG2 decoder performance on a 3~machine cluster (all~1GHz) with a background process started on one of the machines after three minutes.}
   \label{fig6}
\end{center}
\end{minipage}
\end{center}
\end{figure}


Figure~\ref{fig3} shows the performance on a homogeneous 3 machine
cluster. We see that there is some cost to our dynamic load balancing
as compared to no reconfiguration; however, the steady state performance 
is about the same. Figure~\ref{fig6} shows the performance on
a homogeneous 3 machine cluster with a background process that starts
on one of the machines three minutes after the start of the computation.
We see that without dynamic load balancing the performance degrades
significantly; however, with dynamic load balancing, the performance
is about 3 times better. 

\begin{figure}[h] %  figure placement: here, top, bottom, or page
\begin{center}
\begin{minipage}{.49\textwidth}
\begin{center}
   \includegraphics*[width=230pt]{fig4.png} 
   \caption{MPEG2 decoder performance on a 3~machine cluster (all~1GHz) with a background process between frames 12 and 22.}
   \label{fig4}
\end{center}
\end{minipage}
\begin{minipage}{.49\textwidth}
\begin{center}
   \includegraphics*[width=230pt]{fig5.png} 
   \caption{MPEG2~decoder~performance~on~a 4~machine~cluster~(840MHz, 1GHz, 2.2GHz, 3.6GHz) with a background process after frame 8.}
   \label{fig5}
\end{center}
\end{minipage}
\end{center}
\end{figure}


Figure~\ref{fig4} and Figure~\ref{fig5} show how our dynamic load 
balancing can adapt to transient or permanent background processes.
In both cases we see that our dynamic load balancing algorithm 
has significant advantages as compared to execution with no 
reconfiguration.

Our experimental evaluation shows that there is no difference
between having the threshold of reconfiguration being set at 4 
percent or 8 percent. Therefore, we suggest using a threshold
value of 8 percent to avoid frequent reconfiguration.

\section{Future Work}

Evaluate other heuristics for deciding when to reconfigure. Determine
the best reconfiguration interval. Improve the new partitioner
algorithm to use some heuristic or backtracking instead of
being greedy.

\section{Conclusion}
 
Our dynamic load balancing algorithm can have significant impact on the
performance of a StreamIt application that is executed on a cluster.
It allows us to adjust load balance for a non-homogeneous cluster.
It also allows us to adjust load balance if a computationally 
intensive background process is executing or is started on one of the 
cluster machines.

\newpage

%\nocite{*}
\bibliography{report}
\bibliographystyle{plain}

\end{document}
