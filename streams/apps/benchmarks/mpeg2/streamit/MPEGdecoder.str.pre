/*
 * Copyright 2005 by the Massachusetts Institute of Technology.
 *
 * Permission to use, copy, modify, and distribute this
 * software and its documentation for any purpose and without
 * fee is hereby granted, provided that the above copyright
 * notice appear in all copies and that both that copyright
 * notice and this permission notice appear in supporting
 * documentation, and that the name of M.I.T. not be used in
 * advertising or publicity pertaining to distribution of the
 * software without specific, written prior permission.
 * M.I.T. makes no representations about the suitability of
 * this software for any purpose.  It is provided "as is"
 * without express or implied warranty.
 */

/**
 * @description
 * This file contains functions that allow one to decode MPEG-2 compliant video. 
 * The code is based on the MPEG-2 specification (ISO/IEC 13818-2). The MPEG-2 decoding
 * is a work in progress, although it works within a limited test range. Throughout the 
 * source code, citations are made in cases where an understanding of the code would be
 * helped by looking at an outside source. The format I have chosen is 
 * (cite NUM#, LOOKUP_INFO). NUM=1 refers to ISO/IEC: 13818-2, and NUM=2 refers to the reference
 * MPEG implementation written in C, available at [www.mpeg.org].
 *
 * @author <a href="mailto:madrake@gmail.com">Matthew Drake</a>
 * @file MPEGdecoder.str.pre
 * @version 1.0
 */

// Comments for readers of the StreamIt MPEG specification:
//
// TODO notes refer to parts of the MPEG-2 specification which this
// program does not yet handle, or assumptions made by the program.
// FEATURETODO notes refer to changes that ought to be made to the program,
// or support which can be added for more of the MPEG-2 specification, which
// is pending the addition of features to the StreamIt language compiler.
// In general I have tried to document my code, and refer to the MPEG-2
// specification whenever I used it. If you are looking at any particular
// block of code and aren't sure what it is doing, find the previous citation
// comment, and refer to the corresponding page in the MPEG 2 spec.

/**
 * Interprets and decodes a compressed MPEG-2 compliant bit stream, in accordance
 * with the IEEE MPEG-2 specification.
 * @param width The resolution width of the video. This variable is only needed until the StreamIt
 *              language supports dynamically reconfiguring splijtoins.
 * @param height The resolution height of the video. This variable is only needed until the StreamIt
 *               language supports dynamically reconfiguring splitjoins.
 * @input An MPEG-2 compliant bit stream of variable length.
 * @output Outputs a series of images representing the frames of the video. Each image
 *         consists of 3 integers for each pixel, with the number of pixels per image 
 *         equalling the width * height of the video. Frames are output in time order,
 *         top to bottom, left to right, and RGB color order.
 */
bit->int pipeline MPEGStream_to_rawImageStream(int width, int height,
                                               int the_chroma_format) {
    // width, height, chroma: Hacked till we have reprogrammable splitjoins FEATURETODO

    portal<InverseQuantization_AC_Coeff> UpdatePortal_quantiser_data_ac;
    portal<InverseQuantizationJoinerSubstitute> UpdatePortal_macroblock_intra;
    portal<InverseQuantization_DC_Intra_Coeff> UpdatePortal_quantiser_data_dc;
    portal<MotionPrediction> UpdatePortal_picture_type;
    portal<MotionVectorDecode> UpdatePortal_mvd;
    portal<PictureReorder> UpdatePortal_picture_type2;
 
    add MPEGStreamParser(UpdatePortal_quantiser_data_ac,
                         UpdatePortal_quantiser_data_dc,
                         UpdatePortal_macroblock_intra,
                         UpdatePortal_picture_type,
                         UpdatePortal_mvd,
                         UpdatePortal_picture_type2,
                         width,
                         height,
                         the_chroma_format
                         );

    add int->int splitjoin {
        split roundrobin(64*blocks_per_macroblock[the_chroma_format], 16, 3);
        add BlockDecode(UpdatePortal_quantiser_data_ac, 
                        UpdatePortal_macroblock_intra, 
                        UpdatePortal_quantiser_data_dc);
        add int->int pipeline {
            add MotionVectorDecode() to UpdatePortal_mvd;
            add Repeat(8, blocks_per_macroblock[the_chroma_format]);
        }
        add Repeat(3, blocks_per_macroblock[the_chroma_format]); // macroblock_intra
        join roundrobin(64, 8, 3);
    }

    // Each output channel is ordered left to right, top to bottom

    add ColorChannelProcessing(width, height, UpdatePortal_picture_type, the_chroma_format);

    // FEATURETODO This next component should also use the UpdatePortal_picture_type
    // but it doesn't because of messaging limitations.
    add PictureReorder(width, height) to UpdatePortal_picture_type2;

    // This function assumes that no sequence display extension was ever
    // encountered in the data stream, and the default colorspace transformations 
    // apply.
    // (cite 1, P. 47, Table 6-9): Refer to entry 1, which is
    // Recommendation ITU-R BT.709 for transformations.
    add ColorSpaceConversion_YCbCrtoRGB;

}

/**
 * @internal
 */
int->int pipeline BlockDecode(portal<InverseQuantization_AC_Coeff> UpdatePortal_quantiser_data_ac,
                              portal<InverseQuantizationJoinerSubstitute> UpdatePortal_macroblock_intra,
                              portal<InverseQuantization_DC_Intra_Coeff> UpdatePortal_quantiser_data_dc
                              ) {
    add ZigZagUnordering;
    // Assumes no alternate_scan TODO
    // Output of this corresponds to QF[v][u], (cite 1, P. 67)
    add InverseQuantization(UpdatePortal_quantiser_data_ac,
                            UpdatePortal_quantiser_data_dc,
                            UpdatePortal_macroblock_intra);
    // Extreme bounds for both saturations are a best guess about how far off
    // any invalid data could ever get.
    add BestSaturation(-2048, 2047, -2050, 2050);
    add MismatchControl();
    add iDCT8x8_ieee(2); // fast iDCT
    add BestSaturation(-256, 255, -260, 260);
}

/**
 * @internal
 */
int->int pipeline InverseQuantization(  
                                      portal<InverseQuantization_AC_Coeff> UpdatePortal_quantiser_data_ac,
                                      portal<InverseQuantization_DC_Intra_Coeff> UpdatePortal_quantiser_data_dc,
                                      portal<InverseQuantizationJoinerSubstitute> UpdatePortal_macroblock_intra) {

    // The handling of the intra DC coefficient is described on (cite 1, P.69)
    add int->int splitjoin {
        split duplicate;
        // Intra Coded Macroblocks
        add int->int splitjoin {
            split roundrobin(1, 63); 
            add InverseQuantization_DC_Intra_Coeff to UpdatePortal_quantiser_data_dc; // (cite 1, P.69)
            add InverseQuantization_AC_Coeff(1) to UpdatePortal_quantiser_data_ac;
            join roundrobin(1, 63); 
        }
        // Non Intra Coded Macroblocks
        add InverseQuantization_AC_Coeff(0) to UpdatePortal_quantiser_data_ac;
        join roundrobin(64, 64);  
    }
  
    // Selects which stream - FEATURETODO eventually programmable splitjoin and only one of the two
    // above branches gets taken instead of both.
 
    add InverseQuantizationJoinerSubstitute() to UpdatePortal_macroblock_intra;
}

/**
 * @internal
 */
int->int filter InverseQuantizationJoinerSubstitute {
    int macroblock_intra;
 
    init {
        macroblock_intra = -1;
    }
  
    handler setMacroblockIntra(int new_macroblock_intra) {
        macroblock_intra = new_macroblock_intra;
    }
  
    work pop (128) push 64 {
        if (macroblock_intra == -1) {
            println("  Error: macroblock_intra should not be -1, should have recieved update message");
        } else if (macroblock_intra == 1) {
            // It was Intra Coded
            for (int i = 0; i < 64; i++) {
                push(pop());
            }
            for (int i = 0; i < 64; i++) {
                pop();
            }
        } else {
            // It was Non Intra Coded
            for (int i = 0; i < 64; i++) {
                pop();
            }
            for (int i = 0; i < 64; i++) {
                push(pop());
            }
        }
    
    } 

}


/**
 * @internal
 */
int->int filter InverseQuantization_DC_Intra_Coeff() {
    // (cite 1, P.69)
    int[4] intra_dc_mult;
    int intra_dc_precision;

    init {
        intra_dc_mult[0] = 8;
        intra_dc_mult[1] = 4;
        intra_dc_mult[2] = 2;
        intra_dc_mult[3] = 1;
        intra_dc_precision = -1; // In case no message is received, error
    }

    work pop 1 push 1 {
        push(intra_dc_mult[intra_dc_precision] * pop());
    }

    handler setIntraDCPrecision(int new_intra_dc_precision) {
        intra_dc_precision = new_intra_dc_precision;
    }
}

/**
 * @internal
 */
int->int filter InverseQuantization_AC_Coeff(int macroblock_intra) {
    // Assumes 4:2:0 data
    // (cite 1, P.69)
    // intra = 1: This is dequantizing the non-DC part of an intra coded block
    // intra = 0: This is dequantizing the DC and AC part of a non-intra coded block

    // These are all assigned by messages and MUST be assigned before the first 
    // call to work()
    int quantiser_scale_code;
    int q_scale_type;
    int[64] intra_quantiser_matrix;
    int[64] non_intra_quantiser_matrix;

    // (cite 1, P.70 Table 7-6)
    int[2][32] quantiser_scale =
        // Note that quantiser_scale[x][0] is a Forbidden Value
        {{ 0,  2,  4,  6,  8, 10, 12, 14,
           16, 18, 20, 22, 24, 26, 28, 30,
           32, 34, 36, 38, 40, 42, 44, 46,
           48, 50, 52, 54, 56, 58, 60, 62},
         { 0,  1,  2,  3,  4,  5,  6,  7,
           8, 10, 12, 14, 16, 18, 20, 22,
           24, 28, 32, 36, 40, 44, 48, 52, 
           56, 64, 72, 80, 88, 96, 104, 112}};

    init {
        quantiser_scale_code = 0; // Guarantees that this throws an error
        // if it doesn't get a quantiser message
        // before getting some data.
        q_scale_type = -1; // Another nice error if no message received in time.
    }

    work pop (64-macroblock_intra) push (64-macroblock_intra) {
        if (quantiser_scale_code == 0)
            println("Error - quantiser_scale_code not allowed to be 0 " + macroblock_intra);
        for (int i = macroblock_intra; i < 64; i++) {
            int QF = pop();
            // (cite 1, P.71)
            int k = 0;
            if (macroblock_intra == 1) {
                k = 0;
            } else {
                // TODO - I think I'm interpreting this part of the spec correctly, check though.
                if (QF > 0) {
                    k = 1;
                } else if (QF < 0) {
                    k = -1;
                } else {
                    k = 0;
                }          
            }
            int W = 0;
            if (macroblock_intra == 1) {
                W = intra_quantiser_matrix[i];
            } else {
                W = non_intra_quantiser_matrix[i];
            }
            int F = (2 * QF + k) * W * 
                quantiser_scale[q_scale_type][quantiser_scale_code] / 32;
            push(F);
        }
    }

    handler setQuantiserScaleCode(int new_quantiser_scale_code) {
        quantiser_scale_code = new_quantiser_scale_code;
    }

    handler setQuantiserMatrices(int[64] new_intra_quantiser_matrix, 
                                 int[64] new_non_intra_quantiser_matrix) {
        for (int i = 0; i < 64; i++) {
            intra_quantiser_matrix[i] = new_intra_quantiser_matrix[i];
            non_intra_quantiser_matrix[i] = new_non_intra_quantiser_matrix[i];
        }
    }

    handler setQScaleType(int new_q_scale_type) {
        q_scale_type = new_q_scale_type;
    }
} 

/**
 * @internal
 */
int->int filter MismatchControl() {
    // (cite 1, P.71)
    work pop 64 push 64 {
        int sum, val;
        sum = 0;
        for (int i = 0; i < 63; i++) {
            val = pop();
            sum += val;
            push(val);
        }
        val = pop();
        sum += val;
        if ((sum & 0x1) == 0x1) {
            push(val);
        } else {
            if ((val * 0x1) == 0x1) {
                push(val-1);
            } else {
                push(val+1);
            }
        }
    }
}

/**
 * @internal
 */
int->int filter MotionVectorDecode() {
    // Note - at first glance, this filter looks like it OUGHT to handle only a single motion vector instead
    // of all 8, and then it would be wrapped inside an 8 way splitjoin. This is only because of currently
    // existing limitations in this code, however. More general MPEG-2 bitstreams allow for concealment
    // motion vectors (to help in the case of errors introduced during transmission of the bitstream), and
    // when concealment motion vectors are introduced, then dependencies are introduced between the 
    // vectors. These dependencies will make it hard to use an 8-way splitjoin approach without a 
    // message passing scheme that allows for across splitjoin messaging. 

    // Section 7.6.3.1 covers this. (cite 1, P.77)
    int[2][2][2] PMV;
    int[2][2] f_code;

    int mv_format; // HACKED TODO - MESSAGING
    int picture_structure; // HACKED TODO - MESSAGING

    init {
        mv_format = 1; // HACKD TODO MESSAGING
        picture_structure = 1; // HACKED TODO - MESSAGING
    }

    work pop 16 push 8 {
        int[2][2][2] motion_code;
        for (int r = 0; r < 2; r++)
            for (int s = 0; s < 2; s++) 
                for (int t = 0; t < 2; t++) {
                    motion_code[r][s][t] = pop();
                }
        int[2][2][2] motion_residual;
        for (int r = 0; r < 2; r++)
            for (int s = 0; s < 2; s++) 
                for (int t = 0; t < 2; t++) {
                    motion_residual[r][s][t] = pop();
                }
        int[2][2][2] vectorp;
        for (int r = 0; r < 1; r++) {
            // NOTE TODO - Hacked right now, don't know when we need the second motion vector.
            for (int s = 0; s < 2; s++) {
                for (int t = 0; t < 2; t++) {
                    int r_size = f_code[s][t]-1;
                    int f = 1 << r_size;
                    int high = (16*f)-1;
                    int low = ((-16)*f);
                    int range = (32*f);
                    int delta;
                    if ((f == 1) || (motion_code[r][s][t] == 0)) {
                        delta = motion_code[r][s][t];
                    } else {
                        delta = ((int) (abs(motion_code[r][s][t])-1)*f) + 
                            motion_residual[r][s][t]+1;
                        if (motion_code[r][s][t]<0)
                            delta = -delta;
                    }
                    int prediction = PMV[r][s][t];
                    if ((mv_format == 0) && (t == 1) && (picture_structure == 3))
                        println("Error - Program Limitation: May not be correct in decoding motion vectors");
                    vectorp[r][s][t] = prediction + delta;
                    if (vectorp[r][s][t] < low)
                        vectorp[r][s][t] = vectorp[r][s][t] + range;
                    if (vectorp[r][s][t] > high)
                        vectorp[r][s][t] = vectorp[r][s][t] - range;
                    if ((mv_format == 0) && (t == 1) && (picture_structure == 3))
                        println("Error - Program Limitation: May not be correct in decoding motion vectors");
                    else 
                        PMV[r][s][t] = vectorp[r][s][t];
                    // TODO handle updating missed motion_vectors
                    // section 7.6.3.3 
                }
            }
        } 
        for (int r = 0; r < 2; r++)
            for (int s = 0; s < 2; s++) 
                for (int t = 0; t < 2; t++) {
                    push(vectorp[r][s][t]);
                }
    }
  
    handler resetPredictors() {
        for (int i = 0; i < 2; i++)
            for (int j = 0; j < 2; j++)
                for (int k = 0; k < 2; k++) {
                    PMV[i][j][k] = 0;
                }
    }
 
    handler setFCode(int[2][2] new_f_code) {
        for (int s = 0; s < 2; s++) 
            for (int t = 0; t < 2; t++) 
                f_code[s][t] = new_f_code[s][t];
    }

}

/**
 * @internal
 */
int->int pipeline LuminanceChannelProcessing(int width, 
                                             int height,
                                             portal<MotionPrediction> UpdatePortal_picture_type,
                                             int the_chroma_format) {
    add MacroBlockDescrambler(width, 64+11, 2);
    add DescrambleAndMotionCompensate(width, height, 1, 1, UpdatePortal_picture_type, 1, the_chroma_format);
}

/**
 * @internal
 */
int->int pipeline ChrominanceChannelProcessing(int width, 
                                               int height,
                                               portal<MotionPrediction> UpdatePortal_picture_type,
                                               int the_chroma_format) {
    // Assumes 4:2:0 to 4:4:4 or 4:2:2 to 4:4:4
    // Adding 4:4:4 support requires some additional block reordering.
    if (the_chroma_format == 2) {
        add MacroBlockDescrambler(width/2, 64+11, 1);
    }
    int vertical_upsample_factor;
    if (the_chroma_format == 1) {
        vertical_upsample_factor = 2;
    } else {
        vertical_upsample_factor = 1;
    }
    add DescrambleAndMotionCompensate(width, height, vertical_upsample_factor, 2, UpdatePortal_picture_type, 0, the_chroma_format);
    if (the_chroma_format == 1) {
        add ChannelUpsample_Vert_and_Horz(width/2, height/2);
    } else {
        add ChannelUpsample_Horizontal(width/2, height);
    }
}

/**
 * @internal
 */
int->int splitjoin MacroBlockDescrambler(int width, int block_data_size, int horiz_blockwidth) {
    split roundrobin(block_data_size*horiz_blockwidth);
    for (int i = 0; i < 2; i++) {
        add Identity<int>;
    }
    join roundrobin((width/8)*block_data_size);
}

int->int filter SendBackReferenceFrame(int width, int height,
                                       portal<MotionPrediction> UpdatePortal_reference_frame) {
    work pop (width*height) push (width*height) {
        int[width][height] picture;
        for (int y = 0; y < height; y++) {
            for (int x = 0; x < width; x++) {
                push(peek(0));
                picture[x][y] = pop();
            }
        }
        UpdatePortal_reference_frame.referenceFrame(picture) [1:1];    
    }
}

/**
 * @internal
 */
int->int splitjoin BlockDescrambler(int width) {
    split roundrobin(8);
    for (int i = 0; i < 8; i++) {
        add Identity<int>;
    }
    join roundrobin(width);
}

/**
 * @internal
 *
 * This is a filter version of the block descrambler that should avoid
 * some fusion overhead.  This version does not need any buffer, and
 * should be able to be derived by linear analysis.  Unfortunately, no
 * speedups were observed, but including it here for future reference.
 */
int->int filter BlockDescramblerFilter1(int width) {
    work push 8*width pop 8*width {
        for (int i=0; i<64; i+=8) {
            for (int j=0; j<width*8; j+=width) {
                int k = i+j;
                push(peek(k));
                push(peek(k+1));
                push(peek(k+2));
                push(peek(k+3));
                push(peek(k+4));
                push(peek(k+5));
                push(peek(k+6));
                push(peek(k+7));
            }
        }
        for (int i=0; i<8*width; i++) {
            pop();
        }
    }
}

/**
 * @internal
 *
 * This is a filter version of the block descrambler that should avoid
 * some fusion overhead.  This version uses a buffer so that no peek
 * statements are needed.  It is probably slower than
 * BlockDescramblerFilter1, but including for future experiments.
 */
int->int filter BlockDescramblerFilter2(int width) {
    work push 8*width pop 8*width {
        int[8*width] buffer;
        for (int i=0; i<width; i+=8) {
            for (int j=0; j<8; j++) {
                int k = j*width+i;
                buffer[k] = pop();
                buffer[k+1] = pop();
                buffer[k+2] = pop();
                buffer[k+3] = pop();
                buffer[k+4] = pop();
                buffer[k+5] = pop();
                buffer[k+6] = pop();
                buffer[k+7] = pop();
            }
        }
        for (int i=0; i<8*width; i++) {
            push(buffer[i]);
        }
    }
}

/**
 * @internal
 */
int->int filter MotionPrediction(int width, int height) {
    int count;

    int lastSeenFrame;

    int datarate = (width*height/64*(64+8+1+1+1));
    int pushrate = width*height;
  
    int[width][height] prev_picture;
    int[width][height] next_picture;

    int next_picture_type;

    init {
        next_picture_type = -1;
        count = 0;
    }

    work pop datarate push pushrate {
        if (next_picture_type == -1) {
            println("Error - Should have received a picture type message before motion prediction can process");
        } 
        if (next_picture_type == 1 || next_picture_type == 2) {
            prev_picture = next_picture;
            if (next_picture_type == 1) {
                readIPicture();
            } else {
                readPPicture();
            }
        } else {
            readBPicture();
        }
        count++;
    }

    phase readIPicture pop datarate push pushrate {
        lastSeenFrame = 1;
        int[width][height] temp_picture;
 
        for (int blocky = 0; blocky < (height/8); blocky++) {
            for (int blockx = 0; blockx < (width/8); blockx++) {
                for (int y = 0; y < 8; y++) {
                    for (int x = 0; x < 8; x++) {
                        temp_picture[x+blockx*8][y+blocky*8] = pop();
                    }
                }
                for (int i = 0; i < 8; i++) {
                    pop();
                }
                pop();
                pop();
                pop();
            }
        }

        for (int y = 0; y < height; y++) {
            for (int x = 0; x < width; x++) {
                next_picture[x][y] = temp_picture[x][y];
                push(temp_picture[x][y]);
            }
        }
    }

    phase readPPicture pop datarate push pushrate {
        lastSeenFrame = 2;
        int[width][height] temp_picture;
        int[width/8][height/8][2][2][2] vector;
        int[width/8][height/8] macroblock_intra;

        for (int blocky = 0; blocky < height/8; blocky++) {
            for (int blockx = 0; blockx < width/8; blockx++) {
                for (int y = 0; y < 8; y++) {
                    for (int x = 0; x < 8; x++) {
                        temp_picture[x+blockx*8][y+blocky*8] = pop();
                    }
                }
                for (int r = 0; r < 2; r++) {
                    for (int s = 0; s < 2; s++) {
                        for (int t = 0; t < 2; t++) {
                            vector[blockx][blocky][r][s][t] = pop();
                        }
                    }
                }
                macroblock_intra[blockx][blocky] = pop();
                pop();
                pop();
            }
        }

        for (int y = 0; y < height; y++) {
            for (int x = 0; x < width; x++) {
                int pixel;
                if (macroblock_intra[x/8][y/8] == 0) {
                    int sample_data;
                    sample_data = predictMotionPixel(prev_picture, vector, 0, x, y);
                    pixel = sample_data;
                } else {
                    pixel = 0;
                }
                next_picture[x][y] = temp_picture[x][y] + pixel;
                push(next_picture[x][y]);
                if (next_picture[x][y] > 127) {
                    next_picture[x][y] = 127;
                } else if (next_picture[x][y] < -128) {
                    next_picture[x][y] = -128;
                }
            }
        }
    }

    phase readBPicture pop datarate push pushrate {
        lastSeenFrame = 3;
        int[width][height] temp_picture;
        int[width/8][height/8][2][2][2] vector;
        int[width/8][height/8] macroblock_intra;
        int[width/8][height/8] macroblock_motion_forward;
        int[width/8][height/8] macroblock_motion_backward;

        for (int blocky = 0; blocky < height/8; blocky++) {
            for (int blockx = 0; blockx < width/8; blockx++) {
                for (int y = 0; y < 8; y++) {
                    for (int x = 0; x < 8; x++) {
                        temp_picture[x+blockx*8][y+blocky*8] = pop();
                    }
                }
                for (int r = 0; r < 2; r++) {
                    for (int s = 0; s < 2; s++) {
                        for (int t = 0; t < 2; t++) {
                            vector[blockx][blocky][r][s][t] = pop();
                        }
                    }
                }
                macroblock_intra[blockx][blocky] = pop();
                macroblock_motion_forward[blockx][blocky] = pop();
                macroblock_motion_backward[blockx][blocky] = pop();
            }
        }

        for (int y = 0; y < height; y++) {
            for (int x = 0; x < width; x++) {
                int pushval;
                int permsample = 0;
                if (macroblock_intra[x/8][y/8] == 0) {
                    int[2] sample_data;
                    if (macroblock_motion_forward[x/8][y/8] == 1) {
                        sample_data[0] = predictMotionPixel(prev_picture, vector, 0, x, y);
                    }
                    if (macroblock_motion_backward[x/8][y/8] == 1) {
                        sample_data[1] = predictMotionPixel(next_picture, vector, 1, x, y);
                    }
                    if (macroblock_motion_forward[x/8][y/8] == 1) {
                        if (macroblock_motion_backward[x/8][y/8] == 1) {
                            permsample = (1+sample_data[0]+sample_data[1]+256)/2-128;
                        } else {
                            permsample = sample_data[0];  
                        }
                    } else {
                        if (macroblock_motion_backward[x/8][y/8] == 1) {
                            permsample = sample_data[1];
                        } else {
                            // TODO - this should be the previous frame's macroblock, not the previous reference frame's macroblock
                            permsample = prev_picture[x][y];
                        }
                    }
                } else {
                    permsample = 0;
                }
                pushval = temp_picture[x][y] + permsample;
                push(pushval);
            }
        }
    }

    handler setPictureType(int picture_coding_type) {
        next_picture_type = picture_coding_type;
    }

    int predictPixelHorizHalfPelVertHalfPel(int[width][height] predict_pic, int horiz_vector, int vert_vector) {
        int sample_data;
        sample_data = (predict_pic[(horiz_vector-1)/2][(vert_vector-1)/2] +
                       predict_pic[(horiz_vector-1)/2][(vert_vector+1)/2] +
                       predict_pic[(horiz_vector+1)/2][(vert_vector-1)/2] +
                       predict_pic[(horiz_vector+1)/2][(vert_vector+1)/2]);
        sample_data += 128*4;
        if (sample_data > 0) {
            sample_data += 2;
        } else if (sample_data < 0) {
            println("Error - Shouldn't be less than zero " + sample_data);
        }
        sample_data = sample_data / 4;
        sample_data -= 128;
        return sample_data;
    }

    int predictPixelHorizHalfPelVertFullPel(int[width][height] predict_pic, int horiz_vector, int vert_vector) {
        int sample_data;
        sample_data = (predict_pic[(horiz_vector-1)/2][vert_vector/2] +
                       predict_pic[(horiz_vector+1)/2][vert_vector/2]);
        sample_data += 128*2;
        if (sample_data > 0) {
            sample_data += 1;
        } else if (sample_data < 0) { 
            println("Error - Shouldn't be less than zero " + sample_data);
        }
        sample_data = sample_data / 2;
        sample_data -= 128;
        return sample_data;
    }

    int predictPixelHorizFullPelVertHalfPel(int[width][height] predict_pic, int horiz_vector, int vert_vector) {
        int sample_data;
        sample_data = (predict_pic[horiz_vector/2][(vert_vector-1)/2] +
                       predict_pic[horiz_vector/2][(vert_vector+1)/2]);
        sample_data += 128*2;
        if (sample_data > 0) {
            sample_data += 1;
        } else if (sample_data < 0) {
            println("Error - Shouldn't be less than zero " + sample_data);
        }
        sample_data = sample_data / 2;
        sample_data -= 128;
        return sample_data;
    }

    int predictPixelHorizFullPelVertFullPel(int[width][height] predict_pic, int horiz_vector, int vert_vector) {
        int sample_data;
        sample_data = predict_pic[horiz_vector/2][vert_vector/2];
        return sample_data;
    }

    int predictMotionPixel(int[width][height] predict_pic, int[width/8][height/8][2][2][2] vector, 
                           int whichvect, int x, int y) {
        // whichvect = 0 for forward motion prediction
        // whichvect = 1 for backward motion prediction
        int horiz_vector = vector[x/8][y/8][0][whichvect][0] + (x*2);
        int vert_vector = vector[x/8][y/8][0][whichvect][1] + (y*2);
        int sample_data;
        if (vert_vector < 0 || vert_vector >= (height*2-1) || 
            horiz_vector < 0 || horiz_vector >= (width*2-1)) {
            sample_data = 0;
        } else if ((horiz_vector & 0x1) == 1) {
            if ((vert_vector & 0x1) == 1) {
                sample_data = predictPixelHorizHalfPelVertHalfPel(predict_pic, horiz_vector, vert_vector);
            } else {
                sample_data = predictPixelHorizHalfPelVertFullPel(predict_pic, horiz_vector, vert_vector);
            }
        } else {
            if ((vert_vector & 0x1) == 1) {
                sample_data = predictPixelHorizFullPelVertHalfPel(predict_pic, horiz_vector, vert_vector);
            } else {
                sample_data = predictPixelHorizFullPelVertFullPel(predict_pic, horiz_vector, vert_vector);
            }
        }
        if (sample_data > 127)
            sample_data = 127;
        else if (sample_data < -128)
            sample_data = -128;
        return sample_data;
    }

}

// Note: We assume we are going from 4:2:0 to 4:4:4
// Otherwise this won't work.
// Check out store.c in the mpeg reference implementation
// It has a more complicated, probably more accurate
// implementation. Only implement if needed.
/**
 * @internal
 */
int->int pipeline ChannelUpsample_Vert_and_Horz(int sourcewidth, int sourceheight) {
    add ChannelUpsample_Vertical(sourcewidth, sourceheight);
    add ChannelUpsample_Horizontal(sourcewidth, sourceheight);
}

int->int splitjoin ChannelUpsample_Vertical(int sourcewidth, int sourceheight) {
    split roundrobin(1);
    for (int i = 0; i < sourcewidth; i++) {
        add ChannelUpsample_1D(sourceheight, 0.75, 0.25);
    }
    join roundrobin(1);
}

int->int splitjoin ChannelUpsample_Horizontal(int sourcewidth, int sourceheight) {
    split roundrobin(sourcewidth);
    for (int i = 0; i < sourceheight; i++) {
        add ChannelUpsample_1D(sourcewidth, 0.5, 0.5);
    }
    join roundrobin(sourcewidth*2);
}

/**
 * @internal
 */
int->int filter ChannelUpsample_1D_Unoptimized(int sourcelen, float weight1, float weight2) {
    work pop sourcelen push sourcelen*2 {
        int val1 = 0, val2 = 0;
        val1 = pop();
        push(val1);
        for (int i = 0; i < sourcelen-1; i++) {
            val2 = pop();
            float outval = (weight1*val1+weight2*val2);
            push((int) round(outval));
            outval = (weight2*val1+weight1*val2);
            push((int) round(outval));
            val1 = val2;
        }
        push(val2);
    }    
}

/**
 * @internal
 */
int->int filter ChannelUpsample_1D(int sourcelen, 
                                   float weight1, 
                                   float weight2) {
    work pop sourcelen push sourcelen*2 {
        int val1 = 0, val2 = 0;
        // keep track of product of weights to avoid extra multiplies
        float w1val1, w1val2; // weight1 * val1, weight1 * val2
        float w2val1, w2val2; // weight2 * val1, weight2 * val2

        val1 = pop();
        w1val1 = weight1*val1;
        w2val1 = weight2*val1;

        push(val1);
        for (int i = 0; i < sourcelen-1; i++) {
            val2 = pop();
            w1val2 = weight1*val2;
            w2val2 = weight2*val2;

            float outval = (w1val1+w2val2);
            push((int) round(outval));
            outval = (w2val1+w1val2);
            push((int) round(outval));

            w1val1 = w1val2;
            w2val1 = w2val2;
        }
        push(val2);
    }    
}

/**
 * @internal
 */
int->int filter PictureReorder(int width, int height) {
    int datarate = (width*height*3);
    int[(width*height*3)] databuffer;
    int next_picture_type;

    prework pop datarate {
        for (int i = 0; i < datarate; i++) {
            databuffer[i] = pop();
        }
    }

    work pop datarate push datarate {
        if (next_picture_type == 3) {
            for (int i = 0; i < datarate; i++) {
                push(pop());
            }
        } else {
            for (int i = 0; i < datarate; i++) {
                push(databuffer[i]);
                databuffer[i] = pop();
            }
        }     
    }

    handler setPictureType(int picture_coding_type) {
        next_picture_type = picture_coding_type;
    }
}




